{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import itertools\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import datasets,transforms\n",
    "from torchvision.utils import save_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = './images'\n",
    "channels = 1                    # MNIST has only 1\n",
    "\n",
    "n_epochs = 30\n",
    "batch_size = 128\n",
    "lr = 1e-3\n",
    "\n",
    "img_size = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "            transforms.ToTensor()\n",
    "            ])\n",
    "\n",
    "train = datasets.MNIST(root='./data/',train=True,transform=transform,download=True)\n",
    "test = datasets.MNIST(root='./data/',train=False,transform=transform,download=True)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "            train,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "\n",
    ")\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "            test,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = [input_dim] + hidden_dim\n",
    "        self.encoder = nn.ModuleList([nn.Linear(self.hidden_dim[idx], self.hidden_dim[idx+1]) \n",
    "                                      for idx in range(len(self.hidden_dim)-1)])\n",
    "        self.mu = nn.Linear(self.hidden_dim[-1], latent_dim)\n",
    "        self.logvar = nn.Linear(self.hidden_dim[-1], latent_dim)\n",
    "        self.decoder = nn.ModuleList([nn.Linear(latent_dim, self.hidden_dim[-1])] + [nn.Linear(self.hidden_dim[idx], self.hidden_dim[idx-1]) \n",
    "                                                                                for idx in range(len(self.hidden_dim)-1, 0, -1)])\n",
    "        \n",
    "        self.init_weights()\n",
    "        \n",
    "    def init_weights(self):\n",
    "        for layer in self.encoder:\n",
    "            nn.init.xavier_uniform_(layer.weight)\n",
    "            nn.init.zeros_(layer.bias)\n",
    "        for layer in self.decoder:\n",
    "            nn.init.xavier_uniform_(layer.weight)\n",
    "            nn.init.zeros_(layer.bias)\n",
    "        nn.init.xavier_uniform_(self.mu.weight)\n",
    "        nn.init.zeros_(self.mu.bias)\n",
    "        \n",
    "    def reparameterization(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        \n",
    "        return mu + eps * std\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for layer in self.encoder:\n",
    "            x = F.relu(layer(x))\n",
    "            \n",
    "        mu = F.relu(self.mu(x))\n",
    "        logvar = F.relu(self.logvar(x))\n",
    "        z = self.reparameterization(mu, logvar)\n",
    "        \n",
    "        for idx in range(len(self.decoder)):\n",
    "            if idx == len(self.decoder) -1: \n",
    "                z = F.sigmoid(self.decoder[idx](z))\n",
    "            else:\n",
    "                z = F.relu(self.decoder[idx](z))\n",
    "        \n",
    "        return z, mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE(img_size**2, [256], 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAE(\n",
      "  (encoder): ModuleList(\n",
      "    (0): Linear(in_features=784, out_features=256, bias=True)\n",
      "  )\n",
      "  (mu): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (logvar): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (decoder): ModuleList(\n",
      "    (0): Linear(in_features=128, out_features=256, bias=True)\n",
      "    (1): Linear(in_features=256, out_features=784, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE_loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE_loss, self).__init__()\n",
    "    \n",
    "    def forward(self, x, x_hat, mu, logvar):\n",
    "        reconst_loss = F.binary_cross_entropy(x_hat, x, reduction='sum')\n",
    "        kl_div = 0.5 * torch.sum(mu.pow(2) + logvar.exp() - logvar - 1)\n",
    "        \n",
    "        return reconst_loss + kl_div\n",
    "    \n",
    "criterion = VAE_loss() \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, eps=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, train loss: 24305.8743\n",
      "Epoch 2/30, train loss: 20219.7461\n",
      "Epoch 3/30, train loss: 19470.4025\n",
      "Epoch 4/30, train loss: 19068.3516\n",
      "Epoch 5/30, train loss: 18811.7356\n",
      "Epoch 6/30, train loss: 18624.4605\n",
      "Epoch 7/30, train loss: 18489.3783\n",
      "Epoch 8/30, train loss: 18368.9338\n",
      "Epoch 9/30, train loss: 18275.9860\n",
      "Epoch 10/30, train loss: 18222.4914\n",
      "Epoch 11/30, train loss: 18127.2220\n",
      "Epoch 12/30, train loss: 18063.6287\n",
      "Epoch 13/30, train loss: 18012.4368\n",
      "Epoch 14/30, train loss: 17968.5162\n",
      "Epoch 15/30, train loss: 17907.1699\n",
      "Epoch 16/30, train loss: 17888.2026\n",
      "Epoch 17/30, train loss: 17845.9119\n",
      "Epoch 18/30, train loss: 17811.1885\n",
      "Epoch 19/30, train loss: 17773.1718\n",
      "Epoch 20/30, train loss: 17740.0160\n",
      "Epoch 21/30, train loss: 17710.7172\n",
      "Epoch 22/30, train loss: 17686.4788\n",
      "Epoch 23/30, train loss: 17667.2347\n",
      "Epoch 24/30, train loss: 17635.2107\n",
      "Epoch 25/30, train loss: 17626.6690\n",
      "Epoch 26/30, train loss: 17577.5318\n",
      "Epoch 27/30, train loss: 17566.2183\n",
      "Epoch 28/30, train loss: 17550.2618\n",
      "Epoch 29/30, train loss: 17546.8999\n",
      "Epoch 30/30, train loss: 17528.7826\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    train_loss = 0\n",
    "    for i, (x, _) in enumerate(train_dataloader):\n",
    "        # forward\n",
    "        x = x.view(-1, img_size**2)\n",
    "        x = x.to(device)\n",
    "        pred, mu, logvar = model(x)\n",
    "        reconst_loss = F.binary_cross_entropy(pred, x, reduction='sum')\n",
    "        kl_divergence = - 0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "        \n",
    "        loss = reconst_loss + kl_divergence\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "    train_loss /= len(train_dataloader)\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{n_epochs}, train loss: {train_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchvision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
