{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/recbole/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "<frozen importlib._bootstrap>:219: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "from torch.optim import SGD\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('preprocessed_df_with_timestamp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Netflix(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.users = self.df['Cust_ID'].values\n",
    "        self.items = self.df['Movie_Id'].values\n",
    "        self.ratings = self.df['Rating'].values\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        user = self.users[index]\n",
    "        item = self.items[index]\n",
    "        rating = self.ratings[index]\n",
    "        \n",
    "        return user, item, rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cust_ID</th>\n",
       "      <th>Movie_Id</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2005-09-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2005-05-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2005-10-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2005-12-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2004-05-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351307</th>\n",
       "      <td>2490</td>\n",
       "      <td>96</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2004-06-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351312</th>\n",
       "      <td>2489</td>\n",
       "      <td>96</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2005-01-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351328</th>\n",
       "      <td>2494</td>\n",
       "      <td>96</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2003-03-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352251</th>\n",
       "      <td>538</td>\n",
       "      <td>96</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2004-06-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352330</th>\n",
       "      <td>541</td>\n",
       "      <td>96</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2004-04-11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10775 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Cust_ID  Movie_Id  Rating   Timestamp\n",
       "0             0         0     3.0  2005-09-06\n",
       "1             1         0     5.0  2005-05-13\n",
       "2             2         0     4.0  2005-10-19\n",
       "3             3         0     4.0  2005-12-26\n",
       "4             4         0     3.0  2004-05-03\n",
       "...         ...       ...     ...         ...\n",
       "351307     2490        96     4.0  2004-06-08\n",
       "351312     2489        96     4.0  2005-01-19\n",
       "351328     2494        96     4.0  2003-03-12\n",
       "352251      538        96     2.0  2004-06-07\n",
       "352330      541        96     4.0  2004-04-11\n",
       "\n",
       "[10775 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df = df.loc[(df['Cust_ID'] < 2500) & (df['Movie_Id'] < 97)]\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8625/2715847652.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sample_df['Cust_ID'] = sample_df['Cust_ID'].map(sample_df_user2idx)\n",
      "/tmp/ipykernel_8625/2715847652.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sample_df['Movie_Id'] = sample_df['Movie_Id'].map(sample_df_item2idx)\n",
      "/tmp/ipykernel_8625/2715847652.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sample_df['Timestamp'] = pd.to_datetime(sample_df['Timestamp'])\n",
      "/tmp/ipykernel_8625/2715847652.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sample_df.loc[:,'bins'] = pd.cut(sample_df['Timestamp'], bins=bins, labels=False)\n"
     ]
    }
   ],
   "source": [
    "# sample_df = sample_df[['Cust_ID','Movie_Id','Rating']]\n",
    "sample_df_user2idx = {user:idx for idx, user in enumerate(sample_df['Cust_ID'].unique())} \n",
    "sample_df_item2idx = {item:idx for idx, item in enumerate(sample_df['Movie_Id'].unique())}\n",
    "sample_df['Cust_ID'] = sample_df['Cust_ID'].map(sample_df_user2idx)\n",
    "sample_df['Movie_Id'] = sample_df['Movie_Id'].map(sample_df_item2idx)\n",
    "sample_df['Timestamp'] = pd.to_datetime(sample_df['Timestamp'])\n",
    "bins = pd.date_range(start = '1999-11-01', end = '2005-12-31', freq = 'M')\n",
    "sample_df.loc[:,'bins'] = pd.cut(sample_df['Timestamp'], bins=bins, labels=False)\n",
    "\n",
    "# sample_df = sample_df[['Cust_ID','Movie_Id','Rating']]\n",
    "train_df, test_df = train_test_split(sample_df, test_size = 0.2, random_state = 42)\n",
    "temporal_train_df = train_df[['Cust_ID','Movie_Id','Rating','bins']]\n",
    "temporal_test_df = test_df[['Cust_ID','Movie_Id','Rating','bins']]\n",
    "train_df = train_df[['Cust_ID','Movie_Id','Rating']]\n",
    "test_df = test_df[['Cust_ID','Movie_Id','Rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Netflix(train_df)\n",
    "test_dataset = Netflix(test_df)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = csr_matrix(\n",
    "    (np.array(train_df['Rating'].values, dtype = np.int32),\n",
    "    (np.array(train_df['Cust_ID'].values, dtype = np.int32),np.array(train_df['Movie_Id'].values, dtype = np.int32))\n",
    "    ), shape = (len(sample_df_user2idx), len(sample_df_item2idx)))\n",
    "\n",
    "mu = train_df.Rating.mean() \n",
    "F = 15\n",
    "k = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, criterion ,optimizer):\n",
    "    model.train() \n",
    "    total_loss = 0 \n",
    "    for user, item, rating in train_loader:\n",
    "        user = user.to(device)\n",
    "        item = item.to(device)\n",
    "        rating = rating.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        pred = model(user, item)\n",
    "        loss = criterion(pred, rating)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "def evaluate(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for user, item, rating in test_loader:\n",
    "            try:\n",
    "                user = user.to(device)\n",
    "                item = item.to(device)\n",
    "                rating = rating.to(device)\n",
    "\n",
    "                pred = model(user, item)\n",
    "                loss = criterion(pred, rating)\n",
    "\n",
    "                total_loss += loss.item()\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    return total_loss / len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function (this my favorite choice)\n",
    "def RMSELoss(yhat,y):\n",
    "    return torch.sqrt(torch.mean((yhat-y)**2)+1e-6)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaselineEstimates(nn.Module):\n",
    "    def __init__(self, num_users, num_items, mu):\n",
    "        super(BaselineEstimates, self).__init__()\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.mu = mu\n",
    "        \n",
    "        self.user_biases = nn.Embedding(num_users, 1)\n",
    "        self.item_biases = nn.Embedding(num_items, 1)\n",
    "        \n",
    "        self.user_biases.weight.data.normal_(0,1)\n",
    "        self.item_biases.weight.data.normal_(0,1)\n",
    "    \n",
    "    def forward(self, user, item):\n",
    "        bu = self.user_biases(user)\n",
    "        bi = self.item_biases(item)\n",
    "        \n",
    "        rui = self.mu + torch.squeeze(bu) + torch.squeeze(bi)\n",
    "        \n",
    "        return rui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeighborhoodModel(nn.Module):\n",
    "    def __init__(self, R, mu, k):\n",
    "        super(NeighborhoodModel, self).__init__()\n",
    "        self.R = R \n",
    "        self.k = k\n",
    "        self.num_users, self.num_items = R.shape\n",
    "        self.Base = BaselineEstimates(self.num_users, self.num_items, mu)\n",
    "        self.item_weights = nn.Parameter(torch.normal(0,1,size=(self.num_items,self.num_items)))\n",
    "        self.implicit_offset = nn.Parameter(torch.normal(0,1,size=(self.num_items,self.num_items)))\n",
    "        self.mu = mu\n",
    "        self.S = cosine_similarity(R.T)\n",
    "        \n",
    "        self.get_top_k()\n",
    "        self.get_implicit()\n",
    "        \n",
    "    def get_top_n_indices(self, list, n):\n",
    "        sorted_indices = sorted(range(len(list)), key=lambda i: list[i], reverse=True)\n",
    "        top_n_indices = sorted_indices[:n]\n",
    "        \n",
    "        return top_n_indices\n",
    "\n",
    "    def get_top_k(self):\n",
    "        self.similar_k = {}\n",
    "        for item in range(self.num_items):\n",
    "            self.similar_k[item] = self.get_top_n_indices(self.S[item], self.k)\n",
    "            \n",
    "    def get_implicit(self):\n",
    "        self.implicit_data = {} \n",
    "        users, items = R.toarray().nonzero()\n",
    "        for user, item in zip(users, items):\n",
    "            if user not in self.implicit_data:\n",
    "                self.implicit_data[user] = []\n",
    "            self.implicit_data[user].append(item)\n",
    "  \n",
    "    def forward(self, user, item):\n",
    "        bui = self.Base(user, item)\n",
    "        user_idx = int(user)\n",
    "        item_idx = int(item)\n",
    "        \n",
    "        sum_of_item_weights = 0\n",
    "        sum_of_implicit_offset = 0\n",
    "        num_k = 0\n",
    "        \n",
    "        self.used_items = self.implicit_data[user_idx]\n",
    "        \n",
    "        for implicit in self.implicit_data[user_idx]:\n",
    "            if implicit in self.similar_k[item_idx]:\n",
    "                implicit_tensor = torch.LongTensor([implicit]).to(device)\n",
    "                num_k += 1\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    buj = self.Base(user, implicit_tensor)\n",
    "                    \n",
    "                sum_of_item_weights += (int(self.R[user,implicit].data)-buj) * self.item_weights[item][0][implicit]\n",
    "                sum_of_implicit_offset += self.implicit_offset[item][0][implicit]        \n",
    "            \n",
    "        norm = num_k ** -0.5\n",
    "\n",
    "        rui = bui + norm * sum_of_item_weights + norm * sum_of_implicit_offset\n",
    "        \n",
    "        return rui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AsymmetricSVD(nn.Module):\n",
    "    def __init__(self, R, mu, F):\n",
    "        super(AsymmetricSVD, self).__init__()\n",
    "        self.num_users, self.num_items = R.shape\n",
    "        self.Base = BaselineEstimates(self.num_users, self.num_items, mu)\n",
    "        self.R = R \n",
    "        self.Q = nn.Embedding(self.num_items, F)\n",
    "        self.X = nn.Embedding(self.num_items, F)\n",
    "        self.Y = nn.Embedding(self.num_items, F)\n",
    "        \n",
    "        self.Q.weight.data.normal_(0, 1/F)\n",
    "        self.X.weight.data.normal_(0, 1/F)\n",
    "        self.Y.weight.data.normal_(0, 1/F)\n",
    "        \n",
    "    def get_implicit(self):\n",
    "        self.implicit_data = {} \n",
    "        users, items = R.toarray().nonzero()\n",
    "        for user, item in zip(users, items):\n",
    "            if user not in self.implicit_data:\n",
    "                self.implicit_data[user] = []\n",
    "            self.implicit_data[user].append(item)\n",
    "        \n",
    "    def forward(self, user, item):\n",
    "        user_idx = int(user)\n",
    "        \n",
    "        bui = self.Base(user, item)\n",
    "        Q_i = self.Q(item)\n",
    "        \n",
    "        sum_of_item_weights = 0\n",
    "        sum_of_implicit_offset = 0\n",
    "        \n",
    "        for implicit in self.implicit_data[user_idx]:\n",
    "            implicit_tensor = torch.LongTensor([implicit]).to(device)\n",
    "            with torch.no_grad():\n",
    "                buj = self.Base(user, implicit_tensor)\n",
    "                \n",
    "            sum_of_item_weights += (int(self.R[user,implicit].data) - buj) * self.X(implicit_tensor)\n",
    "            sum_of_implicit_offset += self.Y(implicit_tensor)\n",
    "            \n",
    "        norm = len(self.implicit_data[user_idx]) ** -0.5        \n",
    "        \n",
    "        rui = bui + torch.sum(Q_i * (norm * (sum_of_item_weights + sum_of_implicit_offset)), dim = 1)\n",
    "        \n",
    "        return rui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVDPlusPlus(nn.Module):\n",
    "    def __init__(self, R, mu, F, is_layer=False):\n",
    "        super(SVDPlusPlus, self).__init__()\n",
    "        self.is_layer = is_layer\n",
    "        self.R = R \n",
    "        self.num_users, self.num_items = R.shape\n",
    "        self.Base = BaselineEstimates(self.num_users, self.num_items, mu)\n",
    "        \n",
    "        self.user_embedding = nn.Embedding(self.num_users, F)\n",
    "        self.item_embedding = nn.Embedding(self.num_items, F)\n",
    "        \n",
    "        self.Y = nn.Embedding(self.num_items, F)\n",
    "        \n",
    "        self.user_embedding.weight.data.normal_(0,1/F)\n",
    "        self.item_embedding.weight.data.normal_(0,1/F)\n",
    "        self.Y.weight.data.normal_(0,1/F)\n",
    "        self.get_implicit()\n",
    "        \n",
    "    def get_implicit(self):\n",
    "        self.implicit_data = {} \n",
    "        users, items = R.toarray().nonzero()\n",
    "        for user, item in zip(users, items):\n",
    "            if user not in self.implicit_data:\n",
    "                self.implicit_data[user] = []\n",
    "            self.implicit_data[user].append(item)\n",
    "        \n",
    "    def forward(self, user, item):\n",
    "        user_idx = int(user)\n",
    "        \n",
    "        bui = self.Base(user, item)\n",
    "        \n",
    "        P_u = self.user_embedding(user)\n",
    "        Q_i = self.item_embedding(item)\n",
    "        \n",
    "        sum_of_implicit_offset = 0\n",
    "        for implicit in self.implicit_data[user_idx]:\n",
    "            implicit_tensor = torch.LongTensor([implicit]).to(device)\n",
    "            sum_of_implicit_offset += self.Y(implicit_tensor)\n",
    "        \n",
    "        norm = len(self.implicit_data[user_idx]) ** -0.5\n",
    "        \n",
    "        if self.is_layer:\n",
    "            rui = torch.sum(P_u * (Q_i + norm * sum_of_implicit_offset), dim = 1)\n",
    "        else:\n",
    "            rui = bui + torch.sum(P_u * (Q_i + norm * sum_of_implicit_offset), dim = 1)\n",
    "        \n",
    "        return rui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntergratedModel(nn.Module):\n",
    "    def __init__(self, R, mu, F, k):\n",
    "        super(IntergratedModel, self).__init__()\n",
    "        self.neighbor = NeighborhoodModel(R,mu,k)\n",
    "        self.SVD = SVDPlusPlus(R,mu,F, is_layer=True)\n",
    "        \n",
    "        self.neighbor.get_implicit()\n",
    "        self.neighbor.get_top_k()\n",
    "        self.SVD.get_implicit()\n",
    "        \n",
    "    def forward(self, user, item):\n",
    "        rui = self.neighbor(user, item) + self.SVD(user, item)\n",
    "        \n",
    "        return rui"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 model | 0 epoch start\n",
      "3 model epoch: 0, train_loss: 0.7320651157961088, val_loss: 0.8166272692952101\n",
      "3 model | 1 epoch start\n",
      "3 model epoch: 1, train_loss: 0.5224120013170584, val_loss: 0.8025903856490808\n",
      "3 model | 2 epoch start\n",
      "3 model epoch: 2, train_loss: 0.48399020533229786, val_loss: 0.8014221069244849\n",
      "3 model | 3 epoch start\n",
      "3 model epoch: 3, train_loss: 0.4679526876029694, val_loss: 0.8053773985699615\n",
      "3 model | 4 epoch start\n",
      "3 model epoch: 4, train_loss: 0.4599326261347945, val_loss: 0.8029520039860228\n",
      "3 model | 5 epoch start\n",
      "3 model epoch: 5, train_loss: 0.45505499284093276, val_loss: 0.8057474320815282\n",
      "3 model | 6 epoch start\n",
      "3 model epoch: 6, train_loss: 0.45213195224590824, val_loss: 0.8070488541111683\n",
      "3 model | 7 epoch start\n",
      "3 model epoch: 7, train_loss: 0.4510357283332333, val_loss: 0.8070527789020878\n",
      "3 model | 8 epoch start\n",
      "3 model epoch: 8, train_loss: 0.4498033411166584, val_loss: 0.8073434048612655\n",
      "3 model | 9 epoch start\n",
      "3 model epoch: 9, train_loss: 0.44844342519255354, val_loss: 0.8035501294440291\n",
      "3 model | 10 epoch start\n",
      "3 model epoch: 10, train_loss: 0.4485244121286033, val_loss: 0.8050063312593503\n",
      "3 model | 11 epoch start\n",
      "3 model epoch: 11, train_loss: 0.44787137305555236, val_loss: 0.8063442435311894\n",
      "3 model | 12 epoch start\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/opt/ml/input/2023-Summer-Internship-DSAIL/Recsys/Netflix/train.ipynb 셀 20\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B101.101.218.32/opt/ml/input/2023-Summer-Internship-DSAIL/Recsys/Netflix/train.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m,\u001b[39m150\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B101.101.218.32/opt/ml/input/2023-Summer-Internship-DSAIL/Recsys/Netflix/train.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00midx\u001b[39m}\u001b[39;00m\u001b[39m model | \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m epoch start\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B101.101.218.32/opt/ml/input/2023-Summer-Internship-DSAIL/Recsys/Netflix/train.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m     train_loss \u001b[39m=\u001b[39m train(model, train_dataloader, criterion, optimizer)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B101.101.218.32/opt/ml/input/2023-Summer-Internship-DSAIL/Recsys/Netflix/train.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m     val_loss \u001b[39m=\u001b[39m evaluate(model, test_dataloader, criterion)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B101.101.218.32/opt/ml/input/2023-Summer-Internship-DSAIL/Recsys/Netflix/train.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00midx\u001b[39m}\u001b[39;00m\u001b[39m model epoch: \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m, train_loss: \u001b[39m\u001b[39m{\u001b[39;00mtrain_loss\u001b[39m}\u001b[39;00m\u001b[39m, val_loss: \u001b[39m\u001b[39m{\u001b[39;00mval_loss\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32m/opt/ml/input/2023-Summer-Internship-DSAIL/Recsys/Netflix/train.ipynb 셀 20\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, criterion, optimizer)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B101.101.218.32/opt/ml/input/2023-Summer-Internship-DSAIL/Recsys/Netflix/train.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m rating \u001b[39m=\u001b[39m rating\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B101.101.218.32/opt/ml/input/2023-Summer-Internship-DSAIL/Recsys/Netflix/train.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B101.101.218.32/opt/ml/input/2023-Summer-Internship-DSAIL/Recsys/Netflix/train.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m pred \u001b[39m=\u001b[39m model(user, item)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B101.101.218.32/opt/ml/input/2023-Summer-Internship-DSAIL/Recsys/Netflix/train.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(pred, rating)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B101.101.218.32/opt/ml/input/2023-Summer-Internship-DSAIL/Recsys/Netflix/train.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/opt/conda/envs/recbole/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/opt/ml/input/2023-Summer-Internship-DSAIL/Recsys/Netflix/train.ipynb 셀 20\u001b[0m in \u001b[0;36mAsymmetricSVD.forward\u001b[0;34m(self, user, item)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B101.101.218.32/opt/ml/input/2023-Summer-Internship-DSAIL/Recsys/Netflix/train.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B101.101.218.32/opt/ml/input/2023-Summer-Internship-DSAIL/Recsys/Netflix/train.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=34'>35</a>\u001b[0m         buj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mBase(user, implicit_tensor)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B101.101.218.32/opt/ml/input/2023-Summer-Internship-DSAIL/Recsys/Netflix/train.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=36'>37</a>\u001b[0m     sum_of_item_weights \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39mint\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mR[user,implicit]\u001b[39m.\u001b[39mdata) \u001b[39m-\u001b[39m buj) \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX(implicit_tensor)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B101.101.218.32/opt/ml/input/2023-Summer-Internship-DSAIL/Recsys/Netflix/train.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=37'>38</a>\u001b[0m     sum_of_implicit_offset \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mY(implicit_tensor)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B101.101.218.32/opt/ml/input/2023-Summer-Internship-DSAIL/Recsys/Netflix/train.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=39'>40</a>\u001b[0m norm \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimplicit_data[user_idx]) \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m-\u001b[39m\u001b[39m0.5\u001b[39m        \n",
      "File \u001b[0;32m/opt/conda/envs/recbole/lib/python3.8/site-packages/scipy/sparse/_index.py:76\u001b[0m, in \u001b[0;36mIndexMixin.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(col, INT_TYPES):\n\u001b[1;32m     75\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_on_1d_array_slice()\n\u001b[0;32m---> 76\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_arrayXint(row, col)\n\u001b[1;32m     77\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(col, \u001b[39mslice\u001b[39m):\n\u001b[1;32m     78\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_arrayXslice(row, col)\n",
      "File \u001b[0;32m/opt/conda/envs/recbole/lib/python3.8/site-packages/scipy/sparse/_csr.py:324\u001b[0m, in \u001b[0;36mcsr_matrix._get_arrayXint\u001b[0;34m(self, row, col)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_arrayXint\u001b[39m(\u001b[39mself\u001b[39m, row, col):\n\u001b[0;32m--> 324\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_major_index_fancy(row)\u001b[39m.\u001b[39m_get_submatrix(minor\u001b[39m=\u001b[39mcol)\n",
      "File \u001b[0;32m/opt/conda/envs/recbole/lib/python3.8/site-packages/scipy/sparse/_compressed.py:711\u001b[0m, in \u001b[0;36m_cs_matrix._major_index_fancy\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    707\u001b[0m res_data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty(nnz, dtype\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtype)\n\u001b[1;32m    708\u001b[0m csr_row_index(M, indices, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindptr, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata,\n\u001b[1;32m    709\u001b[0m               res_indices, res_data)\n\u001b[0;32m--> 711\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__class__\u001b[39;49m((res_data, res_indices, res_indptr),\n\u001b[1;32m    712\u001b[0m                       shape\u001b[39m=\u001b[39;49mnew_shape, copy\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[0;32m/opt/conda/envs/recbole/lib/python3.8/site-packages/scipy/sparse/_compressed.py:69\u001b[0m, in \u001b[0;36m_cs_matrix.__init__\u001b[0;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[1;32m     64\u001b[0m     maxval \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(shape)\n\u001b[1;32m     65\u001b[0m idx_dtype \u001b[39m=\u001b[39m get_index_dtype((indices, indptr),\n\u001b[1;32m     66\u001b[0m                             maxval\u001b[39m=\u001b[39mmaxval,\n\u001b[1;32m     67\u001b[0m                             check_contents\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> 69\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(indices, copy\u001b[39m=\u001b[39mcopy,\n\u001b[1;32m     70\u001b[0m                         dtype\u001b[39m=\u001b[39midx_dtype)\n\u001b[1;32m     71\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindptr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(indptr, copy\u001b[39m=\u001b[39mcopy, dtype\u001b[39m=\u001b[39midx_dtype)\n\u001b[1;32m     72\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(data, copy\u001b[39m=\u001b[39mcopy, dtype\u001b[39m=\u001b[39mdtype)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "summary = pd.read_csv('summary_with_10000user.csv')\n",
    "model = AsymmetricSVD(R, mu, F)\n",
    "model.get_implicit()\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01,weight_decay=0.001)\n",
    "criterion = RMSELoss\n",
    "early_stop_cnt = 0\n",
    "early_stop_loss = 100000\n",
    "idx = 3\n",
    "for epoch in range(0,150):\n",
    "    print(f'{idx} model | {epoch} epoch start')\n",
    "    train_loss = train(model, train_dataloader, criterion, optimizer)\n",
    "    val_loss = evaluate(model, test_dataloader, criterion)\n",
    "    \n",
    "    print(f'{idx} model epoch: {epoch}, train_loss: {train_loss}, val_loss: {val_loss}')\n",
    "    summary = pd.concat([summary, pd.DataFrame([[idx, epoch, train_loss, val_loss]], columns=['model', 'epoch', 'train_rmse', 'test_rmse'])])\n",
    "    \n",
    "    if early_stop_loss > val_loss:\n",
    "        early_stop_cnt = 0\n",
    "        early_stop_loss = val_loss\n",
    "    else:\n",
    "        early_stop_cnt += 1 \n",
    "        \n",
    "    if early_stop_loss < val_loss and early_stop_cnt > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 model | 0 epoch start\n",
      "0 model epoch: 0, train_loss: 0.7947843706805141, val_loss: 0.8426133349641028\n",
      "0 model | 1 epoch start\n",
      "0 model epoch: 1, train_loss: 0.3598788026932397, val_loss: 0.7712650429135254\n",
      "0 model | 2 epoch start\n",
      "0 model epoch: 2, train_loss: 0.3178387293911942, val_loss: 0.7626618496286546\n",
      "0 model | 3 epoch start\n",
      "0 model epoch: 3, train_loss: 0.31046705799605145, val_loss: 0.7623558970829867\n",
      "0 model | 4 epoch start\n",
      "0 model epoch: 4, train_loss: 0.30875893647714076, val_loss: 0.7615189188263898\n",
      "0 model | 5 epoch start\n",
      "0 model epoch: 5, train_loss: 0.3088090806006443, val_loss: 0.7597735770572772\n",
      "0 model | 6 epoch start\n",
      "0 model epoch: 6, train_loss: 0.3086766629163971, val_loss: 0.7621098483800143\n",
      "0 model | 7 epoch start\n",
      "0 model epoch: 7, train_loss: 0.3086436802870316, val_loss: 0.7607888448591054\n",
      "0 model | 8 epoch start\n",
      "0 model epoch: 8, train_loss: 0.3089161259212105, val_loss: 0.7608994148480405\n",
      "0 model | 9 epoch start\n",
      "0 model epoch: 9, train_loss: 0.30822309769598394, val_loss: 0.7634664187384932\n",
      "0 model | 10 epoch start\n",
      "0 model epoch: 10, train_loss: 0.3086568856059254, val_loss: 0.7609764543303382\n",
      "0 model | 11 epoch start\n",
      "0 model epoch: 11, train_loss: 0.3084549805768669, val_loss: 0.7601864072279998\n",
      "0 model | 12 epoch start\n",
      "0 model epoch: 12, train_loss: 0.3083894818558023, val_loss: 0.7600788303103397\n",
      "0 model | 13 epoch start\n",
      "0 model epoch: 13, train_loss: 0.30836946758406303, val_loss: 0.7617438950307274\n",
      "0 model | 14 epoch start\n",
      "0 model epoch: 14, train_loss: 0.30846884652878903, val_loss: 0.7631566406385882\n",
      "0 model | 15 epoch start\n",
      "0 model epoch: 15, train_loss: 0.3083061429850736, val_loss: 0.7607704563582289\n",
      "0 model | 16 epoch start\n",
      "0 model epoch: 16, train_loss: 0.30880100709332353, val_loss: 0.7629124993098323\n",
      "1 model | 0 epoch start\n",
      "1 model epoch: 0, train_loss: 1.0247561941485657, val_loss: 0.8523769595562408\n",
      "1 model | 1 epoch start\n",
      "1 model epoch: 1, train_loss: 0.8175998648205935, val_loss: 0.8005440617649773\n",
      "1 model | 2 epoch start\n",
      "1 model epoch: 2, train_loss: 0.7928466718198083, val_loss: 0.7927571650131523\n",
      "1 model | 3 epoch start\n",
      "1 model epoch: 3, train_loss: 0.7881435040204614, val_loss: 0.7934974039169661\n",
      "1 model | 4 epoch start\n",
      "1 model epoch: 4, train_loss: 0.7867454853975597, val_loss: 0.7925321027208378\n",
      "1 model | 5 epoch start\n",
      "1 model epoch: 5, train_loss: 0.7867070380993811, val_loss: 0.7921777183747971\n",
      "1 model | 6 epoch start\n",
      "1 model epoch: 6, train_loss: 0.7863060397400682, val_loss: 0.7929181950213415\n",
      "1 model | 7 epoch start\n",
      "1 model epoch: 7, train_loss: 0.7859157444321736, val_loss: 0.7941473036102953\n",
      "1 model | 8 epoch start\n",
      "1 model epoch: 8, train_loss: 0.7865936191815114, val_loss: 0.7908769140473656\n",
      "1 model | 9 epoch start\n",
      "1 model epoch: 9, train_loss: 0.7860633656885845, val_loss: 0.7946266045546236\n",
      "1 model | 10 epoch start\n",
      "1 model epoch: 10, train_loss: 0.7862676295433353, val_loss: 0.7930518048204118\n",
      "1 model | 11 epoch start\n",
      "1 model epoch: 11, train_loss: 0.7862230499420059, val_loss: 0.7942631116668388\n",
      "1 model | 12 epoch start\n",
      "1 model epoch: 12, train_loss: 0.7865185492378155, val_loss: 0.7929614756322331\n",
      "1 model | 13 epoch start\n",
      "1 model epoch: 13, train_loss: 0.7860418492648695, val_loss: 0.7923893181783993\n",
      "1 model | 14 epoch start\n",
      "1 model epoch: 14, train_loss: 0.7868906160077201, val_loss: 0.7927517044219137\n",
      "1 model | 15 epoch start\n",
      "1 model epoch: 15, train_loss: 0.786034051063766, val_loss: 0.7915656647325976\n",
      "1 model | 16 epoch start\n",
      "1 model epoch: 16, train_loss: 0.7858828856191624, val_loss: 0.7928122876992638\n",
      "1 model | 17 epoch start\n",
      "1 model epoch: 17, train_loss: 0.7864633213607685, val_loss: 0.7932946530908062\n",
      "1 model | 18 epoch start\n",
      "1 model epoch: 18, train_loss: 0.7859026207668127, val_loss: 0.7933499682138879\n",
      "1 model | 19 epoch start\n",
      "1 model epoch: 19, train_loss: 0.7860641406299526, val_loss: 0.7942526036475428\n",
      "2 model | 0 epoch start\n",
      "2 model epoch: 0, train_loss: 0.7916845358838722, val_loss: 0.8203115206068052\n",
      "2 model | 1 epoch start\n",
      "2 model epoch: 1, train_loss: 0.3547422417175907, val_loss: 0.7596816126220537\n",
      "2 model | 2 epoch start\n",
      "2 model epoch: 2, train_loss: 0.3107499210912101, val_loss: 0.7518955863235651\n",
      "2 model | 3 epoch start\n",
      "2 model epoch: 3, train_loss: 0.3025020699041829, val_loss: 0.7543032088456479\n",
      "2 model | 4 epoch start\n",
      "2 model epoch: 4, train_loss: 0.3006238310335854, val_loss: 0.7514212633565728\n",
      "2 model | 5 epoch start\n",
      "2 model epoch: 5, train_loss: 0.3010796626243353, val_loss: 0.7537773544650481\n",
      "2 model | 6 epoch start\n",
      "2 model epoch: 6, train_loss: 0.30035746544600456, val_loss: 0.7496436283697839\n",
      "2 model | 7 epoch start\n",
      "2 model epoch: 7, train_loss: 0.3003680051950336, val_loss: 0.7531299402782177\n",
      "2 model | 8 epoch start\n",
      "2 model epoch: 8, train_loss: 0.30020327982638484, val_loss: 0.7514994948556275\n",
      "2 model | 9 epoch start\n",
      "2 model epoch: 9, train_loss: 0.30066751824914084, val_loss: 0.7501830341953244\n",
      "2 model | 10 epoch start\n",
      "2 model epoch: 10, train_loss: 0.3006958573116433, val_loss: 0.7526940783966711\n",
      "2 model | 11 epoch start\n",
      "2 model epoch: 11, train_loss: 0.30026192598391555, val_loss: 0.7522491113697968\n",
      "2 model | 12 epoch start\n",
      "2 model epoch: 12, train_loss: 0.300501202547768, val_loss: 0.7500452694650729\n",
      "2 model | 13 epoch start\n",
      "2 model epoch: 13, train_loss: 0.3007848306862801, val_loss: 0.7521255050425222\n",
      "2 model | 14 epoch start\n",
      "2 model epoch: 14, train_loss: 0.30088849205482027, val_loss: 0.7526410644239173\n",
      "2 model | 15 epoch start\n",
      "2 model epoch: 15, train_loss: 0.3007666265423192, val_loss: 0.7519485887016198\n",
      "2 model | 16 epoch start\n",
      "2 model epoch: 16, train_loss: 0.3005030095328953, val_loss: 0.7506450098589738\n",
      "2 model | 17 epoch start\n",
      "2 model epoch: 17, train_loss: 0.300853214948116, val_loss: 0.7502214155251071\n"
     ]
    }
   ],
   "source": [
    "summary = pd.DataFrame(columns=['model', 'epoch', 'train_rmse', 'test_rmse'])\n",
    "models = [NeighborhoodModel(R,mu,k), SVDPlusPlus(R,mu,F), IntergratedModel(R,mu,F,k)]\n",
    "\n",
    "for idx, model in enumerate(models):\n",
    "    model = model.to(device) \n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01,weight_decay=0.001)\n",
    "    criterion = RMSELoss\n",
    "    early_stop_cnt = 0\n",
    "    early_stop_loss = 100000\n",
    "    for epoch in range(0,150):\n",
    "        print(f'{idx} model | {epoch} epoch start')\n",
    "        train_loss = train(model, train_dataloader, criterion, optimizer)\n",
    "        val_loss = evaluate(model, test_dataloader, criterion)\n",
    "        \n",
    "        print(f'{idx} model epoch: {epoch}, train_loss: {train_loss}, val_loss: {val_loss}')\n",
    "        summary = pd.concat([summary, pd.DataFrame([[idx, epoch, train_loss, val_loss]], columns=['model', 'epoch', 'train_rmse', 'test_rmse'])])\n",
    "        \n",
    "        if early_stop_loss > val_loss:\n",
    "            early_stop_cnt = 0\n",
    "            early_stop_loss = val_loss\n",
    "        else:\n",
    "            early_stop_cnt += 1 \n",
    "            \n",
    "        if early_stop_loss < val_loss and early_stop_cnt > 10:\n",
    "            break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporal Model Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalDynamics(nn.Module):\n",
    "    def __init__(self, R, F, mu, T):\n",
    "        super(TemporalDynamics, self).__init__()\n",
    "        self.R = R \n",
    "        self.mu = mu\n",
    "        self.num_users, self.num_items = R.shape\n",
    "        self.Q = nn.Embedding(self.num_items, F)\n",
    "        self.temporal_user_biases = nn.Parameter(torch.normal(0,1,size=(self.num_users, T)))\n",
    "        self.temporal_item_biases = nn.Parameter(torch.normal(0,1,size=(self.num_items, T)))\n",
    "        self.temporal_user_factors = nn.Parameter(torch.normal(0,1/F,size=(self.num_users, T, F)))\n",
    "        \n",
    "        \n",
    "    def forward(self, user, item, time_bin):\n",
    "        Q_i = self.Q(item)\n",
    "        P_ut = self.temporal_user_factors[user,time_bin,:]\n",
    "        \n",
    "        but = self.temporal_user_biases[user,time_bin]\n",
    "        bit = self.temporal_item_biases[item,time_bin]\n",
    "    \n",
    "\n",
    "        rui = self.mu + torch.squeeze(but) + torch.squeeze(bit) + torch.sum(Q_i * P_ut, dim = 1)\n",
    "        \n",
    "        return rui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Temporal_Netflix(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.users = self.df['Cust_ID'].values\n",
    "        self.items = self.df['Movie_Id'].values\n",
    "        self.ratings = self.df['Rating'].values\n",
    "        self.time = self.df['bins'].values\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        user = self.users[index]\n",
    "        item = self.items[index]\n",
    "        time = self.time[index]\n",
    "\n",
    "        rating = self.ratings[index]\n",
    "        \n",
    "        return user, item,time, rating\n",
    "    \n",
    "def temporal_train(model, train_loader):\n",
    "    model.train() \n",
    "    total_loss = 0 \n",
    "    for user, item, time,rating in train_loader:\n",
    "        user = user.to(device)\n",
    "        item = item.to(device)\n",
    "        time = time.to(device)\n",
    "        rating = rating.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        pred = model(user, item,time)\n",
    "        loss = criterion(pred, rating)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    total_loss = total_loss / len(train_loader)\n",
    "    \n",
    "    return total_loss\n",
    "\n",
    "def temporal_evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for user, item, time,rating in test_loader:\n",
    "            user = user.to(device)\n",
    "            item = item.to(device)\n",
    "            time = time.to(device)\n",
    "            rating = rating.to(device)\n",
    "\n",
    "            pred = model(user, item,time)\n",
    "            loss = criterion(pred, rating)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(test_loader)\n",
    "\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Temporal_Netflix(temporal_train_df)\n",
    "test_dataset = Temporal_Netflix(temporal_test_df)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 epoch start\n",
      "model epoch: 0, train_loss: 1.1588983413921712, val_loss: 0.9978441043604176\n",
      "1 epoch start\n",
      "model epoch: 1, train_loss: 0.9350918661978832, val_loss: 0.939495644723088\n",
      "2 epoch start\n",
      "model epoch: 2, train_loss: 0.9164878167127912, val_loss: 0.9293509276474643\n",
      "3 epoch start\n",
      "model epoch: 3, train_loss: 0.9119749419117924, val_loss: 0.9256476845200995\n",
      "4 epoch start\n",
      "model epoch: 4, train_loss: 0.9105434819861761, val_loss: 0.9249227700910538\n",
      "5 epoch start\n",
      "model epoch: 5, train_loss: 0.9098915659558795, val_loss: 0.9247681179052938\n",
      "6 epoch start\n",
      "model epoch: 6, train_loss: 0.9098770002461978, val_loss: 0.9243884682618714\n",
      "7 epoch start\n",
      "model epoch: 7, train_loss: 0.9099273049964394, val_loss: 0.9244546344045707\n",
      "8 epoch start\n",
      "model epoch: 8, train_loss: 0.9095748652809786, val_loss: 0.9245960744519783\n",
      "9 epoch start\n",
      "model epoch: 9, train_loss: 0.9098863587048485, val_loss: 0.9241361260797243\n",
      "10 epoch start\n"
     ]
    }
   ],
   "source": [
    "T = sample_df['bins'].nunique()\n",
    "\n",
    "model = TemporalDynamics(R,F,mu,T)\n",
    "\n",
    "model = model.to(device) \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, weight_decay=0.001)\n",
    "criterion = RMSELoss\n",
    "early_stop_cnt = 0\n",
    "early_stop_loss = 100000\n",
    "for epoch in range(0,70):\n",
    "    print(f'{epoch} epoch start')\n",
    "    train_loss = temporal_train(model, train_dataloader)\n",
    "    val_loss = temporal_evaluate(model, test_dataloader)\n",
    "    \n",
    "    print(f'model epoch: {epoch}, train_loss: {train_loss}, val_loss: {val_loss}')\n",
    "    summary = pd.concat([summary, pd.DataFrame([[4, epoch, train_loss, val_loss]], columns=['model', 'epoch', 'train_rmse', 'test_rmse'])])\n",
    "    \n",
    "    if early_stop_loss > val_loss:\n",
    "        early_stop_cnt = 0\n",
    "        early_stop_loss = val_loss\n",
    "    else:\n",
    "        early_stop_cnt += 1 \n",
    "        \n",
    "    if early_stop_loss < val_loss and early_stop_cnt > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.to_csv('summary_with_20000user.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_rmse</th>\n",
       "      <th>test_rmse</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.143589</td>\n",
       "      <td>0.495449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.393381</td>\n",
       "      <td>0.691296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.110757</td>\n",
       "      <td>0.520523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.343014</td>\n",
       "      <td>0.907792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       train_rmse  test_rmse\n",
       "model                       \n",
       "0        0.143589   0.495449\n",
       "1        0.393381   0.691296\n",
       "2        0.110757   0.520523\n",
       "4        0.343014   0.907792"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary.groupby('model').agg({'train_rmse':'min', 'test_rmse':'min'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_rmse</th>\n",
       "      <th>test_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.794784</td>\n",
       "      <td>0.842613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.359879</td>\n",
       "      <td>0.771265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.317839</td>\n",
       "      <td>0.762662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.310467</td>\n",
       "      <td>0.762356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.308759</td>\n",
       "      <td>0.761519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.308809</td>\n",
       "      <td>0.759774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.308677</td>\n",
       "      <td>0.762110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.308644</td>\n",
       "      <td>0.760789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.308916</td>\n",
       "      <td>0.760899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.308223</td>\n",
       "      <td>0.763466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.308657</td>\n",
       "      <td>0.760976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.308455</td>\n",
       "      <td>0.760186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.308389</td>\n",
       "      <td>0.760079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0.308369</td>\n",
       "      <td>0.761744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0.308469</td>\n",
       "      <td>0.763157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0.308306</td>\n",
       "      <td>0.760770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.308801</td>\n",
       "      <td>0.762912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.024756</td>\n",
       "      <td>0.852377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.817600</td>\n",
       "      <td>0.800544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.792847</td>\n",
       "      <td>0.792757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.788144</td>\n",
       "      <td>0.793497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.786745</td>\n",
       "      <td>0.792532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.786707</td>\n",
       "      <td>0.792178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.786306</td>\n",
       "      <td>0.792918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.785916</td>\n",
       "      <td>0.794147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.786594</td>\n",
       "      <td>0.790877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.786063</td>\n",
       "      <td>0.794627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.786268</td>\n",
       "      <td>0.793052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0.786223</td>\n",
       "      <td>0.794263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.786519</td>\n",
       "      <td>0.792961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0.786042</td>\n",
       "      <td>0.792389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0.786891</td>\n",
       "      <td>0.792752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.786034</td>\n",
       "      <td>0.791566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0.785883</td>\n",
       "      <td>0.792812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0.786463</td>\n",
       "      <td>0.793295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0.785903</td>\n",
       "      <td>0.793350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0.786064</td>\n",
       "      <td>0.794253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.791685</td>\n",
       "      <td>0.820312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.354742</td>\n",
       "      <td>0.759682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.310750</td>\n",
       "      <td>0.751896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.302502</td>\n",
       "      <td>0.754303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.300624</td>\n",
       "      <td>0.751421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.301080</td>\n",
       "      <td>0.753777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.300357</td>\n",
       "      <td>0.749644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0.300368</td>\n",
       "      <td>0.753130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0.300203</td>\n",
       "      <td>0.751499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0.300668</td>\n",
       "      <td>0.750183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.300696</td>\n",
       "      <td>0.752694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0.300262</td>\n",
       "      <td>0.752249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0.300501</td>\n",
       "      <td>0.750045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0.300785</td>\n",
       "      <td>0.752126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>0.300888</td>\n",
       "      <td>0.752641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>0.300767</td>\n",
       "      <td>0.751949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0.300503</td>\n",
       "      <td>0.750645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>0.300853</td>\n",
       "      <td>0.750221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model epoch  train_rmse  test_rmse\n",
       "0     0     0    0.794784   0.842613\n",
       "0     0     1    0.359879   0.771265\n",
       "0     0     2    0.317839   0.762662\n",
       "0     0     3    0.310467   0.762356\n",
       "0     0     4    0.308759   0.761519\n",
       "0     0     5    0.308809   0.759774\n",
       "0     0     6    0.308677   0.762110\n",
       "0     0     7    0.308644   0.760789\n",
       "0     0     8    0.308916   0.760899\n",
       "0     0     9    0.308223   0.763466\n",
       "0     0    10    0.308657   0.760976\n",
       "0     0    11    0.308455   0.760186\n",
       "0     0    12    0.308389   0.760079\n",
       "0     0    13    0.308369   0.761744\n",
       "0     0    14    0.308469   0.763157\n",
       "0     0    15    0.308306   0.760770\n",
       "0     0    16    0.308801   0.762912\n",
       "0     1     0    1.024756   0.852377\n",
       "0     1     1    0.817600   0.800544\n",
       "0     1     2    0.792847   0.792757\n",
       "0     1     3    0.788144   0.793497\n",
       "0     1     4    0.786745   0.792532\n",
       "0     1     5    0.786707   0.792178\n",
       "0     1     6    0.786306   0.792918\n",
       "0     1     7    0.785916   0.794147\n",
       "0     1     8    0.786594   0.790877\n",
       "0     1     9    0.786063   0.794627\n",
       "0     1    10    0.786268   0.793052\n",
       "0     1    11    0.786223   0.794263\n",
       "0     1    12    0.786519   0.792961\n",
       "0     1    13    0.786042   0.792389\n",
       "0     1    14    0.786891   0.792752\n",
       "0     1    15    0.786034   0.791566\n",
       "0     1    16    0.785883   0.792812\n",
       "0     1    17    0.786463   0.793295\n",
       "0     1    18    0.785903   0.793350\n",
       "0     1    19    0.786064   0.794253\n",
       "0     2     0    0.791685   0.820312\n",
       "0     2     1    0.354742   0.759682\n",
       "0     2     2    0.310750   0.751896\n",
       "0     2     3    0.302502   0.754303\n",
       "0     2     4    0.300624   0.751421\n",
       "0     2     5    0.301080   0.753777\n",
       "0     2     6    0.300357   0.749644\n",
       "0     2     7    0.300368   0.753130\n",
       "0     2     8    0.300203   0.751499\n",
       "0     2     9    0.300668   0.750183\n",
       "0     2    10    0.300696   0.752694\n",
       "0     2    11    0.300262   0.752249\n",
       "0     2    12    0.300501   0.750045\n",
       "0     2    13    0.300785   0.752126\n",
       "0     2    14    0.300888   0.752641\n",
       "0     2    15    0.300767   0.751949\n",
       "0     2    16    0.300503   0.750645\n",
       "0     2    17    0.300853   0.750221"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 model | 0 epoch start\n",
      "0 model epoch: 0, train_loss: 1.3408062031743364, val_loss: 1.2343095534505546\n",
      "0 model | 1 epoch start\n",
      "0 model epoch: 1, train_loss: 0.870291771758033, val_loss: 1.0616667870821468\n",
      "0 model | 2 epoch start\n",
      "0 model epoch: 2, train_loss: 0.6509648654441307, val_loss: 0.9572716262857647\n",
      "0 model | 3 epoch start\n",
      "0 model epoch: 3, train_loss: 0.5221291180559742, val_loss: 0.891603656858786\n",
      "0 model | 4 epoch start\n",
      "0 model epoch: 4, train_loss: 0.4390028937857809, val_loss: 0.8504392013570943\n",
      "0 model | 5 epoch start\n",
      "0 model epoch: 5, train_loss: 0.379468073676493, val_loss: 0.8117040222101667\n",
      "0 model | 6 epoch start\n",
      "0 model epoch: 6, train_loss: 0.33586110169076355, val_loss: 0.7821918901973912\n",
      "0 model | 7 epoch start\n",
      "0 model epoch: 7, train_loss: 0.30322334351387786, val_loss: 0.7589800064003424\n",
      "0 model | 8 epoch start\n",
      "0 model epoch: 8, train_loss: 0.27811256926170164, val_loss: 0.732978934327587\n",
      "0 model | 9 epoch start\n",
      "0 model epoch: 9, train_loss: 0.2589141240241999, val_loss: 0.7194089542008374\n",
      "0 model | 10 epoch start\n",
      "0 model epoch: 10, train_loss: 0.24457136704503854, val_loss: 0.7070437675301603\n",
      "0 model | 11 epoch start\n",
      "0 model epoch: 11, train_loss: 0.23346487153495168, val_loss: 0.6926521448914159\n",
      "0 model | 12 epoch start\n",
      "0 model epoch: 12, train_loss: 0.22505176359257958, val_loss: 0.6830858138792306\n",
      "0 model | 13 epoch start\n",
      "0 model epoch: 13, train_loss: 0.21849075108370222, val_loss: 0.6736800653563448\n",
      "0 model | 14 epoch start\n",
      "0 model epoch: 14, train_loss: 0.21297227048394635, val_loss: 0.6663538790747823\n",
      "0 model | 15 epoch start\n",
      "0 model epoch: 15, train_loss: 0.2079236193598283, val_loss: 0.6616084681698947\n",
      "0 model | 16 epoch start\n",
      "0 model epoch: 16, train_loss: 0.20478781567570908, val_loss: 0.6574241375739548\n",
      "0 model | 17 epoch start\n",
      "0 model epoch: 17, train_loss: 0.20200454872370743, val_loss: 0.6543511188675071\n",
      "0 model | 18 epoch start\n",
      "0 model epoch: 18, train_loss: 0.19902656049642958, val_loss: 0.651230334738538\n",
      "0 model | 19 epoch start\n",
      "0 model epoch: 19, train_loss: 0.19703899396368665, val_loss: 0.6482496298391115\n",
      "0 model | 20 epoch start\n",
      "0 model epoch: 20, train_loss: 0.19522628148714183, val_loss: 0.6476416587742936\n",
      "0 model | 21 epoch start\n",
      "0 model epoch: 21, train_loss: 0.1937495114793588, val_loss: 0.645432247516069\n",
      "0 model | 22 epoch start\n",
      "0 model epoch: 22, train_loss: 0.19287157943351552, val_loss: 0.6424260245503794\n",
      "0 model | 23 epoch start\n",
      "0 model epoch: 23, train_loss: 0.19188508722853295, val_loss: 0.6427120353017232\n",
      "0 model | 24 epoch start\n",
      "0 model epoch: 24, train_loss: 0.19008530742400293, val_loss: 0.6434159284238372\n",
      "0 model | 25 epoch start\n",
      "0 model epoch: 25, train_loss: 0.19029115740754562, val_loss: 0.6421867794505425\n",
      "0 model | 26 epoch start\n",
      "0 model epoch: 26, train_loss: 0.18932599243302758, val_loss: 0.64207076217039\n",
      "0 model | 27 epoch start\n",
      "0 model epoch: 27, train_loss: 0.18892349204287848, val_loss: 0.6395834529263817\n",
      "0 model | 28 epoch start\n",
      "0 model epoch: 28, train_loss: 0.18824903268467094, val_loss: 0.6373390598369403\n",
      "0 model | 29 epoch start\n",
      "0 model epoch: 29, train_loss: 0.1874590536472024, val_loss: 0.6411316535015831\n",
      "0 model | 30 epoch start\n",
      "0 model epoch: 30, train_loss: 0.18775786440979547, val_loss: 0.6396753041267388\n",
      "0 model | 31 epoch start\n",
      "0 model epoch: 31, train_loss: 0.18698515153834674, val_loss: 0.6375660981661879\n",
      "0 model | 32 epoch start\n",
      "0 model epoch: 32, train_loss: 0.1867663282886051, val_loss: 0.637241260854313\n",
      "0 model | 33 epoch start\n",
      "0 model epoch: 33, train_loss: 0.18664464384835897, val_loss: 0.6391689937988282\n",
      "0 model | 34 epoch start\n",
      "0 model epoch: 34, train_loss: 0.18639709673021299, val_loss: 0.6380843997700861\n",
      "0 model | 35 epoch start\n",
      "0 model epoch: 35, train_loss: 0.18635800882653633, val_loss: 0.6347796857577147\n",
      "0 model | 36 epoch start\n",
      "0 model epoch: 36, train_loss: 0.18646014192208885, val_loss: 0.6383480402084301\n",
      "0 model | 37 epoch start\n",
      "0 model epoch: 37, train_loss: 0.18604942793510454, val_loss: 0.6374325048702336\n",
      "0 model | 38 epoch start\n",
      "0 model epoch: 38, train_loss: 0.18587239898855815, val_loss: 0.6379027532698124\n",
      "0 model | 39 epoch start\n",
      "0 model epoch: 39, train_loss: 0.185550357254345, val_loss: 0.6359531888357\n",
      "0 model | 40 epoch start\n",
      "0 model epoch: 40, train_loss: 0.18541988690023606, val_loss: 0.6374514930534847\n",
      "0 model | 41 epoch start\n",
      "0 model epoch: 41, train_loss: 0.18539350981683062, val_loss: 0.6340364451604251\n",
      "0 model | 42 epoch start\n",
      "0 model epoch: 42, train_loss: 0.18523308347689305, val_loss: 0.6346656563659822\n",
      "0 model | 43 epoch start\n",
      "0 model epoch: 43, train_loss: 0.18516854127119506, val_loss: 0.6369654802957718\n",
      "0 model | 44 epoch start\n",
      "0 model epoch: 44, train_loss: 0.18502799365026376, val_loss: 0.6372166422916925\n",
      "0 model | 45 epoch start\n",
      "0 model epoch: 45, train_loss: 0.18488913139899532, val_loss: 0.6340606786774208\n",
      "0 model | 46 epoch start\n",
      "0 model epoch: 46, train_loss: 0.18482953639854444, val_loss: 0.6365166810849119\n",
      "0 model | 47 epoch start\n",
      "0 model epoch: 47, train_loss: 0.18527941517899588, val_loss: 0.6365839562276148\n",
      "0 model | 48 epoch start\n",
      "0 model epoch: 48, train_loss: 0.18500867427196985, val_loss: 0.6339771781853052\n",
      "0 model | 49 epoch start\n",
      "0 model epoch: 49, train_loss: 0.18506976109381437, val_loss: 0.6359735944802408\n",
      "0 model | 50 epoch start\n",
      "0 model epoch: 50, train_loss: 0.1848363502190701, val_loss: 0.6354592275203929\n",
      "0 model | 51 epoch start\n",
      "0 model epoch: 51, train_loss: 0.1847483914569711, val_loss: 0.6331194510976624\n",
      "0 model | 52 epoch start\n",
      "0 model epoch: 52, train_loss: 0.18475595656200225, val_loss: 0.6338247144720368\n",
      "0 model | 53 epoch start\n",
      "0 model epoch: 53, train_loss: 0.1845928135551613, val_loss: 0.6358971344039372\n",
      "0 model | 54 epoch start\n",
      "0 model epoch: 54, train_loss: 0.18456683494956969, val_loss: 0.6326759369265736\n",
      "0 model | 55 epoch start\n",
      "0 model epoch: 55, train_loss: 0.18474961094363346, val_loss: 0.6346525451668082\n",
      "0 model | 56 epoch start\n",
      "0 model epoch: 56, train_loss: 0.18498013943575853, val_loss: 0.6329022346359695\n",
      "0 model | 57 epoch start\n",
      "0 model epoch: 57, train_loss: 0.18488595726821563, val_loss: 0.6360210851029678\n",
      "0 model | 58 epoch start\n",
      "0 model epoch: 58, train_loss: 0.18490762990866957, val_loss: 0.6335440419985298\n",
      "0 model | 59 epoch start\n",
      "0 model epoch: 59, train_loss: 0.18462665863115232, val_loss: 0.6331134681985788\n",
      "0 model | 60 epoch start\n",
      "0 model epoch: 60, train_loss: 0.18458028387669403, val_loss: 0.6329337750435345\n",
      "0 model | 61 epoch start\n",
      "0 model epoch: 61, train_loss: 0.18478713636564736, val_loss: 0.6338373210043667\n",
      "0 model | 62 epoch start\n",
      "0 model epoch: 62, train_loss: 0.1849303566698877, val_loss: 0.6338617960436984\n",
      "0 model | 63 epoch start\n",
      "0 model epoch: 63, train_loss: 0.18494917802076377, val_loss: 0.631419131073911\n",
      "0 model | 64 epoch start\n",
      "0 model epoch: 64, train_loss: 0.18445761404932368, val_loss: 0.6346175589637129\n",
      "0 model | 65 epoch start\n",
      "0 model epoch: 65, train_loss: 0.18466140464276526, val_loss: 0.6324164362049499\n",
      "0 model | 66 epoch start\n",
      "0 model epoch: 66, train_loss: 0.18493063847433097, val_loss: 0.6333829820635164\n",
      "0 model | 67 epoch start\n",
      "0 model epoch: 67, train_loss: 0.1846823298190277, val_loss: 0.6316852159626879\n",
      "0 model | 68 epoch start\n",
      "0 model epoch: 68, train_loss: 0.18458786743235617, val_loss: 0.6341549251159222\n",
      "0 model | 69 epoch start\n",
      "0 model epoch: 69, train_loss: 0.1846931310219676, val_loss: 0.634461126667915\n",
      "0 model | 70 epoch start\n",
      "0 model epoch: 70, train_loss: 0.1849689551977647, val_loss: 0.6313304851593161\n",
      "0 model | 71 epoch start\n",
      "0 model epoch: 71, train_loss: 0.18437205878032142, val_loss: 0.6336218409202974\n",
      "0 model | 72 epoch start\n",
      "0 model epoch: 72, train_loss: 0.18454910292231158, val_loss: 0.6327359254496263\n",
      "0 model | 73 epoch start\n",
      "0 model epoch: 73, train_loss: 0.18449039663430622, val_loss: 0.6336885277382781\n",
      "0 model | 74 epoch start\n",
      "0 model epoch: 74, train_loss: 0.18483958277231793, val_loss: 0.6334562357062331\n",
      "0 model | 75 epoch start\n",
      "0 model epoch: 75, train_loss: 0.18480863088886781, val_loss: 0.6345114166803832\n",
      "0 model | 76 epoch start\n",
      "0 model epoch: 76, train_loss: 0.18482952521705973, val_loss: 0.6345708469963502\n",
      "0 model | 77 epoch start\n",
      "0 model epoch: 77, train_loss: 0.18485627183097986, val_loss: 0.6322153366343536\n",
      "0 model | 78 epoch start\n",
      "0 model epoch: 78, train_loss: 0.18538132336228633, val_loss: 0.6346927097356855\n",
      "0 model | 79 epoch start\n",
      "0 model epoch: 79, train_loss: 0.18483527369922464, val_loss: 0.6331901555922921\n",
      "0 model | 80 epoch start\n",
      "0 model epoch: 80, train_loss: 0.18466564369710944, val_loss: 0.6336813285356133\n",
      "0 model | 81 epoch start\n",
      "0 model epoch: 81, train_loss: 0.1848857127865061, val_loss: 0.6333320738753607\n",
      "1 model | 0 epoch start\n",
      "1 model epoch: 0, train_loss: 1.2598913856825171, val_loss: 1.0649602979573798\n",
      "1 model | 1 epoch start\n",
      "1 model epoch: 1, train_loss: 1.1011250010731055, val_loss: 0.9827810570596863\n",
      "1 model | 2 epoch start\n",
      "1 model epoch: 2, train_loss: 1.0071686323119058, val_loss: 0.9136878965527137\n",
      "1 model | 3 epoch start\n",
      "1 model epoch: 3, train_loss: 0.9264020851571159, val_loss: 0.8558537667350459\n",
      "1 model | 4 epoch start\n",
      "1 model epoch: 4, train_loss: 0.8509588172575393, val_loss: 0.8017936281548983\n",
      "1 model | 5 epoch start\n",
      "1 model epoch: 5, train_loss: 0.782792963220685, val_loss: 0.7680695969715232\n",
      "1 model | 6 epoch start\n",
      "1 model epoch: 6, train_loss: 0.732969935770277, val_loss: 0.740692506002412\n",
      "1 model | 7 epoch start\n",
      "1 model epoch: 7, train_loss: 0.69805749739043, val_loss: 0.7294102730473893\n",
      "1 model | 8 epoch start\n",
      "1 model epoch: 8, train_loss: 0.6757596011561079, val_loss: 0.7189548651371263\n",
      "1 model | 9 epoch start\n",
      "1 model epoch: 9, train_loss: 0.6584735387009137, val_loss: 0.7173124206745364\n",
      "1 model | 10 epoch start\n",
      "1 model epoch: 10, train_loss: 0.6447426533882009, val_loss: 0.713820177619865\n",
      "1 model | 11 epoch start\n",
      "1 model epoch: 11, train_loss: 0.632373655597828, val_loss: 0.7067235938853219\n",
      "1 model | 12 epoch start\n",
      "1 model epoch: 12, train_loss: 0.6218601075349729, val_loss: 0.7050680963152506\n",
      "1 model | 13 epoch start\n",
      "1 model epoch: 13, train_loss: 0.6097369599268546, val_loss: 0.7051220979407787\n",
      "1 model | 14 epoch start\n",
      "1 model epoch: 14, train_loss: 0.5995496486170139, val_loss: 0.7030718781849302\n",
      "1 model | 15 epoch start\n",
      "1 model epoch: 15, train_loss: 0.5862985449340383, val_loss: 0.7039982721595708\n",
      "1 model | 16 epoch start\n",
      "1 model epoch: 16, train_loss: 0.5742394762389074, val_loss: 0.6997612466045742\n",
      "1 model | 17 epoch start\n",
      "1 model epoch: 17, train_loss: 0.5605408025244891, val_loss: 0.7004126092298161\n",
      "1 model | 18 epoch start\n",
      "1 model epoch: 18, train_loss: 0.5505499472809157, val_loss: 0.7005309279269669\n",
      "1 model | 19 epoch start\n",
      "1 model epoch: 19, train_loss: 0.5365998647613227, val_loss: 0.7002236282354006\n",
      "1 model | 20 epoch start\n",
      "1 model epoch: 20, train_loss: 0.5258208962150932, val_loss: 0.699012195620194\n",
      "1 model | 21 epoch start\n",
      "1 model epoch: 21, train_loss: 0.5157039271847825, val_loss: 0.6998822998551245\n",
      "1 model | 22 epoch start\n",
      "1 model epoch: 22, train_loss: 0.5066236656215206, val_loss: 0.7008882868188799\n",
      "1 model | 23 epoch start\n",
      "1 model epoch: 23, train_loss: 0.49684047451087915, val_loss: 0.70234671023603\n",
      "1 model | 24 epoch start\n",
      "1 model epoch: 24, train_loss: 0.4900583462854216, val_loss: 0.701715431192573\n",
      "1 model | 25 epoch start\n",
      "1 model epoch: 25, train_loss: 0.48414778837770267, val_loss: 0.6988782678126807\n",
      "1 model | 26 epoch start\n",
      "1 model epoch: 26, train_loss: 0.477886378181919, val_loss: 0.7002798212363629\n",
      "1 model | 27 epoch start\n",
      "1 model epoch: 27, train_loss: 0.4722867144705349, val_loss: 0.6979919476608872\n",
      "1 model | 28 epoch start\n",
      "1 model epoch: 28, train_loss: 0.4670109345841955, val_loss: 0.7043679972241554\n",
      "1 model | 29 epoch start\n",
      "1 model epoch: 29, train_loss: 0.4615167263689795, val_loss: 0.7054444671847038\n",
      "1 model | 30 epoch start\n",
      "1 model epoch: 30, train_loss: 0.45618594004333396, val_loss: 0.7046732639479468\n",
      "1 model | 31 epoch start\n",
      "1 model epoch: 31, train_loss: 0.4509138401625252, val_loss: 0.7037027451902859\n",
      "1 model | 32 epoch start\n",
      "1 model epoch: 32, train_loss: 0.4455217262723137, val_loss: 0.7054429704790415\n",
      "1 model | 33 epoch start\n",
      "1 model epoch: 33, train_loss: 0.443103066802761, val_loss: 0.703442747135382\n",
      "1 model | 34 epoch start\n",
      "1 model epoch: 34, train_loss: 0.4357383259662743, val_loss: 0.7041893373690462\n",
      "1 model | 35 epoch start\n",
      "1 model epoch: 35, train_loss: 0.43282040958294443, val_loss: 0.7077269861315185\n",
      "1 model | 36 epoch start\n",
      "1 model epoch: 36, train_loss: 0.4285543002886839, val_loss: 0.7056338416875432\n",
      "1 model | 37 epoch start\n",
      "1 model epoch: 37, train_loss: 0.423665538092475, val_loss: 0.70606151290335\n",
      "1 model | 38 epoch start\n",
      "1 model epoch: 38, train_loss: 0.4194853299454809, val_loss: 0.706543624280039\n",
      "2 model | 0 epoch start\n",
      "2 model epoch: 0, train_loss: 1.3472435285694402, val_loss: 1.2027245383333636\n",
      "2 model | 1 epoch start\n",
      "2 model epoch: 1, train_loss: 0.8050561251647304, val_loss: 1.0502100790303752\n",
      "2 model | 2 epoch start\n",
      "2 model epoch: 2, train_loss: 0.6060842815905182, val_loss: 0.9584684684445745\n",
      "2 model | 3 epoch start\n",
      "2 model epoch: 3, train_loss: 0.4892148763240331, val_loss: 0.8954497047711362\n",
      "2 model | 4 epoch start\n",
      "2 model epoch: 4, train_loss: 0.41424938097857955, val_loss: 0.8400659637844331\n",
      "2 model | 5 epoch start\n",
      "2 model epoch: 5, train_loss: 0.36071996449725213, val_loss: 0.8069137646394319\n",
      "2 model | 6 epoch start\n",
      "2 model epoch: 6, train_loss: 0.3206519322504609, val_loss: 0.7805233085996715\n",
      "2 model | 7 epoch start\n",
      "2 model epoch: 7, train_loss: 0.289410350752264, val_loss: 0.7582115526423017\n",
      "2 model | 8 epoch start\n",
      "2 model epoch: 8, train_loss: 0.2642468062237238, val_loss: 0.7347148398396626\n",
      "2 model | 9 epoch start\n",
      "2 model epoch: 9, train_loss: 0.24420918524413587, val_loss: 0.7273865004040695\n",
      "2 model | 10 epoch start\n",
      "2 model epoch: 10, train_loss: 0.22906017337976786, val_loss: 0.7084966633800773\n",
      "2 model | 11 epoch start\n",
      "2 model epoch: 11, train_loss: 0.21588402011339483, val_loss: 0.7009965617638583\n",
      "2 model | 12 epoch start\n",
      "2 model epoch: 12, train_loss: 0.20455412708884946, val_loss: 0.6947055307093898\n",
      "2 model | 13 epoch start\n",
      "2 model epoch: 13, train_loss: 0.1952283912260426, val_loss: 0.6852037056790873\n",
      "2 model | 14 epoch start\n",
      "2 model epoch: 14, train_loss: 0.18717014091668377, val_loss: 0.68219572295617\n",
      "2 model | 15 epoch start\n",
      "2 model epoch: 15, train_loss: 0.18091954897316348, val_loss: 0.6769140647093757\n",
      "2 model | 16 epoch start\n",
      "2 model epoch: 16, train_loss: 0.1755053877958938, val_loss: 0.6728770114598697\n",
      "2 model | 17 epoch start\n",
      "2 model epoch: 17, train_loss: 0.17016835447198492, val_loss: 0.6679959352765962\n",
      "2 model | 18 epoch start\n",
      "2 model epoch: 18, train_loss: 0.16600583374159583, val_loss: 0.6697771729190563\n",
      "2 model | 19 epoch start\n",
      "2 model epoch: 19, train_loss: 0.16164853770538765, val_loss: 0.6715318144485634\n",
      "2 model | 20 epoch start\n",
      "2 model epoch: 20, train_loss: 0.15890650649208807, val_loss: 0.6684245736868296\n",
      "2 model | 21 epoch start\n",
      "2 model epoch: 21, train_loss: 0.154760024874787, val_loss: 0.6660320855001818\n",
      "2 model | 22 epoch start\n",
      "2 model epoch: 22, train_loss: 0.1520239980323012, val_loss: 0.6677953171121828\n",
      "2 model | 23 epoch start\n",
      "2 model epoch: 23, train_loss: 0.1498048512255862, val_loss: 0.6586647153369315\n",
      "2 model | 24 epoch start\n",
      "2 model epoch: 24, train_loss: 0.14729695293871853, val_loss: 0.6632516929198998\n",
      "2 model | 25 epoch start\n",
      "2 model epoch: 25, train_loss: 0.1456733518184182, val_loss: 0.6631202771548997\n",
      "2 model | 26 epoch start\n",
      "2 model epoch: 26, train_loss: 0.14341070176448414, val_loss: 0.6661969853214267\n",
      "2 model | 27 epoch start\n",
      "2 model epoch: 27, train_loss: 0.14174038196662392, val_loss: 0.6611938386647231\n",
      "2 model | 28 epoch start\n",
      "2 model epoch: 28, train_loss: 0.14064096456155384, val_loss: 0.6627861998812439\n",
      "2 model | 29 epoch start\n",
      "2 model epoch: 29, train_loss: 0.1383488068779209, val_loss: 0.6654895557841314\n",
      "2 model | 30 epoch start\n",
      "2 model epoch: 30, train_loss: 0.1369261175462457, val_loss: 0.6612968644248228\n",
      "2 model | 31 epoch start\n",
      "2 model epoch: 31, train_loss: 0.13629828148479498, val_loss: 0.6611064046685812\n",
      "2 model | 32 epoch start\n",
      "2 model epoch: 32, train_loss: 0.13490414004788664, val_loss: 0.6626532730692402\n",
      "2 model | 33 epoch start\n",
      "2 model epoch: 33, train_loss: 0.13388620455521758, val_loss: 0.6646393624604268\n",
      "2 model | 34 epoch start\n",
      "2 model epoch: 34, train_loss: 0.13247949870492873, val_loss: 0.6647881940013828\n",
      "3 model | 0 epoch start\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'AsymmetricSVD' object has no attribute 'implicit_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/opt/ml/input/2023-Summer-Internship-DSAIL/Recsys/Netflix/train.ipynb 셀 30\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B101.101.218.32/opt/ml/input/2023-Summer-Internship-DSAIL/Recsys/Netflix/train.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m,\u001b[39m150\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B101.101.218.32/opt/ml/input/2023-Summer-Internship-DSAIL/Recsys/Netflix/train.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00midx\u001b[39m}\u001b[39;00m\u001b[39m model | \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m epoch start\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B101.101.218.32/opt/ml/input/2023-Summer-Internship-DSAIL/Recsys/Netflix/train.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m     train_loss \u001b[39m=\u001b[39m train(model, train_dataloader, criterion, optimizer)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B101.101.218.32/opt/ml/input/2023-Summer-Internship-DSAIL/Recsys/Netflix/train.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m     val_loss \u001b[39m=\u001b[39m evaluate(model, test_dataloader, criterion)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B101.101.218.32/opt/ml/input/2023-Summer-Internship-DSAIL/Recsys/Netflix/train.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00midx\u001b[39m}\u001b[39;00m\u001b[39m model epoch: \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m, train_loss: \u001b[39m\u001b[39m{\u001b[39;00mtrain_loss\u001b[39m}\u001b[39;00m\u001b[39m, val_loss: \u001b[39m\u001b[39m{\u001b[39;00mval_loss\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32m/opt/ml/input/2023-Summer-Internship-DSAIL/Recsys/Netflix/train.ipynb 셀 30\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, criterion, optimizer)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B101.101.218.32/opt/ml/input/2023-Summer-Internship-DSAIL/Recsys/Netflix/train.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m rating \u001b[39m=\u001b[39m rating\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B101.101.218.32/opt/ml/input/2023-Summer-Internship-DSAIL/Recsys/Netflix/train.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B101.101.218.32/opt/ml/input/2023-Summer-Internship-DSAIL/Recsys/Netflix/train.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m pred \u001b[39m=\u001b[39m model(user, item)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B101.101.218.32/opt/ml/input/2023-Summer-Internship-DSAIL/Recsys/Netflix/train.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(pred, rating)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B101.101.218.32/opt/ml/input/2023-Summer-Internship-DSAIL/Recsys/Netflix/train.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/opt/conda/envs/recbole/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/opt/ml/input/2023-Summer-Internship-DSAIL/Recsys/Netflix/train.ipynb 셀 30\u001b[0m in \u001b[0;36mAsymmetricSVD.forward\u001b[0;34m(self, user, item)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B101.101.218.32/opt/ml/input/2023-Summer-Internship-DSAIL/Recsys/Netflix/train.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m sum_of_item_weights \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B101.101.218.32/opt/ml/input/2023-Summer-Internship-DSAIL/Recsys/Netflix/train.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m sum_of_implicit_offset \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B101.101.218.32/opt/ml/input/2023-Summer-Internship-DSAIL/Recsys/Netflix/train.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39mfor\u001b[39;00m implicit \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mimplicit_data[user_idx]:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B101.101.218.32/opt/ml/input/2023-Summer-Internship-DSAIL/Recsys/Netflix/train.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m     implicit_tensor \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mLongTensor([implicit])\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B101.101.218.32/opt/ml/input/2023-Summer-Internship-DSAIL/Recsys/Netflix/train.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n",
      "File \u001b[0;32m/opt/conda/envs/recbole/lib/python3.8/site-packages/torch/nn/modules/module.py:1269\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1267\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[1;32m   1268\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1269\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1270\u001b[0m     \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'AsymmetricSVD' object has no attribute 'implicit_data'"
     ]
    }
   ],
   "source": [
    "model1 = NeighborhoodModel(R,mu,k)\n",
    "model2 = SVDPlusPlus(R,mu,F)\n",
    "model3 = IntergratedModel(R,mu,F,k)\n",
    "model4 = AsymmetricSVD(R,mu,F)\n",
    "\n",
    "models = [model1, model2, model3, model4]\n",
    "\n",
    "for idx, model in enumerate(models):\n",
    "    model = model.to(device) \n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01,weight_decay=0.001)\n",
    "    criterion = RMSELoss\n",
    "    early_stop_cnt = 0\n",
    "    early_stop_loss = 100000\n",
    "    for epoch in range(0,150):\n",
    "        print(f'{idx} model | {epoch} epoch start')\n",
    "        train_loss = train(model, train_dataloader, criterion, optimizer)\n",
    "        val_loss = evaluate(model, test_dataloader, criterion)\n",
    "        \n",
    "        print(f'{idx} model epoch: {epoch}, train_loss: {train_loss}, val_loss: {val_loss}')\n",
    "        # summary = pd.concat([summary, pd.DataFrame([[idx, epoch, train_loss, val_loss]], columns=['model', 'epoch', 'train_rmse', 'test_rmse'])])\n",
    "        \n",
    "        if early_stop_loss > val_loss:\n",
    "            early_stop_cnt = 0\n",
    "            early_stop_loss = val_loss\n",
    "        else:\n",
    "            early_stop_cnt += 1 \n",
    "            \n",
    "        if early_stop_loss < val_loss and early_stop_cnt > 10:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Netflix(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.users = self.df['Cust_ID'].values\n",
    "        self.items = self.df['Movie_Id'].values\n",
    "        self.ratings = self.df['Rating'].values\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        user = self.users[index]\n",
    "        item = self.items[index]\n",
    "        rating = self.ratings[index]\n",
    "        \n",
    "        return user, item, rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_through_a_top_k_recommender(df, model):\n",
    "    summary = []\n",
    "    rating_5_df = df.loc[df['Rating'] == 5]\n",
    "    rating_no_df = df.loc[df['Rating'] != 5]\n",
    "    \n",
    "    rating_5_dataset = Netflix(rating_5_df)\n",
    "    rating_no_dataset = Netflix(rating_no_df) \n",
    "\n",
    "    rating_5_dataloader = DataLoader(rating_5_dataset, batch_size=1, shuffle=True)\n",
    "    rating_no_dataloader = DataLoader(rating_no_dataset, batch_size=1, shuffle=True)\n",
    "    \n",
    "    for user,item,rating in rating_5_dataloader:\n",
    "        temp = []\n",
    "        user = user.to(device)\n",
    "        item = item.to(device)\n",
    "        \n",
    "        pred_5 = model(user, item)\n",
    "        temp.append(pred_5)\n",
    "        \n",
    "        for user, item, rating in rating_no_dataloader:\n",
    "            user = user.to(device)\n",
    "            item = item.to(device)\n",
    "            \n",
    "            pred_no = model(user, item)\n",
    "            temp.append(pred_no)\n",
    "        summary.append(temp)\n",
    "    \n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_first_index_rank(lists):\n",
    "    percentage = 0\n",
    "    for i in lists:\n",
    "        cnt = 0\n",
    "        first_index = i[0]\n",
    "        for idx in i:\n",
    "            if idx > first_index:\n",
    "                cnt += 1\n",
    "        percentage += cnt / len(i)\n",
    "    \n",
    "    return percentage / len(lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx,model in enumerate(models):\n",
    "    summary = evaluation_through_a_top_k_recommender(sample_df, model)\n",
    "    percentage = calculate_first_index_rank(summary)\n",
    "    print(f'{idx} model percentage: {percentage}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recbole",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
