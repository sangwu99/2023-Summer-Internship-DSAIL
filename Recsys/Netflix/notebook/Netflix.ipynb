{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/recbole/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "<frozen importlib._bootstrap>:219: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "from torch.optim import SGD\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['combined_data_1.txt',\n",
       " 'combined_data_3.txt',\n",
       " 'combined_data_2.txt',\n",
       " 'combined_data_4.txt']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpath = 'archive-2'\n",
    "data_list = []\n",
    "for i in os.listdir(dpath):\n",
    "    if 'combined_data' in i:\n",
    "        data_list.append(i)\n",
    "data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded:  combined_data_1.txt\n",
      "Loaded:  combined_data_3.txt\n",
      "Loaded:  combined_data_2.txt\n",
      "Loaded:  combined_data_4.txt\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'Cust_ID','Rating','Timestamp'}) \n",
    "\n",
    "for data in data_list:\n",
    "    temp_df = pd.read_csv(os.path.join(dpath, data), header = None, names = ['Cust_ID', 'Rating','Timestamp'], usecols = [0,1,2])\n",
    "    temp_df['Rating'] = temp_df['Rating'].astype(float)\n",
    "    df = pd.concat([df, temp_df])\n",
    "    print(\"Loaded: \", data)\n",
    "\n",
    "df.index = np.arange(0,len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>551</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17768</th>\n",
       "      <td>100488434</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17769</th>\n",
       "      <td>100489040</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17770</th>\n",
       "      <td>100489245</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17771</th>\n",
       "      <td>100490608</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17772</th>\n",
       "      <td>100497358</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17773 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           index  Rating\n",
       "0              0    True\n",
       "1              1    True\n",
       "2              2    True\n",
       "3              3    True\n",
       "4            551    True\n",
       "...          ...     ...\n",
       "17768  100488434    True\n",
       "17769  100489040    True\n",
       "17770  100489245    True\n",
       "17771  100490608    True\n",
       "17772  100497358    True\n",
       "\n",
       "[17773 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nan = pd.DataFrame(pd.isnull(df.Rating))\n",
    "df_nan = df_nan[df_nan['Rating'] == True]\n",
    "df_nan = df_nan.reset_index()\n",
    "df_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie numpy: [4.0000e+00 4.0000e+00 4.0000e+00 ... 1.7773e+04 1.7773e+04 1.7773e+04]\n",
      "Length: 100480507\n"
     ]
    }
   ],
   "source": [
    "movie_np = []\n",
    "movie_id = 1\n",
    "\n",
    "for i,j in zip(df_nan['index'][1:],df_nan['index'][:-1]):\n",
    "    # numpy approach\n",
    "    temp = np.full((1,i-j-1), movie_id)\n",
    "    movie_np = np.append(movie_np, temp)\n",
    "    movie_id += 1\n",
    "\n",
    "# Account for last record and corresponding length\n",
    "# numpy approach\n",
    "last_record = np.full((1,len(df) - df_nan.iloc[-1, 0] - 1),movie_id)\n",
    "movie_np = np.append(movie_np, last_record)\n",
    "\n",
    "print('Movie numpy: {}'.format(movie_np))\n",
    "print('Length: {}'.format(len(movie_np)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             0  Cust_ID  Rating   Timestamp  Movie_Id\n",
      "4          NaN  1488844     3.0  2005-09-06         4\n",
      "5000999    NaN   501954     2.0  2004-08-26       999\n",
      "10001965   NaN   404654     5.0  2005-08-29      1965\n",
      "15002879   NaN   886608     2.0  2005-09-19      2879\n",
      "20003828   NaN  1193835     2.0  2003-08-13      3828\n",
      "25004725   NaN    35179     4.0  2004-05-17      4725\n",
      "30005671   NaN  2561536     3.0  2002-09-23      5671\n",
      "35006571   NaN   200362     4.0  2005-02-28      6571\n",
      "40007524   NaN   686629     4.0  2005-03-01      7524\n",
      "45008342   NaN  1494017     2.0  2003-07-04      8342\n",
      "50009229   NaN   437784     4.0  2005-07-30      9229\n",
      "55010055   NaN   788058     4.0  2005-09-29     10055\n",
      "60010827   NaN   433661     4.0  2002-01-18     10827\n",
      "65011673   NaN  2402781     4.0  2004-11-10     11673\n",
      "70012701   NaN   182620     4.0  2004-12-08     12701\n",
      "75013585   NaN   506044     4.0  2004-09-28     13585\n",
      "80014456   NaN   353605     2.0  2005-07-10     14456\n",
      "85015119   NaN   664606     3.0  2005-01-06     15119\n",
      "90016011   NaN  2213715     3.0  2005-07-01     16011\n",
      "95016882   NaN  1589401     5.0  2004-04-30     16882\n",
      "100017630  NaN  2314006     4.0  2005-02-18     17630\n"
     ]
    }
   ],
   "source": [
    "df = df[pd.notnull(df['Rating'])]\n",
    "df['Movie_Id'] = movie_np.astype(int)\n",
    "df['Cust_ID'] = df['Cust_ID'].astype(int)\n",
    "print(df.iloc[::5000000, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21746/1478047817.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Cust_ID'] = df['Cust_ID'].map(user2idx)\n",
      "/tmp/ipykernel_21746/1478047817.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Movie_Id'] = df['Movie_Id'].map(item2idx)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cust_ID</th>\n",
       "      <th>Movie_Id</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2005-09-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2005-05-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2005-10-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2005-12-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2004-05-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100498275</th>\n",
       "      <td>542</td>\n",
       "      <td>17769</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2005-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100498276</th>\n",
       "      <td>29273</td>\n",
       "      <td>17769</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2005-07-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100498277</th>\n",
       "      <td>29251</td>\n",
       "      <td>17769</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2004-08-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100498278</th>\n",
       "      <td>22793</td>\n",
       "      <td>17769</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2004-05-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100498279</th>\n",
       "      <td>76269</td>\n",
       "      <td>17769</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2005-03-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100480507 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Cust_ID  Movie_Id  Rating   Timestamp\n",
       "4                0         0     3.0  2005-09-06\n",
       "5                1         0     5.0  2005-05-13\n",
       "6                2         0     4.0  2005-10-19\n",
       "7                3         0     4.0  2005-12-26\n",
       "8                4         0     3.0  2004-05-03\n",
       "...            ...       ...     ...         ...\n",
       "100498275      542     17769     4.0  2005-11-01\n",
       "100498276    29273     17769     3.0  2005-07-19\n",
       "100498277    29251     17769     1.0  2004-08-07\n",
       "100498278    22793     17769     4.0  2004-05-28\n",
       "100498279    76269     17769     2.0  2005-03-10\n",
       "\n",
       "[100480507 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['Cust_ID', 'Movie_Id', 'Rating','Timestamp']]\n",
    "\n",
    "user2idx = {j:i for i,j in enumerate(df['Cust_ID'].unique())}\n",
    "item2idx = {j:i for i,j in enumerate(df['Movie_Id'].unique())}\n",
    "df['Cust_ID'] = df['Cust_ID'].map(user2idx)\n",
    "df['Movie_Id'] = df['Movie_Id'].map(item2idx)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('preprocessed_df_with_timestamp.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('preprocessed_df_with_timestamp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(P, Q, mu, b_u, b_i, user, item):\n",
    "    pred = mu + b_u[user] + b_i[item] + P[user, :].T.dot(Q[item, :])\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(P, Q, mu, b_u, b_i, samples, lr, reg):\n",
    "    for user, item, rating in samples:\n",
    "        pred = predict(P, Q, mu, b_u, b_i, user, item)\n",
    "        \n",
    "        error = rating - pred\n",
    "        \n",
    "        b_u[user] += lr * (error - reg * b_u[user])\n",
    "        b_i[item] += lr * (error - reg * b_i[item])\n",
    "        \n",
    "        P[user, :] += lr * (error * Q[item, :] - reg * P[user, :])\n",
    "        Q[item, :] += lr * (error * P[user, :] - reg * Q[item, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(samples, P, Q, mu, b_u, b_i):\n",
    "    error = [] \n",
    "    for user,item,rating in samples:\n",
    "        square_error = (rating - predict(P, Q, mu, b_u, b_i, user, item))**2\n",
    "        error.append(square_error)\n",
    "    rmse = np.sqrt(np.array(error).mean())\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MF_with_sgd(object):\n",
    "    def __init__(self, df ,num_users, num_items, F, lr, reg, epochs):\n",
    "        self.df = df\n",
    "        self.num_users, self.num_items = num_users, num_items\n",
    "        self.F = F\n",
    "        self.lr = lr \n",
    "        self.reg = reg \n",
    "        self.epochs = epochs\n",
    "        self.summary = pd.DataFrame(columns = ['epoch','rmse','val_rmse'])\n",
    "        \n",
    "    def build_samples(self): \n",
    "        self.samples = [] \n",
    "        self.users = self.df['Cust_ID'].values \n",
    "        self.items = self.df['Movie_Id'].values\n",
    "        self.ratings = self.df['Rating'].values\n",
    "        \n",
    "        for idx in range(len(self.df)):\n",
    "            if (idx % 10000000) == 0: \n",
    "                print(f\"Loaded: {idx}th sample\")\n",
    "            self.samples.append((self.users[idx],self.items[idx],self.ratings[idx]))\n",
    "    \n",
    "    def train(self): \n",
    "        self.P = np.random.normal(scale = 1/self.F,size = (self.num_users, self.F))\n",
    "        self.Q = np.random.normal(scale = 1/self.F,size = (self.num_items, self.F))\n",
    "        \n",
    "        self.b_u = np.zeros(self.num_users)\n",
    "        self.b_i = np.zeros(self.num_items)\n",
    "        \n",
    "        self.mu = self.df['Rating'].mean()\n",
    "        \n",
    "        np.random.shuffle(self.samples)\n",
    "        \n",
    "        self.train_samples = self.samples[:int(0.8*len(self.samples))]\n",
    "        self.test_samples = self.samples[int(0.8*len(self.samples)):]\n",
    "        for epoch in range(self.epochs): \n",
    "            print(f\"Start: {epoch}th epoch\")\n",
    "            # np.random.shuffle(self.samples)\n",
    "            sgd(self.P, self.Q, self.mu, self.b_u, self.b_i, self.train_samples, self.lr, self.reg)\n",
    "            train_loss = rmse(self.train_samples, self.P, self.Q, self.mu, self.b_u, self.b_i)\n",
    "            test_loss = rmse(self.test_samples, self.P, self.Q, self.mu, self.b_u, self.b_i)\n",
    "            print(f\"Epoch: {epoch} ; error = {train_loss} ; val_error = {test_loss}\")\n",
    "            self.summary.loc[epoch] = [epoch, train_loss,test_loss]\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10185/3791929406.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  als_df['Cust_ID'] = als_df['Cust_ID'].map(als_df_user2idx)\n",
      "/tmp/ipykernel_10185/3791929406.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  als_df['Movie_Id'] = als_df['Movie_Id'].map(als_df_item2idx)\n"
     ]
    }
   ],
   "source": [
    "sgd_df = df.loc[(df['Cust_ID'] < 10000) & (df['Movie_Id'] < 388)]\n",
    "als_df = sgd_df\n",
    "als_df_user2idx = {user:idx for idx, user in enumerate(als_df['Cust_ID'].unique())}\n",
    "als_df_item2idx = {item:idx for idx, item in enumerate(als_df['Movie_Id'].unique())}\n",
    "als_df['Cust_ID'] = als_df['Cust_ID'].map(als_df_user2idx)\n",
    "als_df['Movie_Id'] = als_df['Movie_Id'].map(als_df_item2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: 0th sample\n"
     ]
    }
   ],
   "source": [
    "K = 15\n",
    "lr = 0.01 \n",
    "reg = 0.2 \n",
    "epochs = 80\n",
    "\n",
    "user_num = als_df['Cust_ID'].nunique()\n",
    "item_num = als_df['Movie_Id'].nunique()\n",
    "\n",
    "mf = MF_with_sgd(sgd_df,user_num,item_num, K, lr, reg, epochs)\n",
    "mf.build_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: 0th epoch\n",
      "Epoch: 0 ; error = 1.0320211804992279 ; val_error = 1.039569109343795\n",
      "Start: 1th epoch\n",
      "Epoch: 1 ; error = 1.003542283809406 ; val_error = 1.0190215703024181\n",
      "Start: 2th epoch\n",
      "Epoch: 2 ; error = 0.9872905331640218 ; val_error = 1.0090633133771079\n",
      "Start: 3th epoch\n",
      "Epoch: 3 ; error = 0.9763326810961608 ; val_error = 1.0032914353389255\n",
      "Start: 4th epoch\n",
      "Epoch: 4 ; error = 0.9683406103907002 ; val_error = 0.9996852768897486\n",
      "Start: 5th epoch\n",
      "Epoch: 5 ; error = 0.9622255695273872 ; val_error = 0.9973479457802731\n",
      "Start: 6th epoch\n",
      "Epoch: 6 ; error = 0.9573875874405671 ; val_error = 0.9958088813683454\n",
      "Start: 7th epoch\n",
      "Epoch: 7 ; error = 0.9534618553248603 ; val_error = 0.9947957792550476\n",
      "Start: 8th epoch\n",
      "Epoch: 8 ; error = 0.9502114987904173 ; val_error = 0.9941406139539707\n",
      "Start: 9th epoch\n",
      "Epoch: 9 ; error = 0.9474752386479748 ; val_error = 0.9937348642857555\n",
      "Start: 10th epoch\n",
      "Epoch: 10 ; error = 0.9451391916676423 ; val_error = 0.9935059873851528\n",
      "Start: 11th epoch\n",
      "Epoch: 11 ; error = 0.9431205537189447 ; val_error = 0.993404161459892\n",
      "Start: 12th epoch\n",
      "Epoch: 12 ; error = 0.9413576351277254 ; val_error = 0.9933944110742507\n",
      "Start: 13th epoch\n",
      "Epoch: 13 ; error = 0.9398035117310327 ; val_error = 0.9934517323926612\n",
      "Start: 14th epoch\n",
      "Epoch: 14 ; error = 0.9384218379718494 ; val_error = 0.9935579730629118\n",
      "Start: 15th epoch\n",
      "Epoch: 15 ; error = 0.9371840053499887 ; val_error = 0.993699779202925\n",
      "Start: 16th epoch\n",
      "Epoch: 16 ; error = 0.9360671661043389 ; val_error = 0.9938672126461198\n",
      "Start: 17th epoch\n",
      "Epoch: 17 ; error = 0.9350528290600587 ; val_error = 0.9940528007715655\n",
      "Start: 18th epoch\n",
      "Epoch: 18 ; error = 0.9341258430011404 ; val_error = 0.9942508720682587\n",
      "Start: 19th epoch\n",
      "Epoch: 19 ; error = 0.9332736480442088 ; val_error = 0.9944570842493243\n",
      "Start: 20th epoch\n",
      "Epoch: 20 ; error = 0.9324857157973201 ; val_error = 0.9946680844080616\n",
      "Start: 21th epoch\n",
      "Epoch: 21 ; error = 0.9317531247026146 ; val_error = 0.9948812611270527\n",
      "Start: 22th epoch\n",
      "Epoch: 22 ; error = 0.9310682336187761 ; val_error = 0.995094561504682\n",
      "Start: 23th epoch\n",
      "Epoch: 23 ; error = 0.9304244277550587 ; val_error = 0.9953063545766418\n",
      "Start: 24th epoch\n",
      "Epoch: 24 ; error = 0.9298159185431571 ; val_error = 0.9955153282624258\n",
      "Start: 25th epoch\n",
      "Epoch: 25 ; error = 0.9292375841723783 ; val_error = 0.9957204107808895\n",
      "Start: 26th epoch\n",
      "Epoch: 26 ; error = 0.9286848411029235 ; val_error = 0.9959207100909443\n",
      "Start: 27th epoch\n",
      "Epoch: 27 ; error = 0.92815353941669 ; val_error = 0.99611546672727\n",
      "Start: 28th epoch\n",
      "Epoch: 28 ; error = 0.9276398766955491 ; val_error = 0.9963040166774749\n",
      "Start: 29th epoch\n",
      "Epoch: 29 ; error = 0.9271403264536627 ; val_error = 0.9964857618577716\n",
      "Start: 30th epoch\n",
      "Epoch: 30 ; error = 0.9266515781419002 ; val_error = 0.9966601464031429\n",
      "Start: 31th epoch\n",
      "Epoch: 31 ; error = 0.9261704864908081 ; val_error = 0.9968266374723284\n",
      "Start: 32th epoch\n",
      "Epoch: 32 ; error = 0.9256940285347615 ; val_error = 0.9969847096305005\n",
      "Start: 33th epoch\n",
      "Epoch: 33 ; error = 0.9252192671135402 ; val_error = 0.9971338321496762\n",
      "Start: 34th epoch\n",
      "Epoch: 34 ; error = 0.924743320013642 ; val_error = 0.997273458783982\n",
      "Start: 35th epoch\n",
      "Epoch: 35 ; error = 0.9242633342146117 ; val_error = 0.9974030197513062\n",
      "Start: 36th epoch\n",
      "Epoch: 36 ; error = 0.923776464962154 ; val_error = 0.9975219157963972\n",
      "Start: 37th epoch\n",
      "Epoch: 37 ; error = 0.92327985961017 ; val_error = 0.9976295143304617\n",
      "Start: 38th epoch\n",
      "Epoch: 38 ; error = 0.9227706463631606 ; val_error = 0.9977251477426236\n",
      "Start: 39th epoch\n",
      "Epoch: 39 ; error = 0.9222459282089589 ; val_error = 0.9978081140598958\n",
      "Start: 40th epoch\n",
      "Epoch: 40 ; error = 0.9217027824551538 ; val_error = 0.9978776801924883\n",
      "Start: 41th epoch\n",
      "Epoch: 41 ; error = 0.9211382663622983 ; val_error = 0.9979330880355908\n",
      "Start: 42th epoch\n",
      "Epoch: 42 ; error = 0.9205494293905694 ; val_error = 0.997973563700272\n",
      "Start: 43th epoch\n",
      "Epoch: 43 ; error = 0.9199333325287045 ; val_error = 0.9979983301063363\n",
      "Start: 44th epoch\n",
      "Epoch: 44 ; error = 0.9192870750383118 ; val_error = 0.9980066230798441\n",
      "Start: 45th epoch\n",
      "Epoch: 45 ; error = 0.9186078287082098 ; val_error = 0.9979977109498396\n",
      "Start: 46th epoch\n",
      "Epoch: 46 ; error = 0.9178928793629056 ; val_error = 0.9979709174284449\n",
      "Start: 47th epoch\n",
      "Epoch: 47 ; error = 0.9171396749075597 ; val_error = 0.9979256472881814\n",
      "Start: 48th epoch\n",
      "Epoch: 48 ; error = 0.9163458786350941 ; val_error = 0.9978614140318955\n",
      "Start: 49th epoch\n",
      "Epoch: 49 ; error = 0.9155094259057207 ; val_error = 0.9977778684076503\n",
      "Start: 50th epoch\n",
      "Epoch: 50 ; error = 0.9146285816934818 ; val_error = 0.9976748262899785\n",
      "Start: 51th epoch\n",
      "Epoch: 51 ; error = 0.9137019959572507 ; val_error = 0.9975522941778822\n",
      "Start: 52th epoch\n",
      "Epoch: 52 ; error = 0.912728753426905 ; val_error = 0.9974104904032012\n",
      "Start: 53th epoch\n",
      "Epoch: 53 ; error = 0.9117084142906479 ; val_error = 0.9972498601525028\n",
      "Start: 54th epoch\n",
      "Epoch: 54 ; error = 0.9106410424995319 ; val_error = 0.9970710826198891\n",
      "Start: 55th epoch\n",
      "Epoch: 55 ; error = 0.9095272190043103 ; val_error = 0.9968750690399603\n",
      "Start: 56th epoch\n",
      "Epoch: 56 ; error = 0.9083680381867848 ; val_error = 0.9966629509778134\n",
      "Start: 57th epoch\n",
      "Epoch: 57 ; error = 0.907165086959709 ; val_error = 0.9964360590168511\n",
      "Start: 58th epoch\n",
      "Epoch: 58 ; error = 0.9059204073474022 ; val_error = 0.9961958927939463\n",
      "Start: 59th epoch\n",
      "Epoch: 59 ; error = 0.9046364446508549 ; val_error = 0.9959440840764884\n",
      "Start: 60th epoch\n",
      "Epoch: 60 ; error = 0.9033159843717934 ; val_error = 0.9956823551519108\n",
      "Start: 61th epoch\n",
      "Epoch: 61 ; error = 0.9019620817789965 ; val_error = 0.995412475127638\n",
      "Start: 62th epoch\n",
      "Epoch: 62 ; error = 0.9005779882682259 ; val_error = 0.9951362167799117\n",
      "Start: 63th epoch\n",
      "Epoch: 63 ; error = 0.8991670784914493 ; val_error = 0.9948553163540897\n",
      "Start: 64th epoch\n",
      "Epoch: 64 ; error = 0.8977327816800725 ; val_error = 0.9945714382607814\n",
      "Start: 65th epoch\n",
      "Epoch: 65 ; error = 0.8962785197803219 ; val_error = 0.9942861460148658\n",
      "Start: 66th epoch\n",
      "Epoch: 66 ; error = 0.8948076540983284 ; val_error = 0.994000880121386\n",
      "Start: 67th epoch\n",
      "Epoch: 67 ; error = 0.8933234412517914 ; val_error = 0.9937169430083693\n",
      "Start: 68th epoch\n",
      "Epoch: 68 ; error = 0.8918289984481621 ; val_error = 0.9934354906049263\n",
      "Start: 69th epoch\n",
      "Epoch: 69 ; error = 0.8903272775181956 ; val_error = 0.9931575297987055\n",
      "Start: 70th epoch\n",
      "Epoch: 70 ; error = 0.8888210467486531 ; val_error = 0.9928839207881615\n",
      "Start: 71th epoch\n",
      "Epoch: 71 ; error = 0.8873128793649218 ; val_error = 0.9926153832590858\n",
      "Start: 72th epoch\n",
      "Epoch: 72 ; error = 0.8858051474773848 ; val_error = 0.9923525053352293\n",
      "Start: 73th epoch\n",
      "Epoch: 73 ; error = 0.8843000203789291 ; val_error = 0.9920957543480173\n",
      "Start: 74th epoch\n",
      "Epoch: 74 ; error = 0.8827994662199105 ; val_error = 0.9918454886096199\n",
      "Start: 75th epoch\n",
      "Epoch: 75 ; error = 0.8813052562531191 ; val_error = 0.9916019695310764\n",
      "Start: 76th epoch\n",
      "Epoch: 76 ; error = 0.8798189710068439 ; val_error = 0.9913653735834318\n",
      "Start: 77th epoch\n",
      "Epoch: 77 ; error = 0.8783420078914731 ; val_error = 0.9911358037422558\n",
      "Start: 78th epoch\n",
      "Epoch: 78 ; error = 0.8768755898656164 ; val_error = 0.9909133001775993\n",
      "Start: 79th epoch\n",
      "Epoch: 79 ; error = 0.8754207748796424 ; val_error = 0.9906978500499164\n"
     ]
    }
   ],
   "source": [
    "mf.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result_df = mf.summary \n",
    "\n",
    "x = result_df['epoch'].values\n",
    "y = result_df['val_rmse'].values\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('RMSE')\n",
    "plt.grid(axis = 'y')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def als(R, P, Q, F, reg):\n",
    "#     for user in range(R.shape[0]):\n",
    "#         QT_Q = np.matmul(Q.T, Q)\n",
    "#         li = reg * np.eye(F)\n",
    "#         QT_ru = np.matmul(Q.T,R[user].toarray()[0])\n",
    "#         P[user] = np.linalg.solve(QT_Q + li,QT_ru)\n",
    "        \n",
    "#     for item in range(R.shape[1]):\n",
    "#         PT_P = np.matmul(P.T, P)\n",
    "#         li = reg * np.eye(F)\n",
    "#         PT_ri = np.matmul(P.T,R[:,item].toarray())\n",
    "#         Q[item] = np.linalg.solve(PT_P + li,PT_ri).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def als(R, P, Q, F ,reg):\n",
    "    for user_id, R_user in enumerate(R):\n",
    "        P[user_id] = np.linalg.solve(\n",
    "            np.matmul(Q.T, Q) + reg * np.eye(F),\n",
    "            np.matmul(Q.T, R[user_id])\n",
    "        ) \n",
    "        \n",
    "    for item_id, R_item in enumerate(R.T):\n",
    "        Q[item_id] = np.linalg.solve(\n",
    "            np.matmul(P.T, P) + reg * np.eye(F),\n",
    "            np.matmul(P.T, R[:, item_id])\n",
    "        ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def als_loss(sample, R, P, Q, reg):\n",
    "    loss = 0\n",
    "    for user, item, rating in sample: \n",
    "        loss += (rating - np.dot(P[user].T,Q[item]))**2\n",
    "    for user in range(R.shape[0]):\n",
    "        loss += reg * np.sum(np.square(P[user]))\n",
    "    for item in range(R.shape[1]):\n",
    "        loss += reg * np.sum(np.square(Q[item]))\n",
    "        \n",
    "    return loss / len(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_loss(sample, P, Q):\n",
    "    loss = 0 \n",
    "    for user, item, rating in sample: \n",
    "        loss += pow(rating - np.dot(P[user].T,Q[item]),2)\n",
    "        \n",
    "    return np.sqrt(loss / len(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MF_with_als(object):\n",
    "    def __init__(self, train_df, train_R, F, reg, epochs):\n",
    "        self.train_df = train_df\n",
    "        self.train_R = train_R\n",
    "        self.num_users, self.num_items = train_R.shape \n",
    "        self.F = F \n",
    "        self.reg = reg \n",
    "        self.epochs = epochs \n",
    "        \n",
    "        self.summary = pd.DataFrame(columns = ['epoch','test_loss'])\n",
    "    \n",
    "    def build_samples(self):\n",
    "        self.test_samples = []\n",
    "        self.users = self.train_df['Cust_ID'].values\n",
    "        self.items = self.train_df['Movie_Id'].values\n",
    "        self.ratings = self.train_df['Rating'].values\n",
    "        \n",
    "        for idx in range(len(self.train_df)):\n",
    "            if (idx % 10000000) == 0:\n",
    "                print(f\"Loaded: {idx}th sample\")\n",
    "            self.test_samples.append((self.users[idx],self.items[idx],self.ratings[idx]))   \n",
    "                        \n",
    "    def train(self):\n",
    "        self.P = np.random.normal(scale = 1/self.F, size = (self.num_users, self.F))\n",
    "        self.Q = np.random.normal(scale = 1/self.F, size = (self.num_items, self.F))\n",
    "            \n",
    "        for epoch in range(self.epochs): \n",
    "            print(f'Start: {epoch}th epoch')\n",
    "            als(self.train_R, self.P, self.Q, self.F,self.reg)\n",
    "            train_loss = als_loss(self.test_samples, self.train_R, self.P, self.Q, self.reg)\n",
    "            # test_loss = rmse_loss(self.test_samples, self.P, self.Q)\n",
    "            \n",
    "            \n",
    "            print(f'Epoch: {epoch} ; val_loss = {train_loss}')\n",
    "            self.summary.loc[epoch] = [epoch, train_loss]\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10185/840736911.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  als_df['Cust_ID'] = als_df['Cust_ID'].map(als_df_user2idx)\n",
      "/tmp/ipykernel_10185/840736911.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  als_df['Movie_Id'] = als_df['Movie_Id'].map(als_df_item2idx)\n"
     ]
    }
   ],
   "source": [
    "als_df = sgd_df\n",
    "als_df_user2idx = {user:idx for idx, user in enumerate(als_df['Cust_ID'].unique())}\n",
    "als_df_item2idx = {item:idx for idx, item in enumerate(als_df['Movie_Id'].unique())}\n",
    "als_df['Cust_ID'] = als_df['Cust_ID'].map(als_df_user2idx)\n",
    "als_df['Movie_Id'] = als_df['Movie_Id'].map(als_df_item2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "splited_index = als_df.index.to_list()\n",
    "np.random.shuffle(splited_index)\n",
    "als_train_index = splited_index[:int(0.8*len(als_df))]\n",
    "als_test_index = splited_index[int(0.8*len(als_df)):]\n",
    "als_train_df = als_df.loc[als_train_index]\n",
    "als_test_df = als_df.loc[als_test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_R = csr_matrix(\n",
    "#     (np.array(als_train_df['Rating'].values, dtype = np.int32),\n",
    "#     (np.array(als_train_df['Cust_ID'].values, dtype = np.int32),np.array(als_train_df['Movie_Id'].values, dtype = np.int32))\n",
    "#     ), shape=(als_df['Cust_ID'].nunique(), als_df['Movie_Id'].nunique()))\n",
    "\n",
    "# test_R = csr_matrix(\n",
    "#     (np.array(als_test_df['Rating'].values, dtype = np.int32),\n",
    "#     (np.array(als_test_df['Cust_ID'].values, dtype = np.int32),np.array(als_test_df['Movie_Id'].values, dtype = np.int32))\n",
    "#     ), shape=(als_df['Cust_ID'].nunique(), als_df['Movie_Id'].nunique()))\n",
    "\n",
    "train_R = als_df.pivot_table('Rating', 'Cust_ID', 'Movie_Id').fillna(0) \n",
    "# test_R = als_test_df.pivot_table('Rating', 'Cust_ID', 'Movie_Id').fillna(0)\n",
    "R = np.copy(train_R)\n",
    "\n",
    "F = 40\n",
    "reg = 8\n",
    "epochs = 500 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_R = train_R.toarray()\n",
    "# test_R = test_R.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: 0th sample\n"
     ]
    }
   ],
   "source": [
    "MF_als = MF_with_als(als_df,R, 15, 2, epochs)\n",
    "MF_als.build_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: 0th epoch\n",
      "Epoch: 0 ; val_loss = 6.104721905834055\n",
      "Start: 1th epoch\n",
      "Epoch: 1 ; val_loss = 4.704665314180102\n",
      "Start: 2th epoch\n",
      "Epoch: 2 ; val_loss = 4.58960688153567\n",
      "Start: 3th epoch\n",
      "Epoch: 3 ; val_loss = 4.5545434067362285\n",
      "Start: 4th epoch\n",
      "Epoch: 4 ; val_loss = 4.535409829877034\n",
      "Start: 5th epoch\n",
      "Epoch: 5 ; val_loss = 4.521256138854064\n",
      "Start: 6th epoch\n",
      "Epoch: 6 ; val_loss = 4.510060196491721\n",
      "Start: 7th epoch\n",
      "Epoch: 7 ; val_loss = 4.501205943826861\n",
      "Start: 8th epoch\n",
      "Epoch: 8 ; val_loss = 4.494149797905374\n",
      "Start: 9th epoch\n",
      "Epoch: 9 ; val_loss = 4.488403264739688\n",
      "Start: 10th epoch\n",
      "Epoch: 10 ; val_loss = 4.483603173794562\n",
      "Start: 11th epoch\n",
      "Epoch: 11 ; val_loss = 4.479505796501009\n",
      "Start: 12th epoch\n",
      "Epoch: 12 ; val_loss = 4.475951196209764\n",
      "Start: 13th epoch\n",
      "Epoch: 13 ; val_loss = 4.472831426140789\n",
      "Start: 14th epoch\n",
      "Epoch: 14 ; val_loss = 4.470069826050181\n",
      "Start: 15th epoch\n",
      "Epoch: 15 ; val_loss = 4.467609035850065\n",
      "Start: 16th epoch\n",
      "Epoch: 16 ; val_loss = 4.465404284391892\n",
      "Start: 17th epoch\n",
      "Epoch: 17 ; val_loss = 4.463419566076006\n",
      "Start: 18th epoch\n",
      "Epoch: 18 ; val_loss = 4.461625345951485\n",
      "Start: 19th epoch\n",
      "Epoch: 19 ; val_loss = 4.459997079837437\n",
      "Start: 20th epoch\n",
      "Epoch: 20 ; val_loss = 4.458514187029008\n",
      "Start: 21th epoch\n",
      "Epoch: 21 ; val_loss = 4.45715929198044\n",
      "Start: 22th epoch\n",
      "Epoch: 22 ; val_loss = 4.455917639695094\n",
      "Start: 23th epoch\n",
      "Epoch: 23 ; val_loss = 4.454776632705111\n",
      "Start: 24th epoch\n",
      "Epoch: 24 ; val_loss = 4.453725458747421\n",
      "Start: 25th epoch\n",
      "Epoch: 25 ; val_loss = 4.452754788992907\n",
      "Start: 26th epoch\n",
      "Epoch: 26 ; val_loss = 4.451856532477761\n",
      "Start: 27th epoch\n",
      "Epoch: 27 ; val_loss = 4.4510236358235815\n",
      "Start: 28th epoch\n",
      "Epoch: 28 ; val_loss = 4.450249919609095\n",
      "Start: 29th epoch\n",
      "Epoch: 29 ; val_loss = 4.449529944420713\n",
      "Start: 30th epoch\n",
      "Epoch: 30 ; val_loss = 4.448858900919888\n",
      "Start: 31th epoch\n",
      "Epoch: 31 ; val_loss = 4.44823251932408\n",
      "Start: 32th epoch\n",
      "Epoch: 32 ; val_loss = 4.4476469945707215\n",
      "Start: 33th epoch\n",
      "Epoch: 33 ; val_loss = 4.44709892415603\n",
      "Start: 34th epoch\n",
      "Epoch: 34 ; val_loss = 4.446585256224851\n",
      "Start: 35th epoch\n",
      "Epoch: 35 ; val_loss = 4.446103245974372\n",
      "Start: 36th epoch\n",
      "Epoch: 36 ; val_loss = 4.445650418820647\n",
      "Start: 37th epoch\n",
      "Epoch: 37 ; val_loss = 4.445224539083091\n",
      "Start: 38th epoch\n",
      "Epoch: 38 ; val_loss = 4.444823583205573\n",
      "Start: 39th epoch\n",
      "Epoch: 39 ; val_loss = 4.444445716714053\n",
      "Start: 40th epoch\n",
      "Epoch: 40 ; val_loss = 4.4440892742804765\n",
      "Start: 41th epoch\n",
      "Epoch: 41 ; val_loss = 4.443752742383776\n",
      "Start: 42th epoch\n",
      "Epoch: 42 ; val_loss = 4.443434744151654\n",
      "Start: 43th epoch\n",
      "Epoch: 43 ; val_loss = 4.443134026054454\n",
      "Start: 44th epoch\n",
      "Epoch: 44 ; val_loss = 4.4428494461748995\n",
      "Start: 45th epoch\n",
      "Epoch: 45 ; val_loss = 4.442579963831426\n",
      "Start: 46th epoch\n",
      "Epoch: 46 ; val_loss = 4.442324630371414\n",
      "Start: 47th epoch\n",
      "Epoch: 47 ; val_loss = 4.442082580979334\n",
      "Start: 48th epoch\n",
      "Epoch: 48 ; val_loss = 4.441853027370507\n",
      "Start: 49th epoch\n",
      "Epoch: 49 ; val_loss = 4.4416352512640325\n",
      "Start: 50th epoch\n",
      "Epoch: 50 ; val_loss = 4.441428598539782\n",
      "Start: 51th epoch\n",
      "Epoch: 51 ; val_loss = 4.441232474003328\n",
      "Start: 52th epoch\n",
      "Epoch: 52 ; val_loss = 4.441046336688439\n",
      "Start: 53th epoch\n",
      "Epoch: 53 ; val_loss = 4.440869695639056\n",
      "Start: 54th epoch\n",
      "Epoch: 54 ; val_loss = 4.440702106118847\n",
      "Start: 55th epoch\n",
      "Epoch: 55 ; val_loss = 4.440543166204826\n",
      "Start: 56th epoch\n",
      "Epoch: 56 ; val_loss = 4.440392513723012\n",
      "Start: 57th epoch\n",
      "Epoch: 57 ; val_loss = 4.440249823491123\n",
      "Start: 58th epoch\n",
      "Epoch: 58 ; val_loss = 4.440114804839788\n",
      "Start: 59th epoch\n",
      "Epoch: 59 ; val_loss = 4.439987199379934\n",
      "Start: 60th epoch\n",
      "Epoch: 60 ; val_loss = 4.439866778993204\n",
      "Start: 61th epoch\n",
      "Epoch: 61 ; val_loss = 4.439753344023406\n",
      "Start: 62th epoch\n",
      "Epoch: 62 ; val_loss = 4.4396467216450874\n",
      "Start: 63th epoch\n",
      "Epoch: 63 ; val_loss = 4.439546764393914\n",
      "Start: 64th epoch\n",
      "Epoch: 64 ; val_loss = 4.439453348837168\n",
      "Start: 65th epoch\n",
      "Epoch: 65 ; val_loss = 4.439366374371435\n",
      "Start: 66th epoch\n",
      "Epoch: 66 ; val_loss = 4.439285762130172\n",
      "Start: 67th epoch\n",
      "Epoch: 67 ; val_loss = 4.4392114539879355\n",
      "Start: 68th epoch\n",
      "Epoch: 68 ; val_loss = 4.439143411646188\n",
      "Start: 69th epoch\n",
      "Epoch: 69 ; val_loss = 4.439081615790418\n",
      "Start: 70th epoch\n",
      "Epoch: 70 ; val_loss = 4.439026065301735\n",
      "Start: 71th epoch\n",
      "Epoch: 71 ; val_loss = 4.438976776515153\n",
      "Start: 72th epoch\n",
      "Epoch: 72 ; val_loss = 4.438933782511076\n",
      "Start: 73th epoch\n",
      "Epoch: 73 ; val_loss = 4.438897132426043\n",
      "Start: 74th epoch\n",
      "Epoch: 74 ; val_loss = 4.438866890775726\n",
      "Start: 75th epoch\n",
      "Epoch: 75 ; val_loss = 4.438843136774756\n",
      "Start: 76th epoch\n",
      "Epoch: 76 ; val_loss = 4.438825963644915\n",
      "Start: 77th epoch\n",
      "Epoch: 77 ; val_loss = 4.438815477897301\n",
      "Start: 78th epoch\n",
      "Epoch: 78 ; val_loss = 4.438811798582026\n",
      "Start: 79th epoch\n",
      "Epoch: 79 ; val_loss = 4.438815056489068\n",
      "Start: 80th epoch\n",
      "Epoch: 80 ; val_loss = 4.438825393292734\n",
      "Start: 81th epoch\n",
      "Epoch: 81 ; val_loss = 4.438842960628705\n",
      "Start: 82th epoch\n",
      "Epoch: 82 ; val_loss = 4.438867919092533\n",
      "Start: 83th epoch\n",
      "Epoch: 83 ; val_loss = 4.43890043714909\n",
      "Start: 84th epoch\n",
      "Epoch: 84 ; val_loss = 4.43894068994597\n",
      "Start: 85th epoch\n",
      "Epoch: 85 ; val_loss = 4.438988858020392\n",
      "Start: 86th epoch\n",
      "Epoch: 86 ; val_loss = 4.439045125891563\n",
      "Start: 87th epoch\n",
      "Epoch: 87 ; val_loss = 4.439109680535891\n",
      "Start: 88th epoch\n",
      "Epoch: 88 ; val_loss = 4.439182709736026\n",
      "Start: 89th epoch\n",
      "Epoch: 89 ; val_loss = 4.439264400303512\n",
      "Start: 90th epoch\n",
      "Epoch: 90 ; val_loss = 4.439354936173849\n",
      "Start: 91th epoch\n",
      "Epoch: 91 ; val_loss = 4.4394544963743074\n",
      "Start: 92th epoch\n",
      "Epoch: 92 ; val_loss = 4.4395632528708635\n",
      "Start: 93th epoch\n",
      "Epoch: 93 ; val_loss = 4.439681368301103\n",
      "Start: 94th epoch\n",
      "Epoch: 94 ; val_loss = 4.439808993601071\n",
      "Start: 95th epoch\n",
      "Epoch: 95 ; val_loss = 4.439946265545301\n",
      "Start: 96th epoch\n",
      "Epoch: 96 ; val_loss = 4.440093304213442\n",
      "Start: 97th epoch\n",
      "Epoch: 97 ; val_loss = 4.440250210407986\n",
      "Start: 98th epoch\n",
      "Epoch: 98 ; val_loss = 4.440417063046847\n",
      "Start: 99th epoch\n",
      "Epoch: 99 ; val_loss = 4.440593916562878\n",
      "Start: 100th epoch\n",
      "Epoch: 100 ; val_loss = 4.440780798339501\n",
      "Start: 101th epoch\n",
      "Epoch: 101 ; val_loss = 4.4409777062252305\n",
      "Start: 102th epoch\n",
      "Epoch: 102 ; val_loss = 4.441184606157406\n",
      "Start: 103th epoch\n",
      "Epoch: 103 ; val_loss = 4.441401429946828\n",
      "Start: 104th epoch\n",
      "Epoch: 104 ; val_loss = 4.441628073258825\n",
      "Start: 105th epoch\n",
      "Epoch: 105 ; val_loss = 4.441864393837238\n",
      "Start: 106th epoch\n",
      "Epoch: 106 ; val_loss = 4.442110210017606\n",
      "Start: 107th epoch\n",
      "Epoch: 107 ; val_loss = 4.442365299566265\n",
      "Start: 108th epoch\n",
      "Epoch: 108 ; val_loss = 4.4426293988882986\n",
      "Start: 109th epoch\n",
      "Epoch: 109 ; val_loss = 4.442902202640579\n",
      "Start: 110th epoch\n",
      "Epoch: 110 ; val_loss = 4.443183363777179\n",
      "Start: 111th epoch\n",
      "Epoch: 111 ; val_loss = 4.4434724940536\n",
      "Start: 112th epoch\n",
      "Epoch: 112 ; val_loss = 4.443769165006991\n",
      "Start: 113th epoch\n",
      "Epoch: 113 ; val_loss = 4.444072909417944\n",
      "Start: 114th epoch\n",
      "Epoch: 114 ; val_loss = 4.444383223256287\n",
      "Start: 115th epoch\n",
      "Epoch: 115 ; val_loss = 4.444699568098541\n",
      "Start: 116th epoch\n",
      "Epoch: 116 ; val_loss = 4.445021373999185\n",
      "Start: 117th epoch\n",
      "Epoch: 117 ; val_loss = 4.445348042782106\n",
      "Start: 118th epoch\n",
      "Epoch: 118 ; val_loss = 4.445678951716435\n",
      "Start: 119th epoch\n",
      "Epoch: 119 ; val_loss = 4.44601345752882\n",
      "Start: 120th epoch\n",
      "Epoch: 120 ; val_loss = 4.446350900692213\n",
      "Start: 121th epoch\n",
      "Epoch: 121 ; val_loss = 4.446690609935706\n",
      "Start: 122th epoch\n",
      "Epoch: 122 ; val_loss = 4.447031906901935\n",
      "Start: 123th epoch\n",
      "Epoch: 123 ; val_loss = 4.4473741108884\n",
      "Start: 124th epoch\n",
      "Epoch: 124 ; val_loss = 4.447716543594292\n",
      "Start: 125th epoch\n",
      "Epoch: 125 ; val_loss = 4.448058533806747\n",
      "Start: 126th epoch\n",
      "Epoch: 126 ; val_loss = 4.448399421955646\n",
      "Start: 127th epoch\n",
      "Epoch: 127 ; val_loss = 4.448738564470728\n",
      "Start: 128th epoch\n",
      "Epoch: 128 ; val_loss = 4.449075337882486\n",
      "Start: 129th epoch\n",
      "Epoch: 129 ; val_loss = 4.44940914261489\n",
      "Start: 130th epoch\n",
      "Epoch: 130 ; val_loss = 4.449739406418127\n",
      "Start: 131th epoch\n",
      "Epoch: 131 ; val_loss = 4.450065587415813\n",
      "Start: 132th epoch\n",
      "Epoch: 132 ; val_loss = 4.450387176727424\n",
      "Start: 133th epoch\n",
      "Epoch: 133 ; val_loss = 4.450703700654946\n",
      "Start: 134th epoch\n",
      "Epoch: 134 ; val_loss = 4.451014722421214\n",
      "Start: 135th epoch\n",
      "Epoch: 135 ; val_loss = 4.451319843461008\n",
      "Start: 136th epoch\n",
      "Epoch: 136 ; val_loss = 4.451618704271535\n",
      "Start: 137th epoch\n",
      "Epoch: 137 ; val_loss = 4.451910984837519\n",
      "Start: 138th epoch\n",
      "Epoch: 138 ; val_loss = 4.4521964046547025\n",
      "Start: 139th epoch\n",
      "Epoch: 139 ; val_loss = 4.4524747223747125\n",
      "Start: 140th epoch\n",
      "Epoch: 140 ; val_loss = 4.452745735108351\n",
      "Start: 141th epoch\n",
      "Epoch: 141 ; val_loss = 4.453009277417466\n",
      "Start: 142th epoch\n",
      "Epoch: 142 ; val_loss = 4.453265220034613\n",
      "Start: 143th epoch\n",
      "Epoch: 143 ; val_loss = 4.453513468350521\n",
      "Start: 144th epoch\n",
      "Epoch: 144 ; val_loss = 4.453753960703475\n",
      "Start: 145th epoch\n",
      "Epoch: 145 ; val_loss = 4.453986666514293\n",
      "Start: 146th epoch\n",
      "Epoch: 146 ; val_loss = 4.45421158429884\n",
      "Start: 147th epoch\n",
      "Epoch: 147 ; val_loss = 4.454428739595133\n",
      "Start: 148th epoch\n",
      "Epoch: 148 ; val_loss = 4.454638182838802\n",
      "Start: 149th epoch\n",
      "Epoch: 149 ; val_loss = 4.4548399872137034\n",
      "Start: 150th epoch\n",
      "Epoch: 150 ; val_loss = 4.455034246506678\n",
      "Start: 151th epoch\n",
      "Epoch: 151 ; val_loss = 4.455221072989785\n",
      "Start: 152th epoch\n",
      "Epoch: 152 ; val_loss = 4.455400595348952\n",
      "Start: 153th epoch\n",
      "Epoch: 153 ; val_loss = 4.455572956681195\n",
      "Start: 154th epoch\n",
      "Epoch: 154 ; val_loss = 4.455738312566559\n",
      "Start: 155th epoch\n",
      "Epoch: 155 ; val_loss = 4.455896829235523\n",
      "Start: 156th epoch\n",
      "Epoch: 156 ; val_loss = 4.4560486818346225\n",
      "Start: 157th epoch\n",
      "Epoch: 157 ; val_loss = 4.456194052797396\n",
      "Start: 158th epoch\n",
      "Epoch: 158 ; val_loss = 4.4563331303286695\n",
      "Start: 159th epoch\n",
      "Epoch: 159 ; val_loss = 4.456466106998023\n",
      "Start: 160th epoch\n",
      "Epoch: 160 ; val_loss = 4.456593178450449\n",
      "Start: 161th epoch\n",
      "Epoch: 161 ; val_loss = 4.456714542224676\n",
      "Start: 162th epoch\n",
      "Epoch: 162 ; val_loss = 4.456830396685788\n",
      "Start: 163th epoch\n",
      "Epoch: 163 ; val_loss = 4.456940940060456\n",
      "Start: 164th epoch\n",
      "Epoch: 164 ; val_loss = 4.45704636957831\n",
      "Start: 165th epoch\n",
      "Epoch: 165 ; val_loss = 4.457146880707026\n",
      "Start: 166th epoch\n",
      "Epoch: 166 ; val_loss = 4.457242666483851\n",
      "Start: 167th epoch\n",
      "Epoch: 167 ; val_loss = 4.457333916930082\n",
      "Start: 168th epoch\n",
      "Epoch: 168 ; val_loss = 4.457420818550022\n",
      "Start: 169th epoch\n",
      "Epoch: 169 ; val_loss = 4.457503553903162\n",
      "Start: 170th epoch\n",
      "Epoch: 170 ; val_loss = 4.457582301245578\n",
      "Start: 171th epoch\n",
      "Epoch: 171 ; val_loss = 4.457657234236734\n",
      "Start: 172th epoch\n",
      "Epoch: 172 ; val_loss = 4.457728521702096\n",
      "Start: 173th epoch\n",
      "Epoch: 173 ; val_loss = 4.457796327450374\n",
      "Start: 174th epoch\n",
      "Epoch: 174 ; val_loss = 4.45786081013642\n",
      "Start: 175th epoch\n",
      "Epoch: 175 ; val_loss = 4.457922123167941\n",
      "Start: 176th epoch\n",
      "Epoch: 176 ; val_loss = 4.457980414649401\n",
      "Start: 177th epoch\n",
      "Epoch: 177 ; val_loss = 4.4580358273596685\n",
      "Start: 178th epoch\n",
      "Epoch: 178 ; val_loss = 4.458088498759402\n",
      "Start: 179th epoch\n",
      "Epoch: 179 ; val_loss = 4.458138561023564\n",
      "Start: 180th epoch\n",
      "Epoch: 180 ; val_loss = 4.458186141097074\n",
      "Start: 181th epoch\n",
      "Epoch: 181 ; val_loss = 4.458231360769047\n",
      "Start: 182th epoch\n",
      "Epoch: 182 ; val_loss = 4.458274336763311\n",
      "Start: 183th epoch\n",
      "Epoch: 183 ; val_loss = 4.45831518084358\n",
      "Start: 184th epoch\n",
      "Epoch: 184 ; val_loss = 4.45835399992843\n",
      "Start: 185th epoch\n",
      "Epoch: 185 ; val_loss = 4.458390896216657\n",
      "Start: 186th epoch\n",
      "Epoch: 186 ; val_loss = 4.458425967319365\n",
      "Start: 187th epoch\n",
      "Epoch: 187 ; val_loss = 4.458459306398076\n",
      "Start: 188th epoch\n",
      "Epoch: 188 ; val_loss = 4.45849100230681\n",
      "Start: 189th epoch\n",
      "Epoch: 189 ; val_loss = 4.458521139736469\n",
      "Start: 190th epoch\n",
      "Epoch: 190 ; val_loss = 4.458549799361864\n",
      "Start: 191th epoch\n",
      "Epoch: 191 ; val_loss = 4.458577057988524\n",
      "Start: 192th epoch\n",
      "Epoch: 192 ; val_loss = 4.458602988699133\n",
      "Start: 193th epoch\n",
      "Epoch: 193 ; val_loss = 4.4586276610002695\n",
      "Start: 194th epoch\n",
      "Epoch: 194 ; val_loss = 4.458651140965348\n",
      "Start: 195th epoch\n",
      "Epoch: 195 ; val_loss = 4.458673491377392\n",
      "Start: 196th epoch\n",
      "Epoch: 196 ; val_loss = 4.458694771868282\n",
      "Start: 197th epoch\n",
      "Epoch: 197 ; val_loss = 4.458715039054368\n",
      "Start: 198th epoch\n",
      "Epoch: 198 ; val_loss = 4.458734346669402\n",
      "Start: 199th epoch\n",
      "Epoch: 199 ; val_loss = 4.458752745694495\n",
      "Start: 200th epoch\n",
      "Epoch: 200 ; val_loss = 4.4587702844826875\n",
      "Start: 201th epoch\n",
      "Epoch: 201 ; val_loss = 4.4587870088809805\n",
      "Start: 202th epoch\n",
      "Epoch: 202 ; val_loss = 4.458802962347445\n",
      "Start: 203th epoch\n",
      "Epoch: 203 ; val_loss = 4.458818186064859\n",
      "Start: 204th epoch\n",
      "Epoch: 204 ; val_loss = 4.458832719049614\n",
      "Start: 205th epoch\n",
      "Epoch: 205 ; val_loss = 4.458846598257381\n",
      "Start: 206th epoch\n",
      "Epoch: 206 ; val_loss = 4.4588598586836286\n",
      "Start: 207th epoch\n",
      "Epoch: 207 ; val_loss = 4.458872533460307\n",
      "Start: 208th epoch\n",
      "Epoch: 208 ; val_loss = 4.458884653950013\n",
      "Start: 209th epoch\n",
      "Epoch: 209 ; val_loss = 4.45889624983323\n",
      "Start: 210th epoch\n",
      "Epoch: 210 ; val_loss = 4.458907349194746\n",
      "Start: 211th epoch\n",
      "Epoch: 211 ; val_loss = 4.458917978605002\n",
      "Start: 212th epoch\n",
      "Epoch: 212 ; val_loss = 4.458928163196984\n",
      "Start: 213th epoch\n",
      "Epoch: 213 ; val_loss = 4.45893792674083\n",
      "Start: 214th epoch\n",
      "Epoch: 214 ; val_loss = 4.458947291715097\n",
      "Start: 215th epoch\n",
      "Epoch: 215 ; val_loss = 4.458956279373505\n",
      "Start: 216th epoch\n",
      "Epoch: 216 ; val_loss = 4.458964909809258\n",
      "Start: 217th epoch\n",
      "Epoch: 217 ; val_loss = 4.4589732020163995\n",
      "Start: 218th epoch\n",
      "Epoch: 218 ; val_loss = 4.45898117394791\n",
      "Start: 219th epoch\n",
      "Epoch: 219 ; val_loss = 4.45898884257084\n",
      "Start: 220th epoch\n",
      "Epoch: 220 ; val_loss = 4.458996223919234\n",
      "Start: 221th epoch\n",
      "Epoch: 221 ; val_loss = 4.459003333143143\n",
      "Start: 222th epoch\n",
      "Epoch: 222 ; val_loss = 4.459010184557569\n",
      "Start: 223th epoch\n",
      "Epoch: 223 ; val_loss = 4.459016791686353\n",
      "Start: 224th epoch\n",
      "Epoch: 224 ; val_loss = 4.459023167305022\n",
      "Start: 225th epoch\n",
      "Epoch: 225 ; val_loss = 4.459029323481283\n",
      "Start: 226th epoch\n",
      "Epoch: 226 ; val_loss = 4.4590352716140895\n",
      "Start: 227th epoch\n",
      "Epoch: 227 ; val_loss = 4.459041022469547\n",
      "Start: 228th epoch\n",
      "Epoch: 228 ; val_loss = 4.459046586215653\n",
      "Start: 229th epoch\n",
      "Epoch: 229 ; val_loss = 4.4590519724540245\n",
      "Start: 230th epoch\n",
      "Epoch: 230 ; val_loss = 4.459057190253154\n",
      "Start: 231th epoch\n",
      "Epoch: 231 ; val_loss = 4.4590622481754005\n",
      "Start: 232th epoch\n",
      "Epoch: 232 ; val_loss = 4.4590671543062035\n",
      "Start: 233th epoch\n",
      "Epoch: 233 ; val_loss = 4.4590719162798305\n",
      "Start: 234th epoch\n",
      "Epoch: 234 ; val_loss = 4.459076541304361\n",
      "Start: 235th epoch\n",
      "Epoch: 235 ; val_loss = 4.459081036185981\n",
      "Start: 236th epoch\n",
      "Epoch: 236 ; val_loss = 4.45908540734948\n",
      "Start: 237th epoch\n",
      "Epoch: 237 ; val_loss = 4.459089660861791\n",
      "Start: 238th epoch\n",
      "Epoch: 238 ; val_loss = 4.459093802450134\n",
      "Start: 239th epoch\n",
      "Epoch: 239 ; val_loss = 4.459097837521247\n",
      "Start: 240th epoch\n",
      "Epoch: 240 ; val_loss = 4.459101771179912\n",
      "Start: 241th epoch\n",
      "Epoch: 241 ; val_loss = 4.459105608245105\n",
      "Start: 242th epoch\n",
      "Epoch: 242 ; val_loss = 4.459109353266347\n",
      "Start: 243th epoch\n",
      "Epoch: 243 ; val_loss = 4.459113010538706\n",
      "Start: 244th epoch\n",
      "Epoch: 244 ; val_loss = 4.459116584117238\n",
      "Start: 245th epoch\n",
      "Epoch: 245 ; val_loss = 4.459120077829621\n",
      "Start: 246th epoch\n",
      "Epoch: 246 ; val_loss = 4.459123495290379\n",
      "Start: 247th epoch\n",
      "Epoch: 247 ; val_loss = 4.4591268399115815\n",
      "Start: 248th epoch\n",
      "Epoch: 248 ; val_loss = 4.4591301149147045\n",
      "Start: 249th epoch\n",
      "Epoch: 249 ; val_loss = 4.459133323341617\n",
      "Start: 250th epoch\n",
      "Epoch: 250 ; val_loss = 4.459136468064318\n",
      "Start: 251th epoch\n",
      "Epoch: 251 ; val_loss = 4.459139551794938\n",
      "Start: 252th epoch\n",
      "Epoch: 252 ; val_loss = 4.4591425770943225\n",
      "Start: 253th epoch\n",
      "Epoch: 253 ; val_loss = 4.45914554638087\n",
      "Start: 254th epoch\n",
      "Epoch: 254 ; val_loss = 4.459148461938627\n",
      "Start: 255th epoch\n",
      "Epoch: 255 ; val_loss = 4.459151325924913\n",
      "Start: 256th epoch\n",
      "Epoch: 256 ; val_loss = 4.459154140377387\n",
      "Start: 257th epoch\n",
      "Epoch: 257 ; val_loss = 4.45915690722097\n",
      "Start: 258th epoch\n",
      "Epoch: 258 ; val_loss = 4.459159628273993\n",
      "Start: 259th epoch\n",
      "Epoch: 259 ; val_loss = 4.459162305254948\n",
      "Start: 260th epoch\n",
      "Epoch: 260 ; val_loss = 4.459164939787356\n",
      "Start: 261th epoch\n",
      "Epoch: 261 ; val_loss = 4.459167533405671\n",
      "Start: 262th epoch\n",
      "Epoch: 262 ; val_loss = 4.4591700875601585\n",
      "Start: 263th epoch\n",
      "Epoch: 263 ; val_loss = 4.459172603622202\n",
      "Start: 264th epoch\n",
      "Epoch: 264 ; val_loss = 4.459175082888094\n",
      "Start: 265th epoch\n",
      "Epoch: 265 ; val_loss = 4.459177526583744\n",
      "Start: 266th epoch\n",
      "Epoch: 266 ; val_loss = 4.459179935868792\n",
      "Start: 267th epoch\n",
      "Epoch: 267 ; val_loss = 4.459182311839964\n",
      "Start: 268th epoch\n",
      "Epoch: 268 ; val_loss = 4.4591846555356955\n",
      "Start: 269th epoch\n",
      "Epoch: 269 ; val_loss = 4.459186967938282\n",
      "Start: 270th epoch\n",
      "Epoch: 270 ; val_loss = 4.459189249977421\n",
      "Start: 271th epoch\n",
      "Epoch: 271 ; val_loss = 4.459191502534218\n",
      "Start: 272th epoch\n",
      "Epoch: 272 ; val_loss = 4.45919372644243\n",
      "Start: 273th epoch\n",
      "Epoch: 273 ; val_loss = 4.459195922493112\n",
      "Start: 274th epoch\n",
      "Epoch: 274 ; val_loss = 4.459198091434686\n",
      "Start: 275th epoch\n",
      "Epoch: 275 ; val_loss = 4.459200233977976\n",
      "Start: 276th epoch\n",
      "Epoch: 276 ; val_loss = 4.459202350796307\n",
      "Start: 277th epoch\n",
      "Epoch: 277 ; val_loss = 4.459204442528708\n",
      "Start: 278th epoch\n",
      "Epoch: 278 ; val_loss = 4.459206509781766\n",
      "Start: 279th epoch\n",
      "Epoch: 279 ; val_loss = 4.459208553131767\n",
      "Start: 280th epoch\n",
      "Epoch: 280 ; val_loss = 4.45921057312581\n",
      "Start: 281th epoch\n",
      "Epoch: 281 ; val_loss = 4.45921257028418\n",
      "Start: 282th epoch\n",
      "Epoch: 282 ; val_loss = 4.459214545101012\n",
      "Start: 283th epoch\n",
      "Epoch: 283 ; val_loss = 4.459216498047232\n",
      "Start: 284th epoch\n",
      "Epoch: 284 ; val_loss = 4.459218429570497\n",
      "Start: 285th epoch\n",
      "Epoch: 285 ; val_loss = 4.4592203400973185\n",
      "Start: 286th epoch\n",
      "Epoch: 286 ; val_loss = 4.459222230034568\n",
      "Start: 287th epoch\n",
      "Epoch: 287 ; val_loss = 4.459224099769311\n",
      "Start: 288th epoch\n",
      "Epoch: 288 ; val_loss = 4.459225949671624\n",
      "Start: 289th epoch\n",
      "Epoch: 289 ; val_loss = 4.459227780094811\n",
      "Start: 290th epoch\n",
      "Epoch: 290 ; val_loss = 4.459229591375828\n",
      "Start: 291th epoch\n",
      "Epoch: 291 ; val_loss = 4.459231383837448\n",
      "Start: 292th epoch\n",
      "Epoch: 292 ; val_loss = 4.45923315778833\n",
      "Start: 293th epoch\n",
      "Epoch: 293 ; val_loss = 4.459234913523886\n",
      "Start: 294th epoch\n",
      "Epoch: 294 ; val_loss = 4.459236651327072\n",
      "Start: 295th epoch\n",
      "Epoch: 295 ; val_loss = 4.459238371469934\n",
      "Start: 296th epoch\n",
      "Epoch: 296 ; val_loss = 4.459240074212714\n",
      "Start: 297th epoch\n",
      "Epoch: 297 ; val_loss = 4.459241759805762\n",
      "Start: 298th epoch\n",
      "Epoch: 298 ; val_loss = 4.459243428489525\n",
      "Start: 299th epoch\n",
      "Epoch: 299 ; val_loss = 4.459245080496054\n",
      "Start: 300th epoch\n",
      "Epoch: 300 ; val_loss = 4.459246716048029\n",
      "Start: 301th epoch\n",
      "Epoch: 301 ; val_loss = 4.459248335360476\n",
      "Start: 302th epoch\n",
      "Epoch: 302 ; val_loss = 4.459249938640773\n",
      "Start: 303th epoch\n",
      "Epoch: 303 ; val_loss = 4.459251526089089\n",
      "Start: 304th epoch\n",
      "Epoch: 304 ; val_loss = 4.459253097899029\n",
      "Start: 305th epoch\n",
      "Epoch: 305 ; val_loss = 4.459254654257799\n",
      "Start: 306th epoch\n",
      "Epoch: 306 ; val_loss = 4.459256195346518\n",
      "Start: 307th epoch\n",
      "Epoch: 307 ; val_loss = 4.459257721341063\n",
      "Start: 308th epoch\n",
      "Epoch: 308 ; val_loss = 4.459259232412041\n",
      "Start: 309th epoch\n",
      "Epoch: 309 ; val_loss = 4.459260728724896\n",
      "Start: 310th epoch\n",
      "Epoch: 310 ; val_loss = 4.459262210439938\n",
      "Start: 311th epoch\n",
      "Epoch: 311 ; val_loss = 4.459263677714318\n",
      "Start: 312th epoch\n",
      "Epoch: 312 ; val_loss = 4.459265130699907\n",
      "Start: 313th epoch\n",
      "Epoch: 313 ; val_loss = 4.459266569545149\n",
      "Start: 314th epoch\n",
      "Epoch: 314 ; val_loss = 4.459267994394933\n",
      "Start: 315th epoch\n",
      "Epoch: 315 ; val_loss = 4.459269405390654\n",
      "Start: 316th epoch\n",
      "Epoch: 316 ; val_loss = 4.459270802670304\n",
      "Start: 317th epoch\n",
      "Epoch: 317 ; val_loss = 4.459272186368634\n",
      "Start: 318th epoch\n",
      "Epoch: 318 ; val_loss = 4.459273556617961\n",
      "Start: 319th epoch\n",
      "Epoch: 319 ; val_loss = 4.459274913547711\n",
      "Start: 320th epoch\n",
      "Epoch: 320 ; val_loss = 4.459276257284647\n",
      "Start: 321th epoch\n",
      "Epoch: 321 ; val_loss = 4.459277587952926\n",
      "Start: 322th epoch\n",
      "Epoch: 322 ; val_loss = 4.459278905674767\n",
      "Start: 323th epoch\n",
      "Epoch: 323 ; val_loss = 4.4592802105701175\n",
      "Start: 324th epoch\n",
      "Epoch: 324 ; val_loss = 4.459281502756706\n",
      "Start: 325th epoch\n",
      "Epoch: 325 ; val_loss = 4.459282782350459\n",
      "Start: 326th epoch\n",
      "Epoch: 326 ; val_loss = 4.459284049465546\n",
      "Start: 327th epoch\n",
      "Epoch: 327 ; val_loss = 4.459285304213979\n",
      "Start: 328th epoch\n",
      "Epoch: 328 ; val_loss = 4.459286546706775\n",
      "Start: 329th epoch\n",
      "Epoch: 329 ; val_loss = 4.45928777705285\n",
      "Start: 330th epoch\n",
      "Epoch: 330 ; val_loss = 4.4592889953597705\n",
      "Start: 331th epoch\n",
      "Epoch: 331 ; val_loss = 4.459290201733864\n",
      "Start: 332th epoch\n",
      "Epoch: 332 ; val_loss = 4.459291396279832\n",
      "Start: 333th epoch\n",
      "Epoch: 333 ; val_loss = 4.459292579101549\n",
      "Start: 334th epoch\n",
      "Epoch: 334 ; val_loss = 4.4592937503010806\n",
      "Start: 335th epoch\n",
      "Epoch: 335 ; val_loss = 4.459294909979625\n",
      "Start: 336th epoch\n",
      "Epoch: 336 ; val_loss = 4.459296058237248\n",
      "Start: 337th epoch\n",
      "Epoch: 337 ; val_loss = 4.459297195173062\n",
      "Start: 338th epoch\n",
      "Epoch: 338 ; val_loss = 4.459298320884974\n",
      "Start: 339th epoch\n",
      "Epoch: 339 ; val_loss = 4.459299435469884\n",
      "Start: 340th epoch\n",
      "Epoch: 340 ; val_loss = 4.4593005390241505\n",
      "Start: 341th epoch\n",
      "Epoch: 341 ; val_loss = 4.459301631642722\n",
      "Start: 342th epoch\n",
      "Epoch: 342 ; val_loss = 4.459302713419906\n",
      "Start: 343th epoch\n",
      "Epoch: 343 ; val_loss = 4.4593037844494186\n",
      "Start: 344th epoch\n",
      "Epoch: 344 ; val_loss = 4.45930484482315\n",
      "Start: 345th epoch\n",
      "Epoch: 345 ; val_loss = 4.459305894633835\n",
      "Start: 346th epoch\n",
      "Epoch: 346 ; val_loss = 4.459306933972201\n",
      "Start: 347th epoch\n",
      "Epoch: 347 ; val_loss = 4.459307962928674\n",
      "Start: 348th epoch\n",
      "Epoch: 348 ; val_loss = 4.4593089815928435\n",
      "Start: 349th epoch\n",
      "Epoch: 349 ; val_loss = 4.459309990053797\n",
      "Start: 350th epoch\n",
      "Epoch: 350 ; val_loss = 4.459310988399664\n",
      "Start: 351th epoch\n",
      "Epoch: 351 ; val_loss = 4.459311976718211\n",
      "Start: 352th epoch\n",
      "Epoch: 352 ; val_loss = 4.4593129550965\n",
      "Start: 353th epoch\n",
      "Epoch: 353 ; val_loss = 4.459313923620716\n",
      "Start: 354th epoch\n",
      "Epoch: 354 ; val_loss = 4.45931488237659\n",
      "Start: 355th epoch\n",
      "Epoch: 355 ; val_loss = 4.459315831449554\n",
      "Start: 356th epoch\n",
      "Epoch: 356 ; val_loss = 4.459316770923872\n",
      "Start: 357th epoch\n",
      "Epoch: 357 ; val_loss = 4.459317700883471\n",
      "Start: 358th epoch\n",
      "Epoch: 358 ; val_loss = 4.459318621412186\n",
      "Start: 359th epoch\n",
      "Epoch: 359 ; val_loss = 4.459319532592392\n",
      "Start: 360th epoch\n",
      "Epoch: 360 ; val_loss = 4.4593204345066315\n",
      "Start: 361th epoch\n",
      "Epoch: 361 ; val_loss = 4.459321327236623\n",
      "Start: 362th epoch\n",
      "Epoch: 362 ; val_loss = 4.459322210863514\n",
      "Start: 363th epoch\n",
      "Epoch: 363 ; val_loss = 4.459323085467833\n",
      "Start: 364th epoch\n",
      "Epoch: 364 ; val_loss = 4.459323951129979\n",
      "Start: 365th epoch\n",
      "Epoch: 365 ; val_loss = 4.459324807929235\n",
      "Start: 366th epoch\n",
      "Epoch: 366 ; val_loss = 4.459325655945083\n",
      "Start: 367th epoch\n",
      "Epoch: 367 ; val_loss = 4.459326495255732\n",
      "Start: 368th epoch\n",
      "Epoch: 368 ; val_loss = 4.459327325939364\n",
      "Start: 369th epoch\n",
      "Epoch: 369 ; val_loss = 4.459328148073415\n",
      "Start: 370th epoch\n",
      "Epoch: 370 ; val_loss = 4.459328961735253\n",
      "Start: 371th epoch\n",
      "Epoch: 371 ; val_loss = 4.459329767001144\n",
      "Start: 372th epoch\n",
      "Epoch: 372 ; val_loss = 4.459330563947208\n",
      "Start: 373th epoch\n",
      "Epoch: 373 ; val_loss = 4.4593313526488085\n",
      "Start: 374th epoch\n",
      "Epoch: 374 ; val_loss = 4.459332133181393\n",
      "Start: 375th epoch\n",
      "Epoch: 375 ; val_loss = 4.4593329056189575\n",
      "Start: 376th epoch\n",
      "Epoch: 376 ; val_loss = 4.459333670035955\n",
      "Start: 377th epoch\n",
      "Epoch: 377 ; val_loss = 4.459334426505683\n",
      "Start: 378th epoch\n",
      "Epoch: 378 ; val_loss = 4.459335175101445\n",
      "Start: 379th epoch\n",
      "Epoch: 379 ; val_loss = 4.459335915895841\n",
      "Start: 380th epoch\n",
      "Epoch: 380 ; val_loss = 4.4593366489609165\n",
      "Start: 381th epoch\n",
      "Epoch: 381 ; val_loss = 4.459337374367794\n",
      "Start: 382th epoch\n",
      "Epoch: 382 ; val_loss = 4.459338092188302\n",
      "Start: 383th epoch\n",
      "Epoch: 383 ; val_loss = 4.459338802492555\n",
      "Start: 384th epoch\n",
      "Epoch: 384 ; val_loss = 4.459339505351041\n",
      "Start: 385th epoch\n",
      "Epoch: 385 ; val_loss = 4.4593402008333065\n",
      "Start: 386th epoch\n",
      "Epoch: 386 ; val_loss = 4.459340889008482\n",
      "Start: 387th epoch\n",
      "Epoch: 387 ; val_loss = 4.459341569945347\n",
      "Start: 388th epoch\n",
      "Epoch: 388 ; val_loss = 4.459342243712196\n",
      "Start: 389th epoch\n",
      "Epoch: 389 ; val_loss = 4.459342910376484\n",
      "Start: 390th epoch\n",
      "Epoch: 390 ; val_loss = 4.45934357000588\n",
      "Start: 391th epoch\n",
      "Epoch: 391 ; val_loss = 4.459344222666756\n",
      "Start: 392th epoch\n",
      "Epoch: 392 ; val_loss = 4.4593448684255845\n",
      "Start: 393th epoch\n",
      "Epoch: 393 ; val_loss = 4.459345507348289\n",
      "Start: 394th epoch\n",
      "Epoch: 394 ; val_loss = 4.459346139500147\n",
      "Start: 395th epoch\n",
      "Epoch: 395 ; val_loss = 4.459346764945861\n",
      "Start: 396th epoch\n",
      "Epoch: 396 ; val_loss = 4.459347383750201\n",
      "Start: 397th epoch\n",
      "Epoch: 397 ; val_loss = 4.4593479959769065\n",
      "Start: 398th epoch\n",
      "Epoch: 398 ; val_loss = 4.459348601688965\n",
      "Start: 399th epoch\n",
      "Epoch: 399 ; val_loss = 4.45934920095035\n",
      "Start: 400th epoch\n",
      "Epoch: 400 ; val_loss = 4.459349793822645\n",
      "Start: 401th epoch\n",
      "Epoch: 401 ; val_loss = 4.459350380368238\n",
      "Start: 402th epoch\n",
      "Epoch: 402 ; val_loss = 4.459350960648791\n",
      "Start: 403th epoch\n",
      "Epoch: 403 ; val_loss = 4.459351534725155\n",
      "Start: 404th epoch\n",
      "Epoch: 404 ; val_loss = 4.4593521026581815\n",
      "Start: 405th epoch\n",
      "Epoch: 405 ; val_loss = 4.459352664507954\n",
      "Start: 406th epoch\n",
      "Epoch: 406 ; val_loss = 4.459353220334088\n",
      "Start: 407th epoch\n",
      "Epoch: 407 ; val_loss = 4.459353770195869\n",
      "Start: 408th epoch\n",
      "Epoch: 408 ; val_loss = 4.459354314151924\n",
      "Start: 409th epoch\n",
      "Epoch: 409 ; val_loss = 4.459354852260577\n",
      "Start: 410th epoch\n",
      "Epoch: 410 ; val_loss = 4.459355384579948\n",
      "Start: 411th epoch\n",
      "Epoch: 411 ; val_loss = 4.459355911167103\n",
      "Start: 412th epoch\n",
      "Epoch: 412 ; val_loss = 4.459356432078952\n",
      "Start: 413th epoch\n",
      "Epoch: 413 ; val_loss = 4.459356947372148\n",
      "Start: 414th epoch\n",
      "Epoch: 414 ; val_loss = 4.459357457102506\n",
      "Start: 415th epoch\n",
      "Epoch: 415 ; val_loss = 4.459357961325692\n",
      "Start: 416th epoch\n",
      "Epoch: 416 ; val_loss = 4.459358460096525\n",
      "Start: 417th epoch\n",
      "Epoch: 417 ; val_loss = 4.459358953470014\n",
      "Start: 418th epoch\n",
      "Epoch: 418 ; val_loss = 4.459359441500239\n",
      "Start: 419th epoch\n",
      "Epoch: 419 ; val_loss = 4.459359924240673\n",
      "Start: 420th epoch\n",
      "Epoch: 420 ; val_loss = 4.459360401744923\n",
      "Start: 421th epoch\n",
      "Epoch: 421 ; val_loss = 4.4593608740656\n",
      "Start: 422th epoch\n",
      "Epoch: 422 ; val_loss = 4.459361341255203\n",
      "Start: 423th epoch\n",
      "Epoch: 423 ; val_loss = 4.459361803365666\n",
      "Start: 424th epoch\n",
      "Epoch: 424 ; val_loss = 4.459362260448681\n",
      "Start: 425th epoch\n",
      "Epoch: 425 ; val_loss = 4.459362712555023\n",
      "Start: 426th epoch\n",
      "Epoch: 426 ; val_loss = 4.459363159735309\n",
      "Start: 427th epoch\n",
      "Epoch: 427 ; val_loss = 4.459363602040097\n",
      "Start: 428th epoch\n",
      "Epoch: 428 ; val_loss = 4.459364039518885\n",
      "Start: 429th epoch\n",
      "Epoch: 429 ; val_loss = 4.459364472221035\n",
      "Start: 430th epoch\n",
      "Epoch: 430 ; val_loss = 4.459364900195471\n",
      "Start: 431th epoch\n",
      "Epoch: 431 ; val_loss = 4.4593653234907675\n",
      "Start: 432th epoch\n",
      "Epoch: 432 ; val_loss = 4.459365742154766\n",
      "Start: 433th epoch\n",
      "Epoch: 433 ; val_loss = 4.459366156235427\n",
      "Start: 434th epoch\n",
      "Epoch: 434 ; val_loss = 4.459366565779504\n",
      "Start: 435th epoch\n",
      "Epoch: 435 ; val_loss = 4.45936697083416\n",
      "Start: 436th epoch\n",
      "Epoch: 436 ; val_loss = 4.459367371445669\n",
      "Start: 437th epoch\n",
      "Epoch: 437 ; val_loss = 4.459367767660048\n",
      "Start: 438th epoch\n",
      "Epoch: 438 ; val_loss = 4.459368159522639\n",
      "Start: 439th epoch\n",
      "Epoch: 439 ; val_loss = 4.459368547078888\n",
      "Start: 440th epoch\n",
      "Epoch: 440 ; val_loss = 4.459368930372997\n",
      "Start: 441th epoch\n",
      "Epoch: 441 ; val_loss = 4.459369309449888\n",
      "Start: 442th epoch\n",
      "Epoch: 442 ; val_loss = 4.459369684353325\n",
      "Start: 443th epoch\n",
      "Epoch: 443 ; val_loss = 4.459370055126707\n",
      "Start: 444th epoch\n",
      "Epoch: 444 ; val_loss = 4.459370421813052\n",
      "Start: 445th epoch\n",
      "Epoch: 445 ; val_loss = 4.45937078445525\n",
      "Start: 446th epoch\n",
      "Epoch: 446 ; val_loss = 4.459371143095659\n",
      "Start: 447th epoch\n",
      "Epoch: 447 ; val_loss = 4.45937149777623\n",
      "Start: 448th epoch\n",
      "Epoch: 448 ; val_loss = 4.4593718485383445\n",
      "Start: 449th epoch\n",
      "Epoch: 449 ; val_loss = 4.459372195423404\n",
      "Start: 450th epoch\n",
      "Epoch: 450 ; val_loss = 4.459372538471922\n",
      "Start: 451th epoch\n",
      "Epoch: 451 ; val_loss = 4.459372877724511\n",
      "Start: 452th epoch\n",
      "Epoch: 452 ; val_loss = 4.45937321322113\n",
      "Start: 453th epoch\n",
      "Epoch: 453 ; val_loss = 4.459373545001294\n",
      "Start: 454th epoch\n",
      "Epoch: 454 ; val_loss = 4.459373873104683\n",
      "Start: 455th epoch\n",
      "Epoch: 455 ; val_loss = 4.459374197569705\n",
      "Start: 456th epoch\n",
      "Epoch: 456 ; val_loss = 4.459374518435112\n",
      "Start: 457th epoch\n",
      "Epoch: 457 ; val_loss = 4.459374835739093\n",
      "Start: 458th epoch\n",
      "Epoch: 458 ; val_loss = 4.459375149519428\n",
      "Start: 459th epoch\n",
      "Epoch: 459 ; val_loss = 4.459375459813443\n",
      "Start: 460th epoch\n",
      "Epoch: 460 ; val_loss = 4.459375766658229\n",
      "Start: 461th epoch\n",
      "Epoch: 461 ; val_loss = 4.459376070090677\n",
      "Start: 462th epoch\n",
      "Epoch: 462 ; val_loss = 4.459376370147171\n",
      "Start: 463th epoch\n",
      "Epoch: 463 ; val_loss = 4.459376666863491\n",
      "Start: 464th epoch\n",
      "Epoch: 464 ; val_loss = 4.459376960275255\n",
      "Start: 465th epoch\n",
      "Epoch: 465 ; val_loss = 4.459377250418252\n",
      "Start: 466th epoch\n",
      "Epoch: 466 ; val_loss = 4.459377537327231\n",
      "Start: 467th epoch\n",
      "Epoch: 467 ; val_loss = 4.4593778210364405\n",
      "Start: 468th epoch\n",
      "Epoch: 468 ; val_loss = 4.459378101580724\n",
      "Start: 469th epoch\n",
      "Epoch: 469 ; val_loss = 4.459378378993775\n",
      "Start: 470th epoch\n",
      "Epoch: 470 ; val_loss = 4.459378653309272\n",
      "Start: 471th epoch\n",
      "Epoch: 471 ; val_loss = 4.459378924560484\n",
      "Start: 472th epoch\n",
      "Epoch: 472 ; val_loss = 4.459379192780345\n",
      "Start: 473th epoch\n",
      "Epoch: 473 ; val_loss = 4.459379458001776\n",
      "Start: 474th epoch\n",
      "Epoch: 474 ; val_loss = 4.459379720256674\n",
      "Start: 475th epoch\n",
      "Epoch: 475 ; val_loss = 4.459379979577278\n",
      "Start: 476th epoch\n",
      "Epoch: 476 ; val_loss = 4.459380235995341\n",
      "Start: 477th epoch\n",
      "Epoch: 477 ; val_loss = 4.459380489541936\n",
      "Start: 478th epoch\n",
      "Epoch: 478 ; val_loss = 4.459380740248392\n",
      "Start: 479th epoch\n",
      "Epoch: 479 ; val_loss = 4.459380988145439\n",
      "Start: 480th epoch\n",
      "Epoch: 480 ; val_loss = 4.459381233263373\n",
      "Start: 481th epoch\n",
      "Epoch: 481 ; val_loss = 4.459381475632409\n",
      "Start: 482th epoch\n",
      "Epoch: 482 ; val_loss = 4.459381715282135\n",
      "Start: 483th epoch\n",
      "Epoch: 483 ; val_loss = 4.459381952242656\n",
      "Start: 484th epoch\n",
      "Epoch: 484 ; val_loss = 4.459382186542561\n",
      "Start: 485th epoch\n",
      "Epoch: 485 ; val_loss = 4.459382418211062\n",
      "Start: 486th epoch\n",
      "Epoch: 486 ; val_loss = 4.459382647276818\n",
      "Start: 487th epoch\n",
      "Epoch: 487 ; val_loss = 4.459382873768299\n",
      "Start: 488th epoch\n",
      "Epoch: 488 ; val_loss = 4.459383097713127\n",
      "Start: 489th epoch\n",
      "Epoch: 489 ; val_loss = 4.459383319139614\n",
      "Start: 490th epoch\n",
      "Epoch: 490 ; val_loss = 4.459383538074716\n",
      "Start: 491th epoch\n",
      "Epoch: 491 ; val_loss = 4.459383754546153\n",
      "Start: 492th epoch\n",
      "Epoch: 492 ; val_loss = 4.459383968580354\n",
      "Start: 493th epoch\n",
      "Epoch: 493 ; val_loss = 4.459384180204604\n",
      "Start: 494th epoch\n",
      "Epoch: 494 ; val_loss = 4.459384389444542\n",
      "Start: 495th epoch\n",
      "Epoch: 495 ; val_loss = 4.459384596326784\n",
      "Start: 496th epoch\n",
      "Epoch: 496 ; val_loss = 4.459384800877174\n",
      "Start: 497th epoch\n",
      "Epoch: 497 ; val_loss = 4.459385003120912\n",
      "Start: 498th epoch\n",
      "Epoch: 498 ; val_loss = 4.459385203083656\n",
      "Start: 499th epoch\n",
      "Epoch: 499 ; val_loss = 4.459385400790377\n"
     ]
    }
   ],
   "source": [
    "MF_als.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>test_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.104722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.704665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4.589607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.554543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.535410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>495.0</td>\n",
       "      <td>4.459385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>496.0</td>\n",
       "      <td>4.459385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>497.0</td>\n",
       "      <td>4.459385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>498.0</td>\n",
       "      <td>4.459385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>499.0</td>\n",
       "      <td>4.459385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     epoch  test_loss\n",
       "0      0.0   6.104722\n",
       "1      1.0   4.704665\n",
       "2      2.0   4.589607\n",
       "3      3.0   4.554543\n",
       "4      4.0   4.535410\n",
       "..     ...        ...\n",
       "495  495.0   4.459385\n",
       "496  496.0   4.459385\n",
       "497  497.0   4.459385\n",
       "498  498.0   4.459385\n",
       "499  499.0   4.459385\n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MF_als.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result_df = MF_als.summary \n",
    "\n",
    "x = result_df['epoch'].values\n",
    "y = result_df['test_loss'].values\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(axis = 'y')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch Implementation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Netflix(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.users = self.df['Cust_ID'].values\n",
    "        self.items = self.df['Movie_Id'].values\n",
    "        self.ratings = self.df['Rating'].values\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        user = self.users[index]\n",
    "        item = self.items[index]\n",
    "        rating = self.ratings[index]\n",
    "        \n",
    "        return user, item, rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "480189"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Cust_ID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17770"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Movie_Id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cust_ID</th>\n",
       "      <th>Movie_Id</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2005-09-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2005-05-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2005-10-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2005-12-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2004-05-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338928</th>\n",
       "      <td>327</td>\n",
       "      <td>91</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2004-08-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338930</th>\n",
       "      <td>650</td>\n",
       "      <td>91</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2005-11-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338958</th>\n",
       "      <td>436</td>\n",
       "      <td>91</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2005-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338960</th>\n",
       "      <td>442</td>\n",
       "      <td>91</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2004-11-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338975</th>\n",
       "      <td>671</td>\n",
       "      <td>91</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2005-03-21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9992 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Cust_ID  Movie_Id  Rating   Timestamp\n",
       "0             0         0     3.0  2005-09-06\n",
       "1             1         0     5.0  2005-05-13\n",
       "2             2         0     4.0  2005-10-19\n",
       "3             3         0     4.0  2005-12-26\n",
       "4             4         0     3.0  2004-05-03\n",
       "...         ...       ...     ...         ...\n",
       "338928      327        91     1.0  2004-08-12\n",
       "338930      650        91     2.0  2005-11-16\n",
       "338958      436        91     5.0  2005-10-22\n",
       "338960      442        91     1.0  2004-11-19\n",
       "338975      671        91     1.0  2005-03-21\n",
       "\n",
       "[9992 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df = df.loc[(df['Cust_ID'] < 2500) & (df['Movie_Id'] < 92)]\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25135/2844881322.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sample_df['Cust_ID'] = sample_df['Cust_ID'].map(sample_df_user2idx)\n",
      "/tmp/ipykernel_25135/2844881322.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sample_df['Movie_Id'] = sample_df['Movie_Id'].map(sample_df_item2idx)\n",
      "/tmp/ipykernel_25135/2844881322.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sample_df['Timestamp'] = pd.to_datetime(sample_df['Timestamp'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cust_ID</th>\n",
       "      <th>Movie_Id</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2005-09-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2005-05-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2005-10-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2005-12-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2004-05-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338928</th>\n",
       "      <td>327</td>\n",
       "      <td>91</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2004-08-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338930</th>\n",
       "      <td>650</td>\n",
       "      <td>91</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2005-11-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338958</th>\n",
       "      <td>436</td>\n",
       "      <td>91</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2005-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338960</th>\n",
       "      <td>442</td>\n",
       "      <td>91</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2004-11-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338975</th>\n",
       "      <td>671</td>\n",
       "      <td>91</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2005-03-21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9992 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Cust_ID  Movie_Id  Rating  Timestamp\n",
       "0             0         0     3.0 2005-09-06\n",
       "1             1         0     5.0 2005-05-13\n",
       "2             2         0     4.0 2005-10-19\n",
       "3             3         0     4.0 2005-12-26\n",
       "4             4         0     3.0 2004-05-03\n",
       "...         ...       ...     ...        ...\n",
       "338928      327        91     1.0 2004-08-12\n",
       "338930      650        91     2.0 2005-11-16\n",
       "338958      436        91     5.0 2005-10-22\n",
       "338960      442        91     1.0 2004-11-19\n",
       "338975      671        91     1.0 2005-03-21\n",
       "\n",
       "[9992 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample_df = sample_df[['Cust_ID','Movie_Id','Rating']]\n",
    "sample_df_user2idx = {user:idx for idx, user in enumerate(sample_df['Cust_ID'].unique())} \n",
    "sample_df_item2idx = {item:idx for idx, item in enumerate(sample_df['Movie_Id'].unique())}\n",
    "sample_df['Cust_ID'] = sample_df['Cust_ID'].map(sample_df_user2idx)\n",
    "sample_df['Movie_Id'] = sample_df['Movie_Id'].map(sample_df_item2idx)\n",
    "sample_df['Timestamp'] = pd.to_datetime(sample_df['Timestamp'])\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25135/3691379335.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sample_df.loc[:,'bins'] = pd.cut(sample_df['Timestamp'], bins=bins, labels=False)\n"
     ]
    }
   ],
   "source": [
    "bins = pd.date_range(start = '1999-12-01', end = '2005-12-31', freq = 'M')\n",
    "sample_df.loc[:,'bins'] = pd.cut(sample_df['Timestamp'], bins=bins, labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = sample_df[['Cust_ID','Movie_Id','Rating','bins']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(sample_df, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Netflix(train_df)\n",
    "test_dataset = Netflix(test_df)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, criterion ,optimizer):\n",
    "    model.train() \n",
    "    total_loss = 0 \n",
    "    for user, item, rating in train_loader:\n",
    "        user = user.to(device)\n",
    "        item = item.to(device)\n",
    "        rating = rating.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        pred = model(user, item)\n",
    "        loss = criterion(pred, rating)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "def evaluate(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for user, item, rating in test_loader:\n",
    "            try:\n",
    "                user = user.to(device)\n",
    "                item = item.to(device)\n",
    "                rating = rating.to(device)\n",
    "\n",
    "                pred = model(user, item)\n",
    "                loss = criterion(pred, rating)\n",
    "\n",
    "                total_loss += loss.item()\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    return total_loss / len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSELoss(yhat,y):\n",
    "    return torch.sqrt(torch.mean((yhat-y)**2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicFactorizaionModel(nn.Module):\n",
    "    def __init__(self, num_users, num_items, F):\n",
    "        \n",
    "        super(BasicFactorizaionModel, self).__init__()\n",
    "        self.P = nn.Embedding(num_users, F)\n",
    "        self.Q = nn.Embedding(num_items, F)\n",
    "        \n",
    "        self.P.weight.data.normal_(0,1./F)\n",
    "        self.Q.weight.data.normal_(0,1./F)\n",
    "    \n",
    "    def forward(self, user, item):\n",
    "        P_u = self.P(user)\n",
    "        Q_i = self.Q(item)\n",
    "        \n",
    "        rui = torch.sum(P_u * Q_i, dim = 1)\n",
    "        \n",
    "        return rui\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddingBiases(BasicFactorizaionModel):\n",
    "    def __init__(self, num_users, num_items, F, mu):\n",
    "        \n",
    "        super(AddingBiases, self).__init__(num_users, num_items, F)\n",
    "        self.user_biases = nn.Embedding(num_users, 1)\n",
    "        self.item_biases = nn.Embedding(num_items, 1)\n",
    "        \n",
    "        self.user_biases.weight.data.normal_(0,1)\n",
    "        self.item_biases.weight.data.normal_(0,1)\n",
    "        \n",
    "        self.mu = mu\n",
    "        \n",
    "    def forward(self, user, item):\n",
    "        P_u = self.P(user)\n",
    "        Q_i = self.Q(item)\n",
    "        \n",
    "        bu = self.user_biases(user) \n",
    "        bi = self.item_biases(item)\n",
    "        \n",
    "        rui = self.mu + torch.squeeze(bu) + torch.squeeze(bi) + torch.sum(P_u * Q_i, dim = 1)\n",
    "        \n",
    "        return rui "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdditionalInputSources(AddingBiases):\n",
    "    def __init__(self, num_users, num_items, F, mu, implicit_data):\n",
    "        super(AdditionalInputSources, self).__init__(num_users, num_items, F, mu)\n",
    "        self.implicit_data = implicit_data\n",
    "        \n",
    "        self.implicit_factors = nn.Embedding(num_items, F)\n",
    "        self.implicit_factors.weight.data.normal_(0,1./F)\n",
    "        \n",
    "    def forward(self, user, item):\n",
    "        P_u = self.P(user)\n",
    "        Q_i = self.Q(item)\n",
    "        \n",
    "        bu = self.user_biases(user)\n",
    "        bi = self.item_biases(item)\n",
    "        \n",
    "        sum_of_xi = torch.sum(self.implicit_factors(self.implicit_data[int(user)]),dim = 0)\n",
    "        norm = len(self.implicit_data[user]) ** -0.5\n",
    "        \n",
    "        rui = self.mu + torch.squeeze(bu) + torch.squeeze(bi) + torch.sum(Q_i * (P_u + (norm * sum_of_xi)), dim = 1)\n",
    "        \n",
    "        return rui\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalDynamics(AddingBiases):\n",
    "    def __init__(self, num_users, num_items, F, mu, T):\n",
    "        super(TemporalDynamics, self).__init__(num_users, num_items, F, mu)\n",
    "        \n",
    "        self.temporal_user_biases = nn.Parameter(torch.normal(0,1,size=(num_users, T)))\n",
    "        self.temporal_item_biases = nn.Parameter(torch.normal(0,1,size=(num_items, T)))\n",
    "        self.temporal_user_factors = nn.Parameter(torch.normal(0,1/F,size=(num_users, T, F)))\n",
    "        \n",
    "        \n",
    "    def forward(self, user, item, time_bin):\n",
    "        Q_i = self.Q(item)\n",
    "        P_ut = self.temporal_user_factors[user,time_bin,:]\n",
    "        \n",
    "        but = self.temporal_user_biases[user,time_bin]\n",
    "        bit = self.temporal_item_biases[item,time_bin]\n",
    "    \n",
    "\n",
    "        rui = self.mu + torch.squeeze(but) + torch.squeeze(bit) + torch.sum(Q_i * P_ut, dim = 1)\n",
    "        \n",
    "        return rui"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 다른 논문"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaselineEstimates(nn.Module):\n",
    "    def __init__(self, num_users, num_items, mu):\n",
    "        super(BaselineEstimates, self).__init__()\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.mu = mu\n",
    "        \n",
    "        self.user_biases = nn.Embedding(num_users, 1)\n",
    "        self.item_biases = nn.Embedding(num_items, 1)\n",
    "        \n",
    "        self.user_biases.weight.data.normal_(0,1)\n",
    "        self.item_biases.weight.data.normal_(0,1)\n",
    "    \n",
    "    def forward(self, user, item):\n",
    "        bu = self.user_biases(user)\n",
    "        bi = self.item_biases(item)\n",
    "        \n",
    "        rui = self.mu + torch.squeeze(bu) + torch.squeeze(bi)\n",
    "        \n",
    "        return rui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeighborhoodModel(BaselineEstimates):\n",
    "    def __init__(self, num_users, num_items, mu, implicit_data, R, S, k):\n",
    "        super(NeighborhoodModel, self).__init__(num_users, num_items, mu)\n",
    "        self.R = R \n",
    "        self.S = S\n",
    "        self.k = k \n",
    "        self.implicit_data = implicit_data\n",
    "        self.item_weights = nn.Parameter(torch.normal(size=(num_items,num_items)))\n",
    "        self.implicit_offset = nn.Parameter(torch.normal(size=(num_items,num_items)))\n",
    "        \n",
    "        self.similar_k = []\n",
    "        \n",
    "        self.item_weights.weight.data.normal_(0,1)\n",
    "        self.implicit_offset.weight.data.normal_(0,1)\n",
    "        \n",
    "    def get_top_n_indices(self, list, n):\n",
    "        sorted_indices = sorted(range(len(list)), key=lambda i: list[i], reverse=True)\n",
    "        top_n_indices = sorted_indices[:n]\n",
    "        \n",
    "        return top_n_indices\n",
    "\n",
    "    def get_top_k(self):\n",
    "        for item in range(self.num_items):\n",
    "            self.similar_k.append(self.get_top_n_indices(self.S[item], self.k))\n",
    "            \n",
    "    def forward(self, user, item):\n",
    "        bu = self.user_biases(user)\n",
    "        bi = self.item_biases(item)\n",
    "        \n",
    "        bui = self.mu + torch.squeeze(bu) + torch.squeeze(bi)\n",
    "        \n",
    "        sum_of_item_weights = 0\n",
    "        sum_of_implicit_offset = 0\n",
    "        num_k = 0\n",
    "        \n",
    "        self.used_items = self.implicit_data[user]\n",
    "        \n",
    "        for implicit in self.implicit_data[user]:\n",
    "            if implicit in self.similar_k[item]:\n",
    "                num_k += 1\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    bj = self.item_biases(implicit)\n",
    "                    buj = self.mu + torch.squeeze(bu) + torch.squeeze(bj)\n",
    "                sum_of_item_weights += (self.R[user][implicit]-buj) * self.item_weights[item][implicit]\n",
    "                sum_of_implicit_offset += self.implicit_offset[item][implicit]        \n",
    "            \n",
    "        norm = num_k ** -0.5\n",
    "\n",
    "        rui = bui + norm * sum_of_item_weights + norm * sum_of_implicit_offset\n",
    "        \n",
    "        return rui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AsymmetricSVD(BaselineEstimates):\n",
    "    def __init__(self, num_users, num_items, mu, F, implicit_data,R):\n",
    "        super(AsymmetricSVD, self).__init__(num_users, num_items, mu)\n",
    "        self.R = R \n",
    "        self.implicit_data = implicit_data\n",
    "        self.Q = nn.Embedding(num_items, F)\n",
    "        self.X = nn.Embedding(num_items, F)\n",
    "        self.Y = nn.Embedding(num_items, F)\n",
    "        \n",
    "        self.Q.weight.data.normal_(0, 1/F)\n",
    "        self.X.weight.data.normal_(0, 1/F)\n",
    "        self.Y.weight.data.normal_(0, 1/F)\n",
    "        \n",
    "    def forward(self, user, item):\n",
    "        bu = self.user_biases(user)\n",
    "        bi = self.item_biases(item)\n",
    "        \n",
    "        Q_i = self.Q(item)\n",
    "        \n",
    "        sum_of_item_weights = 0\n",
    "        sum_of_implicit_offset = 0\n",
    "        \n",
    "        for implicit in self.implicit_data[user]:\n",
    "            with torch.no_grad():\n",
    "                bj = self.item_biases(implicit)\n",
    "                buj = self.mu + torch.squeeze(bu) + torch.squeeze(bj)\n",
    "            sum_of_item_weights += (self.R[user][implicit] - buj) * self.X(implicit)\n",
    "            sum_of_implicit_offset += self.Y(implicit)\n",
    "            \n",
    "        norm = len(self.implicit_data[user]) ** -0.5        \n",
    "        \n",
    "        rui = self.mu + torch.squeeze(bu) + torch.squeeze(bi) + torch.sum(Q_i * (norm * (sum_of_item_weights + sum_of_implicit_offset)), dim = 1)\n",
    "        \n",
    "        return rui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVDPlusPlus(BaselineEstimates):\n",
    "    def __init__(self, num_users, num_items, mu, F, implicit_data)\n",
    "        super(SVDPlusPlus, self).__init__(num_users, num_items, mu)\n",
    "        \n",
    "        self.implicit_data = implicit_data\n",
    "        self.user_embedding = nn.Embedding(num_users, F)\n",
    "        self.item_embedding = nn.Embedding(num_items, F)\n",
    "        \n",
    "        self.Y = nn.Embedding(num_items, F)\n",
    "        \n",
    "        self.user_embedding.weight.data.normal_(0,1/F)\n",
    "        self.item_embedding.weight.data.normal_(0,1/F)\n",
    "        self.Y.weight.data.normal_(0,1/F)\n",
    "        \n",
    "    def forward(self, user, item):\n",
    "        \n",
    "        bu = self.user_biases(user)\n",
    "        bi = self.item_biases(item)\n",
    "        \n",
    "        P_u = self.user_embedding(user)\n",
    "        Q_i = self.item_embedding(item)\n",
    "        \n",
    "        sum_of_implicit_offset = 0\n",
    "        for implicit in self.implicit_data[user]:\n",
    "            sum_of_implicit_offset += self.Y(implicit)\n",
    "        \n",
    "        norm = len(self.implicit_data[user]) ** -0.5\n",
    "        \n",
    "        rui = self.mu + torch.squeeze(bu) + torch.squeeze(bi) + torch.sum(P_u * (Q_i + norm * sum_of_implicit_offset), dim = 1)\n",
    "        \n",
    "        return rui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntergratedModel(nn.Module):\n",
    "    def __init__(self, num_users, num_items, mu, F, implicit_data, R, S, k):\n",
    "        super(IntergratedModel, self).__init__()\n",
    "        self.neighbor = NeighborhoodModel(num_users, num_items, mu, implicit_data, R, S, k)\n",
    "        self.SVD = SVDPlusPlus(num_users, num_items, mu, F, implicit_data)\n",
    "        \n",
    "    def forward(self, user, item):\n",
    "        rui = self.neighbor(user, item) + self.SVD(user, item)\n",
    "        \n",
    "        return rui"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 개정 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaselineEstimates(nn.Module):\n",
    "    def __init__(self, num_users, num_items, mu):\n",
    "        super(BaselineEstimates, self).__init__()\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.mu = mu\n",
    "        \n",
    "        self.user_biases = nn.Embedding(num_users, 1)\n",
    "        self.item_biases = nn.Embedding(num_items, 1)\n",
    "        \n",
    "        self.user_biases.weight.data.normal_(0,1)\n",
    "        self.item_biases.weight.data.normal_(0,1)\n",
    "    \n",
    "    def forward(self, user, item):\n",
    "        bu = self.user_biases(user)\n",
    "        bi = self.item_biases(item)\n",
    "        \n",
    "        rui = self.mu + torch.squeeze(bu) + torch.squeeze(bi)\n",
    "        \n",
    "        return rui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeighborhoodModel(nn.Module):\n",
    "    def __init__(self, num_users, num_items, mu, implicit_data, R, S, k):\n",
    "        super(NeighborhoodModel, self).__init__()\n",
    "        self.Base = BaselineEstimates(num_users, num_items, mu)\n",
    "        self.R = R \n",
    "        self.S = S\n",
    "        self.k = k \n",
    "        self.implicit_data = implicit_data\n",
    "        self.item_weights = nn.Parameter(torch.normal(size=(num_items,num_items)))\n",
    "        self.implicit_offset = nn.Parameter(torch.normal(size=(num_items,num_items)))\n",
    "        self.mu = mu\n",
    "        \n",
    "        self.similar_k = []\n",
    "        \n",
    "        self.item_weights.weight.data.normal_(0,1)\n",
    "        self.implicit_offset.weight.data.normal_(0,1)\n",
    "        \n",
    "    def get_top_n_indices(self, list, n):\n",
    "        sorted_indices = sorted(range(len(list)), key=lambda i: list[i], reverse=True)\n",
    "        top_n_indices = sorted_indices[:n]\n",
    "        \n",
    "        return top_n_indices\n",
    "\n",
    "    def get_top_k(self):\n",
    "        for item in range(self.num_items):\n",
    "            self.similar_k.append(self.get_top_n_indices(self.S[item], self.k))\n",
    "            \n",
    "    def forward(self, user, item):\n",
    "        bui = self.Base(user, item)\n",
    "        \n",
    "        sum_of_item_weights = 0\n",
    "        sum_of_implicit_offset = 0\n",
    "        num_k = 0\n",
    "        \n",
    "        self.used_items = self.implicit_data[user]\n",
    "        \n",
    "        for implicit in self.implicit_data[user]:\n",
    "            if implicit in self.similar_k[item]:\n",
    "                num_k += 1\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    bj = self.Base.item_biases(implicit)\n",
    "                    buj = self.mu + torch.squeeze(self.Base.user_biases(user)) + torch.squeeze(bj)\n",
    "                    \n",
    "                sum_of_item_weights += (self.R[user][implicit]-buj) * self.item_weights[item][implicit]\n",
    "                sum_of_implicit_offset += self.implicit_offset[item][implicit]        \n",
    "            \n",
    "        norm = num_k ** -0.5\n",
    "\n",
    "        rui = bui + norm * sum_of_item_weights + norm * sum_of_implicit_offset\n",
    "        \n",
    "        return rui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AsymmetricSVD(nn.Module):\n",
    "    def __init__(self, num_users, num_items, mu, F, implicit_data,R):\n",
    "        super(AsymmetricSVD, self).__init__()\n",
    "        self.Base = BaselineEstimates(num_users, num_items, mu)\n",
    "        self.R = R \n",
    "        self.implicit_data = implicit_data\n",
    "        self.Q = nn.Embedding(num_items, F)\n",
    "        self.X = nn.Embedding(num_items, F)\n",
    "        self.Y = nn.Embedding(num_items, F)\n",
    "        \n",
    "        self.Q.weight.data.normal_(0, 1/F)\n",
    "        self.X.weight.data.normal_(0, 1/F)\n",
    "        self.Y.weight.data.normal_(0, 1/F)\n",
    "        \n",
    "    def forward(self, user, item):\n",
    "        bui = self.Base(user, item)\n",
    "        Q_i = self.Q(item)\n",
    "        \n",
    "        sum_of_item_weights = 0\n",
    "        sum_of_implicit_offset = 0\n",
    "        \n",
    "        for implicit in self.implicit_data[user]:\n",
    "            with torch.no_grad():\n",
    "                bj = self.item_biases(implicit)\n",
    "                buj = self.mu + torch.squeeze(bu) + torch.squeeze(bj)\n",
    "            sum_of_item_weights += (self.R[user][implicit] - buj) * self.X(implicit)\n",
    "            sum_of_implicit_offset += self.Y(implicit)\n",
    "            \n",
    "        norm = len(self.implicit_data[user]) ** -0.5        \n",
    "        \n",
    "        rui = bui + torch.sum(Q_i * (norm * (sum_of_item_weights + sum_of_implicit_offset)), dim = 1)\n",
    "        \n",
    "        return rui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVDPlusPlus(nn.Module):\n",
    "    def __init__(self, num_users, num_items, mu, F, implicit_data, is_layer=False):\n",
    "        super(SVDPlusPlus, self).__init__()\n",
    "        self.is_layer = is_layer\n",
    "        self.Base = BaselineEstimates(num_users, num_items, mu)\n",
    "        \n",
    "        self.implicit_data = implicit_data\n",
    "        self.user_embedding = nn.Embedding(num_users, F)\n",
    "        self.item_embedding = nn.Embedding(num_items, F)\n",
    "        \n",
    "        self.Y = nn.Embedding(num_items, F)\n",
    "        \n",
    "        self.user_embedding.weight.data.normal_(0,1/F)\n",
    "        self.item_embedding.weight.data.normal_(0,1/F)\n",
    "        self.Y.weight.data.normal_(0,1/F)\n",
    "        \n",
    "    def forward(self, user, item):\n",
    "        bui = self.Base(user, item)\n",
    "        \n",
    "        P_u = self.user_embedding(user)\n",
    "        Q_i = self.item_embedding(item)\n",
    "        \n",
    "        sum_of_implicit_offset = 0\n",
    "        for implicit in self.implicit_data[user]:\n",
    "            sum_of_implicit_offset += self.Y(implicit)\n",
    "        \n",
    "        norm = len(self.implicit_data[user]) ** -0.5\n",
    "        \n",
    "        if self.is_layer:\n",
    "            rui = torch.sum(P_u * (Q_i + norm * sum_of_implicit_offset), dim = 1)\n",
    "        else:\n",
    "            rui = bui + torch.sum(P_u * (Q_i + norm * sum_of_implicit_offset), dim = 1)\n",
    "        \n",
    "        return rui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntergratedModel(nn.Module):\n",
    "    def __init__(self, num_users, num_items, mu, F, implicit_data, R, S, k):\n",
    "        super(IntergratedModel, self).__init__()\n",
    "        self.neighbor = NeighborhoodModel(num_users, num_items, mu, implicit_data, R, S, k)\n",
    "        self.SVD = SVDPlusPlus(num_users, num_items, mu, F, implicit_data, is_layer=True)\n",
    "        \n",
    "    def forward(self, user, item):\n",
    "        rui = self.neighbor(user, item) + self.SVD(user, item)\n",
    "        \n",
    "        return rui"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 start\n",
      "epoch: 0, train_loss: 4.785584051672856e+33, val_loss: 8.660470352966813e+35\n",
      "epoch: 1 start\n",
      "epoch: 1, train_loss: nan, val_loss: nan\n",
      "epoch: 2 start\n",
      "epoch: 2, train_loss: nan, val_loss: nan\n",
      "epoch: 3 start\n",
      "epoch: 3, train_loss: nan, val_loss: nan\n",
      "epoch: 4 start\n"
     ]
    }
   ],
   "source": [
    "mu = train_df.Rating.mean() \n",
    "implicit_data = train_df.groupby('Cust_ID')['Movie_Id'].apply(list)\n",
    "\n",
    "tmp_implicit_data = [[] for _ in range(1000)]  \n",
    "for idx, i in enumerate(implicit_data):\n",
    "    tmp_implicit_data[implicit_data.index[idx]].append(torch.LongTensor(i).to(device))\n",
    "    \n",
    "model = AdditionalInputSources(len(sample_df_user2idx), len(sample_df_item2idx), 20, mu, tmp_implicit_data)\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01, momentum = 0.9)\n",
    "\n",
    "best_metric = 1 \n",
    "summary = pd.DataFrame({'epoch':[], 'train_loss':[], 'val_loss':[]})\n",
    "\n",
    "for epoch in range(0, 31):\n",
    "    print(f'epoch: {epoch} start')\n",
    "    train_loss = train(model, train_dataloader, RMSELoss, optimizer)\n",
    "    val_loss = evaluate(model, test_dataloader, RMSELoss)\n",
    "    \n",
    "    print(f'epoch: {epoch}, train_loss: {train_loss}, val_loss: {val_loss}')\n",
    "    summary.loc[epoch] = [epoch, train_loss, val_loss]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Timestamp = pd.to_datetime(df.Timestamp, format = '%Y-%m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df.groupby('Timestamp')['Rating'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp\n",
       "1999-11-11    3.428571\n",
       "1999-12-06    3.333333\n",
       "1999-12-08    3.655172\n",
       "1999-12-09    3.487500\n",
       "1999-12-10    3.666667\n",
       "                ...   \n",
       "2005-12-27    3.636133\n",
       "2005-12-28    3.658005\n",
       "2005-12-29    3.686704\n",
       "2005-12-30    3.674725\n",
       "2005-12-31    3.704992\n",
       "Name: Rating, Length: 2182, dtype: float64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 30  # 이동평균 윈도우 크기\n",
    "grouped = grouped.rolling(window).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(grouped.index, grouped.values, marker='o')\n",
    "plt.xlabel('Timestamp')\n",
    "plt.ylabel('Average Rating')\n",
    "plt.title('Average Rating by Timestamp')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neighbor Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = csr_matrix(\n",
    "    (np.array(train_df['Rating'].values, dtype = np.int32),\n",
    "    (np.array(train_df['Cust_ID'].values, dtype = np.int32),np.array(train_df['Movie_Id'].values, dtype = np.int32))\n",
    "    ), shape = (len(sample_df_user2idx), len(sample_df_item2idx)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeighborhoodModel(nn.Module):\n",
    "    def __init__(self, R,mu, k):\n",
    "        super(NeighborhoodModel, self).__init__()\n",
    "        self.R = R \n",
    "        self.k = k\n",
    "        self.num_users, self.num_items = R.shape\n",
    "        self.Base = BaselineEstimates(self.num_users, self.num_items, mu)\n",
    "        self.item_weights = nn.Parameter(torch.normal(0,1,size=(self.num_items,self.num_items)))\n",
    "        self.implicit_offset = nn.Parameter(torch.normal(0,1,size=(self.num_items,self.num_items)))\n",
    "        self.mu = mu\n",
    "        self.S = cosine_similarity(R.T)\n",
    "                \n",
    "        # self.item_weights.weight.data.normal_(0,1)\n",
    "        # self.implicit_offset.weight.data.normal_(0,1)\n",
    "        \n",
    "    def get_top_n_indices(self, list, n):\n",
    "        sorted_indices = sorted(range(len(list)), key=lambda i: list[i], reverse=True)\n",
    "        top_n_indices = sorted_indices[:n]\n",
    "        \n",
    "        return top_n_indices\n",
    "\n",
    "    def get_top_k(self):\n",
    "        self.similar_k = {}\n",
    "        for item in range(self.num_items):\n",
    "            self.similar_k[item] = self.get_top_n_indices(self.S[item], self.k)\n",
    "            \n",
    "    def get_implicit(self):\n",
    "        self.implicit_data = {} \n",
    "        users, items = R.toarray().nonzero()\n",
    "        for user, item in zip(users, items):\n",
    "            if user not in self.implicit_data:\n",
    "                self.implicit_data[user] = []\n",
    "            self.implicit_data[user].append(item)\n",
    "  \n",
    "    def forward(self, user, item):\n",
    "        bui = self.Base(user, item)\n",
    "        user_idx = int(user)\n",
    "        item_idx = int(item)\n",
    "        \n",
    "        sum_of_item_weights = 0\n",
    "        sum_of_implicit_offset = 0\n",
    "        num_k = 0\n",
    "        \n",
    "        self.used_items = self.implicit_data[user_idx]\n",
    "        \n",
    "        for implicit in self.implicit_data[user_idx]:\n",
    "            if implicit in self.similar_k[item_idx]:\n",
    "                implicit_tensor = torch.LongTensor([implicit]).to(device)\n",
    "                num_k += 1\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    buj = self.Base(user, implicit_tensor)\n",
    "                    \n",
    "                sum_of_item_weights += (int(self.R[user,implicit].data)-buj) * self.item_weights[item][0][implicit]\n",
    "                sum_of_implicit_offset += self.implicit_offset[item][0][implicit]        \n",
    "            \n",
    "        norm = num_k ** -0.5\n",
    "\n",
    "        rui = bui + norm * sum_of_item_weights + norm * sum_of_implicit_offset\n",
    "        \n",
    "        return rui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = train_df.Rating.mean() \n",
    "model = NeighborhoodModel(R, mu, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_implicit()\n",
    "model.get_top_k()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 start\n",
      "epoch: 0, train_loss: 0.622453521526758, val_loss: 0.8263899317684921\n",
      "epoch: 1 start\n",
      "epoch: 1, train_loss: 0.39978697247888034, val_loss: 0.7565786944904466\n",
      "epoch: 2 start\n",
      "epoch: 2, train_loss: 0.3776391831088108, val_loss: 0.7324660293769097\n",
      "epoch: 3 start\n",
      "epoch: 3, train_loss: 0.3670304416771244, val_loss: 0.7923912673875533\n",
      "epoch: 4 start\n",
      "epoch: 4, train_loss: 0.3551513009294392, val_loss: 0.7553155518184905\n",
      "epoch: 5 start\n",
      "epoch: 5, train_loss: 0.34936424383718134, val_loss: 0.791883708626822\n",
      "epoch: 6 start\n",
      "epoch: 6, train_loss: 0.35093378408229514, val_loss: 0.8215925696046428\n",
      "epoch: 7 start\n",
      "epoch: 7, train_loss: 0.35111757789315634, val_loss: 0.7969914830703029\n",
      "epoch: 8 start\n",
      "epoch: 8, train_loss: 0.3525471170661822, val_loss: 0.7919800053721013\n",
      "epoch: 9 start\n",
      "epoch: 9, train_loss: 0.3528641533606658, val_loss: 0.8151825267100347\n",
      "epoch: 10 start\n",
      "epoch: 10, train_loss: 0.3541123909628967, val_loss: 0.7996981177048542\n",
      "epoch: 11 start\n",
      "epoch: 11, train_loss: 0.35560269848287784, val_loss: 0.7970867326046122\n",
      "epoch: 12 start\n",
      "epoch: 12, train_loss: 0.3610968603820716, val_loss: 0.8878601678256216\n",
      "epoch: 13 start\n",
      "epoch: 13, train_loss: 0.36104719341395475, val_loss: 0.8371145966098927\n",
      "epoch: 14 start\n",
      "epoch: 14, train_loss: 0.36911619221960573, val_loss: 0.9029637442425587\n",
      "epoch: 15 start\n",
      "epoch: 15, train_loss: 0.3698904070134912, val_loss: 0.8557534190961693\n",
      "epoch: 16 start\n",
      "epoch: 16, train_loss: 0.37713760898275966, val_loss: 0.8456642771435118\n",
      "epoch: 17 start\n",
      "epoch: 17, train_loss: 0.3771330222462282, val_loss: 0.8861795150194542\n",
      "epoch: 18 start\n",
      "epoch: 18, train_loss: 0.38155877365114677, val_loss: 0.906493732606011\n",
      "epoch: 19 start\n",
      "epoch: 19, train_loss: 0.38229583018856356, val_loss: 0.9227686032723671\n",
      "epoch: 20 start\n",
      "epoch: 20, train_loss: 0.38263843342965737, val_loss: 0.885744880950111\n",
      "epoch: 21 start\n",
      "epoch: 21, train_loss: 0.3871095409398009, val_loss: 0.930016333063046\n",
      "epoch: 22 start\n",
      "epoch: 22, train_loss: 0.39365516681479046, val_loss: 0.9315919533200476\n",
      "epoch: 23 start\n",
      "epoch: 23, train_loss: 0.39577535973379663, val_loss: 0.9643612684213322\n",
      "epoch: 24 start\n",
      "epoch: 24, train_loss: 0.40104577257431345, val_loss: 1.002281900586606\n",
      "epoch: 25 start\n",
      "epoch: 25, train_loss: 0.39872795943136763, val_loss: 0.9957206783897284\n",
      "epoch: 26 start\n",
      "epoch: 26, train_loss: 0.40044312172633534, val_loss: 0.9745695179569656\n",
      "epoch: 27 start\n",
      "epoch: 27, train_loss: 0.4013887609334295, val_loss: 0.9840046820259202\n",
      "epoch: 28 start\n",
      "epoch: 28, train_loss: 0.41022134815975064, val_loss: 1.0118937640040442\n",
      "epoch: 29 start\n",
      "epoch: 29, train_loss: 0.4197711628727381, val_loss: 1.0856585391089433\n",
      "epoch: 30 start\n",
      "epoch: 30, train_loss: 0.4188851076265058, val_loss: 1.025028427364887\n"
     ]
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01, momentum = 0.9)\n",
    "\n",
    "best_metric = 1 \n",
    "summary = pd.DataFrame({'epoch':[], 'train_loss':[], 'val_loss':[]})\n",
    "\n",
    "for epoch in range(0, 31):\n",
    "    print(f'epoch: {epoch} start')\n",
    "    train_loss = train(model, train_dataloader, RMSELoss, optimizer)\n",
    "    val_loss = evaluate(model, test_dataloader, RMSELoss)\n",
    "    \n",
    "    print(f'epoch: {epoch}, train_loss: {train_loss}, val_loss: {val_loss}')\n",
    "    summary.loc[epoch] = [epoch, train_loss, val_loss]\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AsymmetricSVD Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AsymmetricSVD(nn.Module):\n",
    "    def __init__(self, R, mu, F):\n",
    "        super(AsymmetricSVD, self).__init__()\n",
    "        self.num_users, self.num_items = R.shape\n",
    "        self.Base = BaselineEstimates(self.num_users, self.num_items, mu)\n",
    "        self.R = R \n",
    "        self.Q = nn.Embedding(self.num_items, F)\n",
    "        self.X = nn.Embedding(self.num_items, F)\n",
    "        self.Y = nn.Embedding(self.num_items, F)\n",
    "        \n",
    "        self.Q.weight.data.normal_(0, 1/F)\n",
    "        self.X.weight.data.normal_(0, 1/F)\n",
    "        self.Y.weight.data.normal_(0, 1/F)\n",
    "        \n",
    "    def get_implicit(self):\n",
    "        self.implicit_data = {} \n",
    "        users, items = R.toarray().nonzero()\n",
    "        for user, item in zip(users, items):\n",
    "            if user not in self.implicit_data:\n",
    "                self.implicit_data[user] = []\n",
    "            self.implicit_data[user].append(item)\n",
    "        \n",
    "    def forward(self, user, item):\n",
    "        user_idx = int(user)\n",
    "        \n",
    "        bui = self.Base(user, item)\n",
    "        Q_i = self.Q(item)\n",
    "        \n",
    "        sum_of_item_weights = 0\n",
    "        sum_of_implicit_offset = 0\n",
    "        \n",
    "        for implicit in self.implicit_data[user_idx]:\n",
    "            implicit_tensor = torch.LongTensor([implicit]).to(device)\n",
    "            with torch.no_grad():\n",
    "                buj = self.Base(user, implicit_tensor)\n",
    "                \n",
    "            sum_of_item_weights += (int(self.R[user,implicit].data) - buj) * self.X(implicit_tensor)\n",
    "            sum_of_implicit_offset += self.Y(implicit_tensor)\n",
    "            \n",
    "        norm = len(self.implicit_data[user_idx]) ** -0.5        \n",
    "        \n",
    "        rui = bui + torch.sum(Q_i * (norm * (sum_of_item_weights + sum_of_implicit_offset)), dim = 1)\n",
    "        \n",
    "        return rui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 start\n",
      "epoch: 0, train_loss: 0.6986598813505259, val_loss: 0.9947714358568192\n",
      "epoch: 1 start\n",
      "epoch: 1, train_loss: 0.5851209419304672, val_loss: 0.9911296897199287\n",
      "epoch: 2 start\n",
      "epoch: 2, train_loss: 0.5654666379987112, val_loss: 0.9564874087529758\n",
      "epoch: 3 start\n",
      "epoch: 3, train_loss: 0.54976838750325, val_loss: 0.927793711692229\n",
      "epoch: 4 start\n",
      "epoch: 4, train_loss: 0.5427328251338596, val_loss: 0.9848491631340182\n",
      "epoch: 5 start\n",
      "epoch: 5, train_loss: 0.5348831640977548, val_loss: 1.0254358974261664\n",
      "epoch: 6 start\n"
     ]
    }
   ],
   "source": [
    "mu = train_df.Rating.mean() \n",
    "model = AsymmetricSVD(R,mu, 20)\n",
    "model.get_implicit()\n",
    "device = torch.device('cpu')\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01, momentum = 0.9)\n",
    "\n",
    "best_metric = 1 \n",
    "summary = pd.DataFrame({'epoch':[], 'train_loss':[], 'val_loss':[]})\n",
    "\n",
    "for epoch in range(0, 31):\n",
    "    print(f'epoch: {epoch} start')\n",
    "    train_loss = train(model, train_dataloader, RMSELoss, optimizer)\n",
    "    val_loss = evaluate(model, test_dataloader, RMSELoss)\n",
    "    \n",
    "    print(f'epoch: {epoch}, train_loss: {train_loss}, val_loss: {val_loss}')\n",
    "    summary.loc[epoch] = [epoch, train_loss, val_loss]\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD++ Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVDPlusPlus(nn.Module):\n",
    "    def __init__(self, R, mu, F, is_layer=False):\n",
    "        super(SVDPlusPlus, self).__init__()\n",
    "        self.is_layer = is_layer\n",
    "        self.R = R \n",
    "        self.num_users, self.num_items = R.shape\n",
    "        self.Base = BaselineEstimates(self.num_users, self.num_items, mu)\n",
    "        \n",
    "        self.user_embedding = nn.Embedding(self.num_users, F)\n",
    "        self.item_embedding = nn.Embedding(self.num_items, F)\n",
    "        \n",
    "        self.Y = nn.Embedding(self.num_items, F)\n",
    "        \n",
    "        self.user_embedding.weight.data.normal_(0,1/F)\n",
    "        self.item_embedding.weight.data.normal_(0,1/F)\n",
    "        self.Y.weight.data.normal_(0,1/F)\n",
    "        \n",
    "    def get_implicit(self):\n",
    "        self.implicit_data = {} \n",
    "        users, items = R.toarray().nonzero()\n",
    "        for user, item in zip(users, items):\n",
    "            if user not in self.implicit_data:\n",
    "                self.implicit_data[user] = []\n",
    "            self.implicit_data[user].append(item)\n",
    "        \n",
    "    def forward(self, user, item):\n",
    "        user_idx = int(user)\n",
    "        \n",
    "        bui = self.Base(user, item)\n",
    "        \n",
    "        P_u = self.user_embedding(user)\n",
    "        Q_i = self.item_embedding(item)\n",
    "        \n",
    "        sum_of_implicit_offset = 0\n",
    "        for implicit in self.implicit_data[user_idx]:\n",
    "            implicit_tensor = torch.LongTensor([implicit]).to(device)\n",
    "            sum_of_implicit_offset += self.Y(implicit_tensor)\n",
    "        \n",
    "        norm = len(self.implicit_data[user_idx]) ** -0.5\n",
    "        \n",
    "        if self.is_layer:\n",
    "            rui = torch.sum(P_u * (Q_i + norm * sum_of_implicit_offset), dim = 1)\n",
    "        else:\n",
    "            rui = bui + torch.sum(P_u * (Q_i + norm * sum_of_implicit_offset), dim = 1)\n",
    "        \n",
    "        return rui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = train_df.Rating.mean() \n",
    "model = SVDPlusPlus(R, mu, 20)\n",
    "model.get_implicit()\n",
    "device = torch.device('cpu')\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01, momentum = 0.9)\n",
    "\n",
    "best_metric = 1 \n",
    "summary = pd.DataFrame({'epoch':[], 'train_loss':[], 'val_loss':[]})\n",
    "\n",
    "for epoch in range(0, 31):\n",
    "    print(f'epoch: {epoch} start')\n",
    "    train_loss = train(model, train_dataloader, RMSELoss, optimizer)\n",
    "    val_loss = evaluate(model, test_dataloader, RMSELoss)\n",
    "    \n",
    "    print(f'epoch: {epoch}, train_loss: {train_loss}, val_loss: {val_loss}')\n",
    "    summary.loc[epoch] = [epoch, train_loss, val_loss]\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Intergrated Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntergratedModel(nn.Module):\n",
    "    def __init__(self, R, mu, F, k):\n",
    "        super(IntergratedModel, self).__init__()\n",
    "        self.neighbor = NeighborhoodModel(R,mu,k)\n",
    "        self.SVD = SVDPlusPlus(R,mu,F, is_layer=True)\n",
    "        \n",
    "    def model_init(self):\n",
    "        self.neighbor.get_implicit()\n",
    "        self.neighbor.get_top_k()\n",
    "        self.SVD.get_implicit()\n",
    "        \n",
    "    def forward(self, user, item):\n",
    "        rui = self.neighbor(user, item) + self.SVD(user, item)\n",
    "        \n",
    "        return rui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 start\n",
      "epoch: 0, train_loss: 0.6343768035409695, val_loss: 0.7460026293191658\n",
      "epoch: 1 start\n",
      "epoch: 1, train_loss: 0.39162416618010226, val_loss: 0.7726222559075435\n",
      "epoch: 2 start\n",
      "epoch: 2, train_loss: 0.35223923379213484, val_loss: 0.7968696838113414\n",
      "epoch: 3 start\n",
      "epoch: 3, train_loss: 0.3383389142825808, val_loss: 0.7939018138300902\n",
      "epoch: 4 start\n",
      "epoch: 4, train_loss: 0.3280554994484942, val_loss: 0.8061952504062426\n",
      "epoch: 5 start\n",
      "epoch: 5, train_loss: 0.3217552751894627, val_loss: 0.7928626581433864\n",
      "epoch: 6 start\n",
      "epoch: 6, train_loss: 0.3202105530520304, val_loss: 0.7533481101048416\n",
      "epoch: 7 start\n",
      "epoch: 7, train_loss: 0.3197014715168781, val_loss: 0.8231635082451596\n",
      "epoch: 8 start\n",
      "epoch: 8, train_loss: 0.32314364579570887, val_loss: 0.8086306941455575\n",
      "epoch: 9 start\n",
      "epoch: 9, train_loss: 0.3223049497493073, val_loss: 0.8103082744537919\n",
      "epoch: 10 start\n",
      "epoch: 10, train_loss: 0.32487125970664643, val_loss: 0.7900588867059346\n",
      "epoch: 11 start\n",
      "epoch: 11, train_loss: 0.3255467473869626, val_loss: 0.7952006455583535\n",
      "epoch: 12 start\n",
      "epoch: 12, train_loss: 0.3277794482477963, val_loss: 0.8283909258095845\n",
      "epoch: 13 start\n",
      "epoch: 13, train_loss: 0.3356418812862553, val_loss: 0.8334629534538267\n",
      "epoch: 14 start\n",
      "epoch: 14, train_loss: 0.3378951182206991, val_loss: 0.8276510042338266\n",
      "epoch: 15 start\n",
      "epoch: 15, train_loss: 0.3354490014839669, val_loss: 0.8521067287144869\n",
      "epoch: 16 start\n",
      "epoch: 16, train_loss: 0.3428596675784667, val_loss: 0.8570390699367006\n",
      "epoch: 17 start\n",
      "epoch: 17, train_loss: 0.35402448385549357, val_loss: 0.9392771889148592\n",
      "epoch: 18 start\n",
      "epoch: 18, train_loss: 0.3509028268952133, val_loss: 0.8574598399729372\n",
      "epoch: 19 start\n",
      "epoch: 19, train_loss: 0.35992132034956714, val_loss: 0.8747029997419572\n",
      "epoch: 20 start\n",
      "epoch: 20, train_loss: 0.3653132052082849, val_loss: 0.8717933052842352\n",
      "epoch: 21 start\n",
      "epoch: 21, train_loss: 0.3659958077244387, val_loss: 0.9049476216425593\n",
      "epoch: 22 start\n",
      "epoch: 22, train_loss: 0.3677471492159401, val_loss: 0.8833253723757901\n",
      "epoch: 23 start\n",
      "epoch: 23, train_loss: 0.37859816639826877, val_loss: 0.9268362426449204\n",
      "epoch: 24 start\n",
      "epoch: 24, train_loss: 0.3807354313115759, val_loss: 0.9034910558416821\n",
      "epoch: 25 start\n",
      "epoch: 25, train_loss: 0.3863127447835319, val_loss: 0.8867871277518813\n",
      "epoch: 26 start\n",
      "epoch: 26, train_loss: 0.3920196329292302, val_loss: 0.899399888185992\n",
      "epoch: 27 start\n",
      "epoch: 27, train_loss: 0.39748924480159015, val_loss: 0.9731833932435828\n",
      "epoch: 28 start\n",
      "epoch: 28, train_loss: 0.4006853639649783, val_loss: 0.9431853363623077\n",
      "epoch: 29 start\n",
      "epoch: 29, train_loss: 0.4095615757444945, val_loss: 0.8961145219771847\n",
      "epoch: 30 start\n",
      "epoch: 30, train_loss: 0.4090384267001177, val_loss: 0.919607348136302\n"
     ]
    }
   ],
   "source": [
    "mu = train_df.Rating.mean() \n",
    "model = IntergratedModel(R, mu, 20, 5)\n",
    "model.model_init()\n",
    "device = torch.device('cpu')\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01, momentum = 0.9)\n",
    "\n",
    "best_metric = 1 \n",
    "summary = pd.DataFrame({'epoch':[], 'train_loss':[], 'val_loss':[]})\n",
    "\n",
    "for epoch in range(0, 31):\n",
    "    print(f'epoch: {epoch} start')\n",
    "    train_loss = train(model, train_dataloader, RMSELoss, optimizer)\n",
    "    val_loss = evaluate(model, test_dataloader, RMSELoss)\n",
    "    \n",
    "    print(f'epoch: {epoch}, train_loss: {train_loss}, val_loss: {val_loss}')\n",
    "    summary.loc[epoch] = [epoch, train_loss, val_loss]\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporal Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Temporal_Netflix(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.users = self.df['Cust_ID'].values\n",
    "        self.items = self.df['Movie_Id'].values\n",
    "        self.ratings = self.df['Rating'].values\n",
    "        self.time = self.df['bins'].values\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        user = self.users[index]\n",
    "        item = self.items[index]\n",
    "        time = self.time[index]\n",
    "\n",
    "        rating = self.ratings[index]\n",
    "        \n",
    "        return user, item,time, rating\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(sample_df, test_size = 0.2, random_state = 42)\n",
    "train_dataset = Temporal_Netflix(train_df)\n",
    "test_dataset = Temporal_Netflix(test_df)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "def temporal_train(model, train_loader):\n",
    "    model.train() \n",
    "    total_loss = 0 \n",
    "    for user, item, time,rating in train_loader:\n",
    "        user = user.to(device)\n",
    "        item = item.to(device)\n",
    "        time = time.to(device)\n",
    "        rating = rating.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        pred = model(user, item,time)\n",
    "        loss = criterion(pred, rating)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    total_loss = total_loss / len(train_loader)\n",
    "    \n",
    "    return total_loss\n",
    "\n",
    "def temporal_evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for user, item, time,rating in test_loader:\n",
    "            user = user.to(device)\n",
    "            item = item.to(device)\n",
    "            time = time.to(device)\n",
    "            rating = rating.to(device)\n",
    "\n",
    "            pred = model(user, item,time)\n",
    "            loss = criterion(pred, rating)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(test_loader)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = train_df.Rating.mean()\n",
    "model = TemporalDynamics(len(sample_df_user2idx), len(sample_df_item2idx), 20, mu, 72)\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01, momentum = 0.9)\n",
    "criterion = RMSELoss\n",
    "\n",
    "best_metric = 1 \n",
    "summary = pd.DataFrame({'epoch':[], 'train_loss':[], 'val_loss':[]})\n",
    "\n",
    "for epoch in range(0, 31):\n",
    "    print(f'epoch: {epoch} start')\n",
    "    train_loss = temporal_train(model, train_dataloader)\n",
    "    val_loss = temporal_evaluate(model, test_dataloader)\n",
    "    \n",
    "    print(f'epoch: {epoch}, train_loss: {train_loss}, val_loss: {val_loss}')\n",
    "    summary.loc[epoch] = [epoch, train_loss, val_loss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recbole",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
