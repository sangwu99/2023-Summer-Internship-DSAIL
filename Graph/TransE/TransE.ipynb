{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.data import FB15kDataset\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# entities: 14951\n",
      "# relations: 1345\n",
      "# training edges: 483142\n",
      "# validation edges: 50000\n",
      "# testing edges: 59071\n",
      "Done loading data from cached files.\n",
      "966284 966284 966284\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "dataset = FB15kDataset()\n",
    "graph = dataset[0]\n",
    "\n",
    "# get training mask\n",
    "train_mask = graph.edata['train_mask']\n",
    "train_idx = torch.nonzero(train_mask, as_tuple=False).squeeze()\n",
    "head, tail = graph.edges._graph.find_edges(train_idx)\n",
    "# get edge types in training set\n",
    "label = graph.edata['etype'][train_idx]\n",
    "print(len(head), len(tail), len(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransE(nn.Module):\n",
    "    def __init__(self, num_entities: int, num_relations: int, embedding_dim: int):\n",
    "        super().__init__()\n",
    "        self.num_entities = num_entities\n",
    "        self.num_relations = num_relations\n",
    "        self.k = embedding_dim\n",
    "        self.entity_embedding = nn.Embedding(num_entities, embedding_dim)\n",
    "        self.relation_embedding = nn.Embedding(num_relations, embedding_dim)\n",
    "        self.initialize()\n",
    "        \n",
    "    def initialize(self):\n",
    "        nn.init.uniform_(self.entity_embedding.weight.data, -6/self.k, 6/self.k)\n",
    "        nn.init.uniform_(self.relation_embedding.weight.data, -6/self.k, 6/self.k)\n",
    "        \n",
    "        self.relation_embedding.weight.data = self.relation_embedding.weight.data / torch.norm(self.relation_embedding.weight.data, dim=1, keepdim=True)\n",
    "    \n",
    "    def norm_entity(self):\n",
    "        self.entity_embedding.weight.data = self.entity_embedding.weight.data / torch.norm(self.entity_embedding.weight.data, dim=1, keepdim=True)\n",
    "        \n",
    "    def forward(self, head: torch.Tensor, tail: torch.Tensor, label: torch.Tensor):\n",
    "        head_embedding = self.entity_embedding(head)\n",
    "        tail_embedding = self.entity_embedding(tail)\n",
    "        relation_embedding = self.relation_embedding(label)\n",
    "        \n",
    "        score = torch.norm(head_embedding + relation_embedding - tail_embedding, dim=1)\n",
    "        return score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14951"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.num_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FB15k(Dataset):\n",
    "    def __init__(self, graph, idx):\n",
    "        self.head, self.tail = graph.edges._graph.find_edges(idx)\n",
    "        self.label = graph.edata['etype'][idx]\n",
    "        self.num_entities = graph.num_nodes()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.head)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.head[idx], self.label[idx], self.tail[idx] \n",
    "    \n",
    "    def make_neg_samples(self, num_neg_samples: int, entities):\n",
    "        neg_samples = []\n",
    "        for entity in entities:\n",
    "            neg_samples.extend([entity] * num_neg_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_neg_samples(num_neg_samples, entities):\n",
    "    neg_samples = []\n",
    "    for entity in entities:\n",
    "        neg_samples.append(torch.randint(0, num_entities, (num_neg_samples,)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(graph, batch_size=128):\n",
    "    train_mask, val_mask, test_mask = graph.edata['train_mask'], graph.edata['val_mask'], graph.edata['test_mask']\n",
    "    \n",
    "    train_idx = torch.nonzero(train_mask, as_tuple=False).squeeze()\n",
    "    val_idx = torch.nonzero(val_mask, as_tuple=False).squeeze()\n",
    "    test_idx = torch.nonzero(test_mask, as_tuple=False).squeeze()\n",
    "    \n",
    "    train_dataset = FB15k(graph, train_idx)\n",
    "    val_dataset = FB15k(graph, val_idx)\n",
    "    test_dataset = FB15k(graph, test_idx)\n",
    "    \n",
    "    train_dataloader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size, shuffle=False)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size, shuffle=False)\n",
    "    \n",
    "    \n",
    "    return train_dataloader, val_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# entities: 14951\n",
      "# relations: 1345\n",
      "# training edges: 483142\n",
      "# validation edges: 50000\n",
      "# testing edges: 59071\n",
      "Done loading data from cached files.\n"
     ]
    }
   ],
   "source": [
    "dataset = FB15kDataset()\n",
    "graph = dataset[0]\n",
    "train_dataloader, val_dataloader, test_dataloader = split_dataset(graph,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransE(graph.num_nodes(), graph.num_edges(), 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "head, label, tail = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(head,label,tail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.1264, 1.1560, 1.2738, 1.0391, 1.1043, 1.0790, 1.2637, 1.3209],\n",
       "       grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([pred, neg_pred], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg = torch.randint(0, 14951, (4,))\n",
    "neg_pred = model(head, label, neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1., -1., -1., -1.])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-1 * torch.ones(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1023, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.MarginRankingLoss(0.1)(pred, neg_pred, -1 * torch.ones(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6474,  3487, 13227,  8967, 13721, 12050,  1396,  6958])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2267,  354,  178, 4885, 2267,  354,  178, 4885, 2267,  354,  178, 4885,\n",
       "        2267,  354,  178, 4885])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/opt/ml/input/2023-Summer-Internship-DSAIL/Graph/TransE/TransE.ipynb ì…€ 21\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B101.101.218.32/opt/ml/input/2023-Summer-Internship-DSAIL/Graph/TransE/TransE.ipynb#Y110sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(pos, neg, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39mones(batch \u001b[39m*\u001b[39m neg_num \u001b[39m*\u001b[39m \u001b[39m2\u001b[39m))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B101.101.218.32/opt/ml/input/2023-Summer-Internship-DSAIL/Graph/TransE/TransE.ipynb#Y110sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad() \n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B101.101.218.32/opt/ml/input/2023-Summer-Internship-DSAIL/Graph/TransE/TransE.ipynb#Y110sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B101.101.218.32/opt/ml/input/2023-Summer-Internship-DSAIL/Graph/TransE/TransE.ipynb#Y110sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m total_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B101.101.218.32/opt/ml/input/2023-Summer-Internship-DSAIL/Graph/TransE/TransE.ipynb#Y110sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m/opt/conda/envs/recbole/lib/python3.8/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    489\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    490\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/envs/recbole/lib/python3.8/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 30 \n",
    "model = TransE(graph.num_nodes(), graph.num_edges(), 50)\n",
    "neg_num = 2\n",
    "criterion = nn.MarginRankingLoss(0.1)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "batch = 4\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.norm_entity()\n",
    "    total_loss = 0\n",
    "\n",
    "    for head, label, tail in train_dataloader:\n",
    "        head, label, tail = head.repeat(neg_num) , label.repeat(neg_num), tail.repeat(neg_num)\n",
    "        pos = model(head, label, tail).repeat(2)\n",
    "        neg_head, neg_tail = torch.randint(0, 14951, (batch * neg_num,)), torch.randint(0, 14951, (batch * neg_num,))\n",
    "        neg = torch.cat([model(head, label, neg_tail), model(neg_head, label, tail)], dim = 0)\n",
    "        \n",
    "        loss = criterion(pos, neg, -1 * torch.ones(batch * neg_num * 2))\n",
    "        optimizer.zero_grad() \n",
    "        loss.backward()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "    print(total_loss // len(train_dataloader))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.1264, 1.1560, 1.2738, 1.0391, 1.1264, 1.1560, 1.2738, 1.0391, 1.1264,\n",
       "        1.1560, 1.2738, 1.0391], grad_fn=<RepeatBackward0>)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = pred.repeat(3)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9159, 14794,   385,  8600])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsail",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
